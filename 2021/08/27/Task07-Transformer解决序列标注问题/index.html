<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=2">
<meta name="theme-color" content="#222">
<meta name="generator" content="Hexo 5.4.0">
  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png">
  <link rel="mask-icon" href="/images/logo.svg" color="#222">

<link rel="stylesheet" href="/css/main.css">


<link rel="stylesheet" href="/lib/font-awesome/css/all.min.css">

<script id="hexo-configurations">
    var NexT = window.NexT || {};
    var CONFIG = {"hostname":"example.com","root":"/","scheme":"Muse","version":"7.8.0","exturl":false,"sidebar":{"position":"left","display":"post","padding":18,"offset":12,"onmobile":false},"copycode":{"enable":false,"show_result":false,"style":null},"back2top":{"enable":true,"sidebar":false,"scrollpercent":false},"bookmark":{"enable":false,"color":"#222","save":"auto"},"fancybox":false,"mediumzoom":false,"lazyload":false,"pangu":false,"comments":{"style":"tabs","active":null,"storage":true,"lazyload":false,"nav":null},"algolia":{"hits":{"per_page":10},"labels":{"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}},"localsearch":{"enable":false,"trigger":"auto","top_n_per_article":1,"unescape":false,"preload":false},"motion":{"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}},"path":"search.xml"};
  </script>

  <meta name="description" content="0 总结1.trainer.evaluate()AttributeError: ‘NoneType’ object has no attribute ‘log_metric’解决：pip install tensorboard分析：应当是tensorboard缺失或者版本不对 2.序列标注任务和文本分类任务相比，只是在最后一层有所改动 1 序列标注任务简介常见的三种token级别的分类任务：  N">
<meta property="og:type" content="article">
<meta property="og:title" content="Task07-Transformer解决序列标注问题">
<meta property="og:url" content="http://example.com/2021/08/27/Task07-Transformer%E8%A7%A3%E5%86%B3%E5%BA%8F%E5%88%97%E6%A0%87%E6%B3%A8%E9%97%AE%E9%A2%98/index.html">
<meta property="og:site_name" content="Hexo">
<meta property="og:description" content="0 总结1.trainer.evaluate()AttributeError: ‘NoneType’ object has no attribute ‘log_metric’解决：pip install tensorboard分析：应当是tensorboard缺失或者版本不对 2.序列标注任务和文本分类任务相比，只是在最后一层有所改动 1 序列标注任务简介常见的三种token级别的分类任务：  N">
<meta property="og:locale" content="en_US">
<meta property="article:published_time" content="2021-08-27T09:26:23.000Z">
<meta property="article:modified_time" content="2021-08-30T13:51:57.046Z">
<meta property="article:author" content="Ming Qin">
<meta name="twitter:card" content="summary">

<link rel="canonical" href="http://example.com/2021/08/27/Task07-Transformer%E8%A7%A3%E5%86%B3%E5%BA%8F%E5%88%97%E6%A0%87%E6%B3%A8%E9%97%AE%E9%A2%98/">


<script id="page-configurations">
  // https://hexo.io/docs/variables.html
  CONFIG.page = {
    sidebar: "",
    isHome : false,
    isPost : true,
    lang   : 'en'
  };
</script>

  <title>Task07-Transformer解决序列标注问题 | Hexo</title>
  






  <noscript>
  <style>
  .use-motion .brand,
  .use-motion .menu-item,
  .sidebar-inner,
  .use-motion .post-block,
  .use-motion .pagination,
  .use-motion .comments,
  .use-motion .post-header,
  .use-motion .post-body,
  .use-motion .collection-header { opacity: initial; }

  .use-motion .site-title,
  .use-motion .site-subtitle {
    opacity: initial;
    top: initial;
  }

  .use-motion .logo-line-before i { left: initial; }
  .use-motion .logo-line-after i { right: initial; }
  </style>
</noscript>

</head>

<body itemscope itemtype="http://schema.org/WebPage">
  <div class="container use-motion">
    <div class="headband"></div>

    <header class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-container">
  <div class="site-nav-toggle">
    <div class="toggle" aria-label="Toggle navigation bar">
      <span class="toggle-line toggle-line-first"></span>
      <span class="toggle-line toggle-line-middle"></span>
      <span class="toggle-line toggle-line-last"></span>
    </div>
  </div>

  <div class="site-meta">

    <a href="/" class="brand" rel="start">
      <span class="logo-line-before"><i></i></span>
      <h1 class="site-title">Hexo</h1>
      <span class="logo-line-after"><i></i></span>
    </a>
  </div>

  <div class="site-nav-right">
    <div class="toggle popup-trigger">
    </div>
  </div>
</div>




<nav class="site-nav">
  <ul id="menu" class="main-menu menu">
        <li class="menu-item menu-item-home">

    <a href="/" rel="section"><i class="fa fa-home fa-fw"></i>Home</a>

  </li>
        <li class="menu-item menu-item-archives">

    <a href="/archives/" rel="section"><i class="fa fa-archive fa-fw"></i>Archives</a>

  </li>
  </ul>
</nav>




</div>
    </header>

    
  <div class="back-to-top">
    <i class="fa fa-arrow-up"></i>
    <span>0%</span>
  </div>


    <main class="main">
      <div class="main-inner">
        <div class="content-wrap">
          

          <div class="content post posts-expand">
            

    
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="en">
    <link itemprop="mainEntityOfPage" href="http://example.com/2021/08/27/Task07-Transformer%E8%A7%A3%E5%86%B3%E5%BA%8F%E5%88%97%E6%A0%87%E6%B3%A8%E9%97%AE%E9%A2%98/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="Ming Qin">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Hexo">
    </span>
      <header class="post-header">
        <h1 class="post-title" itemprop="name headline">
          Task07-Transformer解决序列标注问题
        </h1>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>

              <time title="Created: 2021-08-27 17:26:23" itemprop="dateCreated datePublished" datetime="2021-08-27T17:26:23+08:00">2021-08-27</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">Edited on</span>
                <time title="Modified: 2021-08-30 21:51:57" itemprop="dateModified" datetime="2021-08-30T21:51:57+08:00">2021-08-30</time>
              </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
        <h1 id="0-总结"><a href="#0-总结" class="headerlink" title="0 总结"></a>0 总结</h1><p>1.<br>trainer.evaluate()<br>AttributeError: ‘NoneType’ object has no attribute ‘log_metric’<br>解决：pip install tensorboard<br>分析：应当是tensorboard缺失或者版本不对</p>
<p>2.<br>序列标注任务和文本分类任务相比，只是在最后一层有所改动</p>
<h1 id="1-序列标注任务简介"><a href="#1-序列标注任务简介" class="headerlink" title="1 序列标注任务简介"></a>1 序列标注任务简介</h1><p>常见的三种token级别的分类任务：</p>
<ul>
<li>NER，标注 person、organization\location 等</li>
<li>POS(Part-of-speech tagging，词性标注) ： 名词、动词和形容词等</li>
<li>Chunk（Chunking短语组块）：将同一短语的token组块放在一起。</li>
</ul>
<p>注意根据GPU显存调整batch size 的大小</p>
<h1 id="2-选择一种分类任务"><a href="#2-选择一种分类任务" class="headerlink" title="2 选择一种分类任务"></a>2 选择一种分类任务</h1><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">task = <span class="string">&quot;ner&quot;</span> <span class="comment">#需要是&quot;ner&quot;, &quot;pos&quot; 或者 &quot;chunk&quot;</span></span><br><span class="line">model_checkpoint = <span class="string">&quot;distilbert-base-uncased&quot;</span></span><br><span class="line">batch_size = <span class="number">16</span></span><br></pre></td></tr></table></figure>

<h1 id="3-加载数据及数据分析"><a href="#3-加载数据及数据分析" class="headerlink" title="3 加载数据及数据分析"></a>3 加载数据及数据分析</h1><h2 id="3-1-加载数据"><a href="#3-1-加载数据" class="headerlink" title="3.1 加载数据"></a>3.1 加载数据</h2><p>同Task06</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> datasets <span class="keyword">import</span> load_dataset, load_metric</span><br></pre></td></tr></table></figure>
<p>加载数据官方指南：<a target="_blank" rel="noopener" href="https://huggingface.co/docs/datasets/loading_datasets.html#from-local-files">数据集文档</a></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">datasets = load_dataset(<span class="string">&quot;conll2003&quot;</span>)</span><br><span class="line"><span class="comment"># 此处加载[CONLL 2003 dataset](https://www.aclweb.org/anthology/W03-0419.pdf)数据集。</span></span><br></pre></td></tr></table></figure>

<h2 id="3-2-数据分析"><a href="#3-2-数据分析" class="headerlink" title="3.2 数据分析"></a>3.2 数据分析</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">datasets</span><br></pre></td></tr></table></figure>




<pre><code>DatasetDict(&#123;
    train: Dataset(&#123;
        features: [&#39;id&#39;, &#39;tokens&#39;, &#39;pos_tags&#39;, &#39;chunk_tags&#39;, &#39;ner_tags&#39;],
        num_rows: 14041
    &#125;)
    validation: Dataset(&#123;
        features: [&#39;id&#39;, &#39;tokens&#39;, &#39;pos_tags&#39;, &#39;chunk_tags&#39;, &#39;ner_tags&#39;],
        num_rows: 3250
    &#125;)
    test: Dataset(&#123;
        features: [&#39;id&#39;, &#39;tokens&#39;, &#39;pos_tags&#39;, &#39;chunk_tags&#39;, &#39;ner_tags&#39;],
        num_rows: 3453
    &#125;)
&#125;)
</code></pre>
<p>‘datasets’本身是一种<a target="_blank" rel="noopener" href="https://huggingface.co/docs/datasets/package_reference/main_classes.html#datasetdict"><code>DatasetDict</code></a>数据结构.拥有：</p>
<ul>
<li>训练集</li>
<li>验证集</li>
<li>测试集<br>只需要使用对应的key（train，validation，set）即可得到对应数据。</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">datasets[<span class="string">&quot;train&quot;</span>][<span class="number">0</span>]</span><br><span class="line"><span class="comment"># 给定一个数据切分的key（train、validation或者test）和下标即可查看数据。</span></span><br></pre></td></tr></table></figure>




<pre><code>&#123;&#39;chunk_tags&#39;: [11, 21, 11, 12, 21, 22, 11, 12, 0],
 &#39;id&#39;: &#39;0&#39;,
 &#39;ner_tags&#39;: [3, 0, 7, 0, 0, 0, 7, 0, 0],
 &#39;pos_tags&#39;: [22, 42, 16, 21, 35, 37, 16, 21, 7],
 &#39;tokens&#39;: [&#39;EU&#39;,
  &#39;rejects&#39;,
  &#39;German&#39;,
  &#39;call&#39;,
  &#39;to&#39;,
  &#39;boycott&#39;,
  &#39;British&#39;,
  &#39;lamb&#39;,
  &#39;.&#39;]&#125;
</code></pre>
<p>所有的数据标签labels都已经被编码成了整数，可以直接被预训练transformer模型使用。这些整数的编码所对应的实际类别储存在<code>features</code>中。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">datasets[<span class="string">&quot;train&quot;</span>].features[<span class="string">f&quot;ner_tags&quot;</span>]</span><br></pre></td></tr></table></figure>
<pre><code>Sequence(feature=ClassLabel(num_classes=9, names=[&#39;O&#39;, &#39;B-PER&#39;, &#39;I-PER&#39;, &#39;B-ORG&#39;, &#39;I-ORG&#39;, &#39;B-LOC&#39;, &#39;I-LOC&#39;, &#39;B-MISC&#39;, &#39;I-MISC&#39;], names_file=None, id=None), length=-1, id=None)
- &#39;PER&#39; for person
- &#39;ORG&#39; for organization
- &#39;LOC&#39; for location
- &#39;MISC&#39; for miscellaneous
‘0’的意思是没有实体。 ‘B-’前缀代表实体开始的token，‘I-’前缀代表实体中间的token。
</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">label_list = datasets[<span class="string">&quot;train&quot;</span>].features[<span class="string">f&quot;<span class="subst">&#123;task&#125;</span>_tags&quot;</span>].feature.names</span><br><span class="line">label_list</span><br></pre></td></tr></table></figure>




<pre><code>[&#39;O&#39;, &#39;B-PER&#39;, &#39;I-PER&#39;, &#39;B-ORG&#39;, &#39;I-ORG&#39;, &#39;B-LOC&#39;, &#39;I-LOC&#39;, &#39;B-MISC&#39;, &#39;I-MISC&#39;]
</code></pre>
<p>同Task06， 为了能够进一步理解数据长什么样子，下面的函数将从数据集里随机选择几个例子进行展示。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> datasets <span class="keyword">import</span> ClassLabel, <span class="type">Sequence</span></span><br><span class="line"><span class="keyword">import</span> random</span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">from</span> IPython.display <span class="keyword">import</span> display, HTML</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">show_random_elements</span>(<span class="params">dataset, num_examples=<span class="number">10</span></span>):</span></span><br><span class="line">    <span class="keyword">assert</span> num_examples &lt;= <span class="built_in">len</span>(dataset), <span class="string">&quot;Can&#x27;t pick more elements than there are in the dataset.&quot;</span></span><br><span class="line">    picks = []</span><br><span class="line">    <span class="keyword">for</span> _ <span class="keyword">in</span> <span class="built_in">range</span>(num_examples):</span><br><span class="line">        pick = random.randint(<span class="number">0</span>, <span class="built_in">len</span>(dataset)-<span class="number">1</span>)</span><br><span class="line">        <span class="keyword">while</span> pick <span class="keyword">in</span> picks:</span><br><span class="line">            pick = random.randint(<span class="number">0</span>, <span class="built_in">len</span>(dataset)-<span class="number">1</span>)</span><br><span class="line">        picks.append(pick)</span><br><span class="line">    </span><br><span class="line">    df = pd.DataFrame(dataset[picks])</span><br><span class="line">    <span class="keyword">for</span> column, typ <span class="keyword">in</span> dataset.features.items():</span><br><span class="line">        <span class="keyword">if</span> <span class="built_in">isinstance</span>(typ, ClassLabel):</span><br><span class="line">            df[column] = df[column].transform(<span class="keyword">lambda</span> i: typ.names[i])</span><br><span class="line">        <span class="keyword">elif</span> <span class="built_in">isinstance</span>(typ, <span class="type">Sequence</span>) <span class="keyword">and</span> <span class="built_in">isinstance</span>(typ.feature, ClassLabel):</span><br><span class="line">            df[column] = df[column].transform(<span class="keyword">lambda</span> x: [typ.feature.names[i] <span class="keyword">for</span> i <span class="keyword">in</span> x])</span><br><span class="line">    display(HTML(df.to_html()))</span><br></pre></td></tr></table></figure>


<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">show_random_elements(datasets[<span class="string">&quot;train&quot;</span>])</span><br></pre></td></tr></table></figure>


<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>id</th>
      <th>tokens</th>
      <th>pos_tags</th>
      <th>chunk_tags</th>
      <th>ner_tags</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>2227</td>
      <td>[Result, of, a, French, first, division, match, on, Friday, .]</td>
      <td>[NN, IN, DT, JJ, JJ, NN, NN, IN, NNP, .]</td>
      <td>[B-NP, B-PP, B-NP, I-NP, I-NP, I-NP, I-NP, B-PP, B-NP, O]</td>
      <td>[O, O, O, B-MISC, O, O, O, O, O, O]</td>
    </tr>
    <tr>
      <th>1</th>
      <td>2615</td>
      <td>[Mid-tier, golds, up, in, heavy, trading, .]</td>
      <td>[NN, NNS, IN, IN, JJ, NN, .]</td>
      <td>[B-NP, I-NP, B-PP, B-PP, B-NP, I-NP, O]</td>
      <td>[O, O, O, O, O, O, O]</td>
    </tr>
    <tr>
      <th>2</th>
      <td>10256</td>
      <td>[Neagle, (, 14-6, ), beat, the, Braves, for, the, third, time, this, season, ,, allowing, two, runs, and, six, hits, in, eight, innings, .]</td>
      <td>[NNP, (, CD, ), VB, DT, NNPS, IN, DT, JJ, NN, DT, NN, ,, VBG, CD, NNS, CC, CD, NNS, IN, CD, NN, .]</td>
      <td>[B-NP, O, B-NP, O, B-VP, B-NP, I-NP, B-PP, B-NP, I-NP, I-NP, B-NP, I-NP, O, B-VP, B-NP, I-NP, O, B-NP, I-NP, B-PP, B-NP, I-NP, O]</td>
      <td>[B-PER, O, O, O, O, O, B-ORG, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O]</td>
    </tr>
    <tr>
      <th>3</th>
      <td>10720</td>
      <td>[Hansa, Rostock, 4, 1, 2, 1, 5, 4, 5]</td>
      <td>[NNP, NNP, CD, CD, CD, CD, CD, CD, CD]</td>
      <td>[B-NP, I-NP, I-NP, I-NP, I-NP, I-NP, I-NP, I-NP, I-NP]</td>
      <td>[B-ORG, I-ORG, O, O, O, O, O, O, O]</td>
    </tr>
    <tr>
      <th>4</th>
      <td>7125</td>
      <td>[MONTREAL, 70, 59, .543, 11]</td>
      <td>[NNP, CD, CD, CD, CD]</td>
      <td>[B-NP, I-NP, I-NP, I-NP, I-NP]</td>
      <td>[B-ORG, O, O, O, O]</td>
    </tr>
    <tr>
      <th>5</th>
      <td>3316</td>
      <td>[Softbank, Corp, said, on, Friday, that, it, would, procure, $, 900, million, through, the, foreign, exchange, market, by, September, 5, as, part, of, its, acquisition, of, U.S., firm, ,, Kingston, Technology, Co, .]</td>
      <td>[NNP, NNP, VBD, IN, NNP, IN, PRP, MD, NN, $, CD, CD, IN, DT, JJ, NN, NN, IN, NNP, CD, IN, NN, IN, PRP$, NN, IN, NNP, NN, ,, NNP, NNP, NNP, .]</td>
      <td>[B-NP, I-NP, B-VP, B-PP, B-NP, B-SBAR, B-NP, B-VP, B-NP, I-NP, I-NP, I-NP, B-PP, B-NP, I-NP, I-NP, I-NP, B-PP, B-NP, I-NP, B-PP, B-NP, B-PP, B-NP, I-NP, B-PP, B-NP, I-NP, O, B-NP, I-NP, I-NP, O]</td>
      <td>[B-ORG, I-ORG, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, B-LOC, O, O, B-ORG, I-ORG, I-ORG, O]</td>
    </tr>
    <tr>
      <th>6</th>
      <td>3923</td>
      <td>[Ghent, 3, Aalst, 2]</td>
      <td>[NN, CD, NNP, CD]</td>
      <td>[B-NP, I-NP, I-NP, I-NP]</td>
      <td>[B-ORG, O, B-ORG, O]</td>
    </tr>
    <tr>
      <th>7</th>
      <td>2776</td>
      <td>[The, separatists, ,, who, swept, into, Grozny, on, August, 6, ,, still, control, large, areas, of, the, centre, of, town, ,, and, Russian, soldiers, are, based, at, checkpoints, on, the, approach, roads, .]</td>
      <td>[DT, NNS, ,, WP, VBD, IN, NNP, IN, NNP, CD, ,, RB, VBP, JJ, NNS, IN, DT, NN, IN, NN, ,, CC, JJ, NNS, VBP, VBN, IN, NNS, IN, DT, NN, NNS, .]</td>
      <td>[B-NP, I-NP, O, B-NP, B-VP, B-PP, B-NP, B-PP, B-NP, I-NP, O, B-ADVP, B-VP, B-NP, I-NP, B-PP, B-NP, I-NP, B-PP, B-NP, O, O, B-NP, I-NP, B-VP, I-VP, B-PP, B-NP, B-PP, B-NP, I-NP, I-NP, O]</td>
      <td>[O, O, O, O, O, O, B-LOC, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, B-MISC, O, O, O, O, O, O, O, O, O, O]</td>
    </tr>
    <tr>
      <th>8</th>
      <td>1178</td>
      <td>[Doctor, Masserigne, Ndiaye, said, medical, staff, were, overwhelmed, with, work, ., "]</td>
      <td>[NNP, NNP, NNP, VBD, JJ, NN, VBD, VBN, IN, NN, ., "]</td>
      <td>[B-NP, I-NP, I-NP, B-VP, B-NP, I-NP, B-VP, I-VP, B-PP, B-NP, O, O]</td>
      <td>[O, B-PER, I-PER, O, O, O, O, O, O, O, O, O]</td>
    </tr>
    <tr>
      <th>9</th>
      <td>10988</td>
      <td>[Reuters, historical, calendar, -, September, 4, .]</td>
      <td>[NNP, JJ, NN, :, NNP, CD, .]</td>
      <td>[B-NP, I-NP, I-NP, O, B-NP, I-NP, O]</td>
      <td>[B-ORG, O, O, O, O, O, O]</td>
    </tr>
  </tbody>
</table>

<h1 id="4-预处理数据"><a href="#4-预处理数据" class="headerlink" title="4 预处理数据"></a>4 预处理数据</h1><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> transformers <span class="keyword">import</span> AutoTokenizer</span><br><span class="line">    </span><br><span class="line">tokenizer = AutoTokenizer.from_pretrained(model_checkpoint)</span><br></pre></td></tr></table></figure>
<p>注意：以下代码要求tokenizer必须是transformers.PreTrainedTokenizerFast类型，因为我们在预处理的时候需要用到fast tokenizer的一些特殊特性（比如多线程快速tokenizer）。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> transformers</span><br><span class="line"><span class="keyword">assert</span> <span class="built_in">isinstance</span>(tokenizer, transformers.PreTrainedTokenizerFast)</span><br></pre></td></tr></table></figure>

<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">tokenizer(<span class="string">&quot;Hello, this is one sentence!&quot;</span>)</span><br></pre></td></tr></table></figure>




<pre><code>&#123;&#39;input_ids&#39;: [101, 7592, 1010, 2023, 2003, 2028, 6251, 999, 102], &#39;attention_mask&#39;: [1, 1, 1, 1, 1, 1, 1, 1, 1]&#125;
</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">tokenizer([<span class="string">&quot;Hello&quot;</span>, <span class="string">&quot;,&quot;</span>, <span class="string">&quot;this&quot;</span>, <span class="string">&quot;is&quot;</span>, <span class="string">&quot;one&quot;</span>, <span class="string">&quot;sentence&quot;</span>, <span class="string">&quot;split&quot;</span>, <span class="string">&quot;into&quot;</span>, <span class="string">&quot;words&quot;</span>, <span class="string">&quot;.&quot;</span>], is_split_into_words=<span class="literal">True</span>)</span><br></pre></td></tr></table></figure>




<pre><code>&#123;&#39;input_ids&#39;: [101, 7592, 1010, 2023, 2003, 2028, 6251, 3975, 2046, 2616, 1012, 102], &#39;attention_mask&#39;: [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]&#125;
</code></pre>
<h2 id="4-1-tokenizer会将word继续切分"><a href="#4-1-tokenizer会将word继续切分" class="headerlink" title="4.1 tokenizer会将word继续切分"></a>4.1 tokenizer会将word继续切分</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">example = datasets[<span class="string">&quot;train&quot;</span>][<span class="number">4</span>]</span><br><span class="line"><span class="built_in">print</span>(example[<span class="string">&quot;tokens&quot;</span>])</span><br></pre></td></tr></table></figure>

<pre><code>[&#39;Germany&#39;, &quot;&#39;s&quot;, &#39;representative&#39;, &#39;to&#39;, &#39;the&#39;, &#39;European&#39;, &#39;Union&#39;, &quot;&#39;s&quot;, &#39;veterinary&#39;, &#39;committee&#39;, &#39;Werner&#39;, &#39;Zwingmann&#39;, &#39;said&#39;, &#39;on&#39;, &#39;Wednesday&#39;, &#39;consumers&#39;, &#39;should&#39;, &#39;buy&#39;, &#39;sheepmeat&#39;, &#39;from&#39;, &#39;countries&#39;, &#39;other&#39;, &#39;than&#39;, &#39;Britain&#39;, &#39;until&#39;, &#39;the&#39;, &#39;scientific&#39;, &#39;advice&#39;, &#39;was&#39;, &#39;clearer&#39;, &#39;.&#39;]
</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">tokenized_input = tokenizer(example[<span class="string">&quot;tokens&quot;</span>], is_split_into_words=<span class="literal">True</span>)</span><br><span class="line">tokens = tokenizer.convert_ids_to_tokens(tokenized_input[<span class="string">&quot;input_ids&quot;</span>])</span><br><span class="line"><span class="built_in">print</span>(tokens)</span><br></pre></td></tr></table></figure>

<pre><code>[&#39;[CLS]&#39;, &#39;germany&#39;, &quot;&#39;&quot;, &#39;s&#39;, &#39;representative&#39;, &#39;to&#39;, &#39;the&#39;, &#39;european&#39;, &#39;union&#39;, &quot;&#39;&quot;, &#39;s&#39;, &#39;veterinary&#39;, &#39;committee&#39;, &#39;werner&#39;, &#39;z&#39;, &#39;##wing&#39;, &#39;##mann&#39;, &#39;said&#39;, &#39;on&#39;, &#39;wednesday&#39;, &#39;consumers&#39;, &#39;should&#39;, &#39;buy&#39;, &#39;sheep&#39;, &#39;##me&#39;, &#39;##at&#39;, &#39;from&#39;, &#39;countries&#39;, &#39;other&#39;, &#39;than&#39;, &#39;britain&#39;, &#39;until&#39;, &#39;the&#39;, &#39;scientific&#39;, &#39;advice&#39;, &#39;was&#39;, &#39;clearer&#39;, &#39;.&#39;, &#39;[SEP]&#39;]
</code></pre>
<h2 id="4-2-对切分后的token与原word对齐"><a href="#4-2-对切分后的token与原word对齐" class="headerlink" title="4.2 对切分后的token与原word对齐"></a>4.2 对切分后的token与原word对齐</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">print</span>(tokenized_input.word_ids())</span><br><span class="line"><span class="comment"># word_ids方法能将subtokens和words还有标注的labels对齐。</span></span><br></pre></td></tr></table></figure>

<pre><code>[None, 0, 1, 1, 2, 3, 4, 5, 6, 7, 7, 8, 9, 10, 11, 11, 11, 12, 13, 14, 15, 16, 17, 18, 18, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, None]
</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">word_ids = tokenized_input.word_ids()</span><br><span class="line">aligned_labels = [-<span class="number">100</span> <span class="keyword">if</span> i <span class="keyword">is</span> <span class="literal">None</span> <span class="keyword">else</span> example[<span class="string">f&quot;<span class="subst">&#123;task&#125;</span>_tags&quot;</span>][i] <span class="keyword">for</span> i <span class="keyword">in</span> word_ids]</span><br><span class="line"><span class="built_in">print</span>(<span class="built_in">len</span>(aligned_labels), <span class="built_in">len</span>(tokenized_input[<span class="string">&quot;input_ids&quot;</span>]))</span><br></pre></td></tr></table></figure>

<pre><code>39 39
</code></pre>
<p>两种对齐label的方式：</p>
<ul>
<li>多个subtokens对齐一个word，对齐一个label</li>
<li>多个subtokens的第一个subtoken对齐word，对齐一个label，其他subtokens直接赋予-100.</li>
</ul>
<h2 id="4-3-整合预处理函数"><a href="#4-3-整合预处理函数" class="headerlink" title="4.3 整合预处理函数"></a>4.3 整合预处理函数</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">##？？？？</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">tokenize_and_align_labels</span>(<span class="params">examples</span>):</span></span><br><span class="line">    tokenized_inputs = tokenizer(examples[<span class="string">&quot;tokens&quot;</span>], truncation=<span class="literal">True</span>, is_split_into_words=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line">    labels = []</span><br><span class="line">    <span class="keyword">for</span> i, label <span class="keyword">in</span> <span class="built_in">enumerate</span>(examples[<span class="string">f&quot;<span class="subst">&#123;task&#125;</span>_tags&quot;</span>]):</span><br><span class="line">        word_ids = tokenized_inputs.word_ids(batch_index=i)</span><br><span class="line">        previous_word_idx = <span class="literal">None</span></span><br><span class="line">        label_ids = []</span><br><span class="line">        <span class="keyword">for</span> word_idx <span class="keyword">in</span> word_ids:</span><br><span class="line">            <span class="comment"># Special tokens have a word id that is None. We set the label to -100 so they are automatically</span></span><br><span class="line">            <span class="comment"># ignored in the loss function.</span></span><br><span class="line">            <span class="keyword">if</span> word_idx <span class="keyword">is</span> <span class="literal">None</span>:</span><br><span class="line">                label_ids.append(-<span class="number">100</span>)</span><br><span class="line">            <span class="comment"># We set the label for the first token of each word.</span></span><br><span class="line">            <span class="keyword">elif</span> word_idx != previous_word_idx:</span><br><span class="line">                label_ids.append(label[word_idx])</span><br><span class="line">            <span class="comment"># For the other tokens in a word, we set the label to either the current label or -100, depending on</span></span><br><span class="line">            <span class="comment"># the label_all_tokens flag.</span></span><br><span class="line">            <span class="keyword">else</span>:</span><br><span class="line">                label_ids.append(label[word_idx] <span class="keyword">if</span> label_all_tokens <span class="keyword">else</span> -<span class="number">100</span>)</span><br><span class="line">            previous_word_idx = word_idx</span><br><span class="line"></span><br><span class="line">        labels.append(label_ids)</span><br><span class="line"></span><br><span class="line">    tokenized_inputs[<span class="string">&quot;labels&quot;</span>] = labels</span><br><span class="line">    <span class="keyword">return</span> tokenized_inputs</span><br></pre></td></tr></table></figure>

<p>以上的预处理函数可以处理一个样本，也可以处理多个样本exapmles。如果是处理多个样本，则返回的是多个样本被预处理之后的结果list。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">tokenize_and_align_labels(datasets[<span class="string">&#x27;train&#x27;</span>][:<span class="number">5</span>])</span><br></pre></td></tr></table></figure>


<pre><code>&#123;&#39;input_ids&#39;: [[101, 7327, 19164, 2446, 2655, 2000, 17757, 2329, 12559, 1012, 102], [101, 2848, 13934, 102], [101, 9371, 2727, 1011, 5511, 1011, 2570, 102], [101, 1996, 2647, 3222, 2056, 2006, 9432, 2009, 18335, 2007, 2446, 6040, 2000, 10390, 2000, 18454, 2078, 2329, 12559, 2127, 6529, 5646, 3251, 5506, 11190, 4295, 2064, 2022, 11860, 2000, 8351, 1012, 102], [101, 2762, 1005, 1055, 4387, 2000, 1996, 2647, 2586, 1005, 1055, 15651, 2837, 14121, 1062, 9328, 5804, 2056, 2006, 9317, 10390, 2323, 4965, 8351, 4168, 4017, 2013, 3032, 2060, 2084, 3725, 2127, 1996, 4045, 6040, 2001, 24509, 1012, 102]], &#39;attention_mask&#39;: [[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]], &#39;labels&#39;: [[-100, 3, 0, 7, 0, 0, 0, 7, 0, 0, -100], [-100, 1, 2, -100], [-100, 5, 0, 0, 0, 0, 0, -100], [-100, 0, 3, 4, 0, 0, 0, 0, 0, 0, 7, 0, 0, 0, 0, 0, 0, 7, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, -100], [-100, 5, 0, 0, 0, 0, 0, 3, 4, 0, 0, 0, 0, 1, 2, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 5, 0, 0, 0, 0, 0, 0, 0, -100]]&#125;
</code></pre>
<p>接下来对数据集datasets里面的所有样本进行预处理，处理的方式是使用map函数，将预处理函数prepare_train_features应用到（map)所有样本上。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">tokenized_datasets = datasets.<span class="built_in">map</span>(tokenize_and_align_labels, batched=<span class="literal">True</span>)</span><br></pre></td></tr></table></figure>

<h1 id="5-微调预训练模型"><a href="#5-微调预训练模型" class="headerlink" title="5 微调预训练模型"></a>5 微调预训练模型</h1><h2 id="5-1-设置Trainer"><a href="#5-1-设置Trainer" class="headerlink" title="5.1 设置Trainer"></a>5.1 设置Trainer</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"><span class="keyword">from</span> transformers <span class="keyword">import</span> AutoModelForTokenClassification, TrainingArguments, Trainer</span><br><span class="line"></span><br><span class="line">model = AutoModelForTokenClassification.from_pretrained(model_checkpoint, num_labels=<span class="built_in">len</span>(label_list))</span><br><span class="line"><span class="comment"># 使用`AutoModelForTokenClassification` 这个类做seq2seq任务</span></span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 同Task06</span></span><br><span class="line">args = TrainingArguments(</span><br><span class="line">    <span class="string">f&quot;test-<span class="subst">&#123;task&#125;</span>&quot;</span>,</span><br><span class="line">    evaluation_strategy = <span class="string">&quot;epoch&quot;</span>,</span><br><span class="line">    learning_rate=<span class="number">2e-5</span>,</span><br><span class="line">    per_device_train_batch_size=batch_size,</span><br><span class="line">    per_device_eval_batch_size=batch_size,</span><br><span class="line">    num_train_epochs=<span class="number">3</span>,</span><br><span class="line">    weight_decay=<span class="number">0.01</span>,</span><br><span class="line">)</span><br></pre></td></tr></table></figure>

<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> transformers <span class="keyword">import</span> DataCollatorForTokenClassification</span><br><span class="line"></span><br><span class="line">data_collator = DataCollatorForTokenClassification(tokenizer)</span><br><span class="line"><span class="comment"># 需要一个数据收集器data collator，将处理好的输入喂给模型</span></span><br></pre></td></tr></table></figure>

<h2 id="5-2-设置评估方法"><a href="#5-2-设置评估方法" class="headerlink" title="5.2 设置评估方法"></a>5.2 设置评估方法</h2><p>使用<a target="_blank" rel="noopener" href="https://github.com/chakki-works/seqeval"><code>seqeval</code></a> metric来完成评估。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">metric = load_metric(<span class="string">&quot;seqeval&quot;</span>)</span><br></pre></td></tr></table></figure>

<p>评估的输入是预测和label的list</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">labels = [label_list[i] <span class="keyword">for</span> i <span class="keyword">in</span> example[<span class="string">f&quot;<span class="subst">&#123;task&#125;</span>_tags&quot;</span>]]</span><br><span class="line">metric.compute(predictions=[labels], references=[labels])</span><br></pre></td></tr></table></figure>




<pre><code>&#123;&#39;LOC&#39;: &#123;&#39;f1&#39;: 1.0, &#39;number&#39;: 2, &#39;precision&#39;: 1.0, &#39;recall&#39;: 1.0&#125;,
 &#39;ORG&#39;: &#123;&#39;f1&#39;: 1.0, &#39;number&#39;: 1, &#39;precision&#39;: 1.0, &#39;recall&#39;: 1.0&#125;,
 &#39;PER&#39;: &#123;&#39;f1&#39;: 1.0, &#39;number&#39;: 1, &#39;precision&#39;: 1.0, &#39;recall&#39;: 1.0&#125;,
 &#39;overall_accuracy&#39;: 1.0,
 &#39;overall_f1&#39;: 1.0,
 &#39;overall_precision&#39;: 1.0,
 &#39;overall_recall&#39;: 1.0&#125;
</code></pre>
<p>对模型预测结果做一些后处理：</p>
<ul>
<li>选择预测分类最大概率的下标</li>
<li>将下标转化为label</li>
<li>忽略-100所在地方</li>
</ul>
<h2 id="5-3-将参数设置和评估方法两步整合起来"><a href="#5-3-将参数设置和评估方法两步整合起来" class="headerlink" title="5.3 将参数设置和评估方法两步整合起来"></a>5.3 将参数设置和评估方法两步整合起来</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">compute_metrics</span>(<span class="params">p</span>):</span></span><br><span class="line">    predictions, labels = p</span><br><span class="line">    predictions = np.argmax(predictions, axis=<span class="number">2</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># Remove ignored index (special tokens)</span></span><br><span class="line">    true_predictions = [</span><br><span class="line">        [label_list[p] <span class="keyword">for</span> (p, l) <span class="keyword">in</span> <span class="built_in">zip</span>(prediction, label) <span class="keyword">if</span> l != -<span class="number">100</span>]</span><br><span class="line">        <span class="keyword">for</span> prediction, label <span class="keyword">in</span> <span class="built_in">zip</span>(predictions, labels)</span><br><span class="line">    ]</span><br><span class="line">    true_labels = [</span><br><span class="line">        [label_list[l] <span class="keyword">for</span> (p, l) <span class="keyword">in</span> <span class="built_in">zip</span>(prediction, label) <span class="keyword">if</span> l != -<span class="number">100</span>]</span><br><span class="line">        <span class="keyword">for</span> prediction, label <span class="keyword">in</span> <span class="built_in">zip</span>(predictions, labels)</span><br><span class="line">    ]</span><br><span class="line"></span><br><span class="line">    results = metric.compute(predictions=true_predictions, references=true_labels)</span><br><span class="line">    <span class="keyword">return</span> &#123;</span><br><span class="line">        <span class="string">&quot;precision&quot;</span>: results[<span class="string">&quot;overall_precision&quot;</span>],</span><br><span class="line">        <span class="string">&quot;recall&quot;</span>: results[<span class="string">&quot;overall_recall&quot;</span>],</span><br><span class="line">        <span class="string">&quot;f1&quot;</span>: results[<span class="string">&quot;overall_f1&quot;</span>],</span><br><span class="line">        <span class="string">&quot;accuracy&quot;</span>: results[<span class="string">&quot;overall_accuracy&quot;</span>],</span><br><span class="line">    &#125;</span><br></pre></td></tr></table></figure>


<p>我们计算所有类别总的precision/recall/f1，所以会扔掉单个类别的precision/recall/f1 </p>
<p>将数据/模型/参数传入<code>Trainer</code>即可</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">trainer = Trainer(</span><br><span class="line">    model,</span><br><span class="line">    args,</span><br><span class="line">    train_dataset=tokenized_datasets[<span class="string">&quot;train&quot;</span>],</span><br><span class="line">    eval_dataset=tokenized_datasets[<span class="string">&quot;validation&quot;</span>],</span><br><span class="line">    data_collator=data_collator,</span><br><span class="line">    tokenizer=tokenizer,</span><br><span class="line">    compute_metrics=compute_metrics</span><br><span class="line">)</span><br></pre></td></tr></table></figure>

<p>调用<code>train</code>方法开始训练</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">trainer.train()</span><br></pre></td></tr></table></figure>



  <div>
      <style>
          /* Turns off some styling */
          progress {
              /* gets rid of default border in Firefox and Opera. */
              border: none;
              /* Needs to be in here for Safari polyfill so background images work as expected. */
              background-size: auto;
          }
      </style>

<p>  <progress value='2634' max='2634' style='width:300px; height:20px; vertical-align: middle;'></progress><br>  [2634/2634 01:45, Epoch 3/3]<br>  </div><br>  <table border="1" class="dataframe"></p>
<thead>
  <tr style="text-align: left;">
    <th>Epoch</th>
    <th>Training Loss</th>
    <th>Validation Loss</th>
    <th>Precision</th>
    <th>Recall</th>
    <th>F1</th>
    <th>Accuracy</th>
  </tr>
</thead>
<tbody>
  <tr>
    <td>1</td>
    <td>0.237721</td>
    <td>0.068198</td>
    <td>0.903148</td>
    <td>0.921132</td>
    <td>0.912051</td>
    <td>0.979713</td>
  </tr>
  <tr>
    <td>2</td>
    <td>0.053160</td>
    <td>0.059337</td>
    <td>0.927697</td>
    <td>0.932990</td>
    <td>0.930336</td>
    <td>0.983113</td>
  </tr>
  <tr>
    <td>3</td>
    <td>0.029850</td>
    <td>0.059346</td>
    <td>0.929267</td>
    <td>0.939143</td>
    <td>0.934179</td>
    <td>0.984257</td>
  </tr>
</tbody>
</table><p>





<pre><code>TrainOutput(global_step=2634, training_loss=0.08569671253227518)
</code></pre>
<h1 id="6-对模型进行评估"><a href="#6-对模型进行评估" class="headerlink" title="6 对模型进行评估"></a>6 对模型进行评估</h1><h2 id="6-1-对总类别进行评估"><a href="#6-1-对总类别进行评估" class="headerlink" title="6.1 对总类别进行评估"></a>6.1 对总类别进行评估</h2><p>我们可以再次使用<code>evaluate</code>方法评估，可以评估其他数据集。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">trainer.evaluate()</span><br></pre></td></tr></table></figure>



<div>
    <style>
        /* Turns off some styling */
        progress {
            /* gets rid of default border in Firefox and Opera. */
            border: none;
            /* Needs to be in here for Safari polyfill so background images work as expected. */
            background-size: auto;
        }
    </style>

<p>  <progress value='408' max='204' style='width:300px; height:20px; vertical-align: middle;'></progress><br>  [204/204 00:05]</p>
</div>






<pre><code>&#123;&#39;eval_loss&#39;: 0.05934586375951767,
 &#39;eval_precision&#39;: 0.9292672127518264,
 &#39;eval_recall&#39;: 0.9391430808815304,
 &#39;eval_f1&#39;: 0.9341790463472988,
 &#39;eval_accuracy&#39;: 0.9842565968195466,
 &#39;epoch&#39;: 3.0&#125;
</code></pre>
<h2 id="6-2-对单个类别进行评估"><a href="#6-2-对单个类别进行评估" class="headerlink" title="6.2 对单个类别进行评估"></a>6.2 对单个类别进行评估</h2><p>如果想要得到单个类别的precision/recall/f1，我们直接将结果输入相同的评估函数即可：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">predictions, labels, _ = trainer.predict(tokenized_datasets[<span class="string">&quot;validation&quot;</span>])</span><br><span class="line">predictions = np.argmax(predictions, axis=<span class="number">2</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Remove ignored index (special tokens)</span></span><br><span class="line">true_predictions = [</span><br><span class="line">    [label_list[p] <span class="keyword">for</span> (p, l) <span class="keyword">in</span> <span class="built_in">zip</span>(prediction, label) <span class="keyword">if</span> l != -<span class="number">100</span>]</span><br><span class="line">    <span class="keyword">for</span> prediction, label <span class="keyword">in</span> <span class="built_in">zip</span>(predictions, labels)</span><br><span class="line">]</span><br><span class="line">true_labels = [</span><br><span class="line">    [label_list[l] <span class="keyword">for</span> (p, l) <span class="keyword">in</span> <span class="built_in">zip</span>(prediction, label) <span class="keyword">if</span> l != -<span class="number">100</span>]</span><br><span class="line">    <span class="keyword">for</span> prediction, label <span class="keyword">in</span> <span class="built_in">zip</span>(predictions, labels)</span><br><span class="line">]</span><br><span class="line"></span><br><span class="line">results = metric.compute(predictions=true_predictions, references=true_labels)</span><br><span class="line">results</span><br></pre></td></tr></table></figure>




<pre><code>&#123;&#39;LOC&#39;: &#123;&#39;precision&#39;: 0.949718574108818,
  &#39;recall&#39;: 0.966768525592055,
  &#39;f1&#39;: 0.9581677077418134,
  &#39;number&#39;: 2618&#125;,
 &#39;MISC&#39;: &#123;&#39;precision&#39;: 0.8132387706855791,
  &#39;recall&#39;: 0.8383428107229894,
  &#39;f1&#39;: 0.8255999999999999,
  &#39;number&#39;: 1231&#125;,
 &#39;ORG&#39;: &#123;&#39;precision&#39;: 0.9055232558139535,
  &#39;recall&#39;: 0.9090466926070039,
  &#39;f1&#39;: 0.9072815533980583,
  &#39;number&#39;: 2056&#125;,
 &#39;PER&#39;: &#123;&#39;precision&#39;: 0.9759552042160737,
  &#39;recall&#39;: 0.9765985497692815,
  &#39;f1&#39;: 0.9762767710049424,
  &#39;number&#39;: 3034&#125;,
 &#39;overall_precision&#39;: 0.9292672127518264,
 &#39;overall_recall&#39;: 0.9391430808815304,
 &#39;overall_f1&#39;: 0.9341790463472988,
 &#39;overall_accuracy&#39;: 0.9842565968195466&#125;
</code></pre>
<h1 id="7-将训练好的自己的模型上传到Model-Hub"><a href="#7-将训练好的自己的模型上传到Model-Hub" class="headerlink" title="7 将训练好的自己的模型上传到Model-Hub"></a>7 将训练好的自己的模型上传到Model-Hub</h1><p>最后别忘了，查看如何上传模型 ，上传模型到](<a target="_blank" rel="noopener" href="https://huggingface.co/transformers/model_sharing.html">https://huggingface.co/transformers/model_sharing.html</a>) 到<a target="_blank" rel="noopener" href="https://huggingface.co/models">🤗 Model Hub</a>。随后您就可以像这个notebook一开始一样，直接用模型名字就能使用您自己上传的模型啦。</p>
<h1 id="8-参考文献"><a href="#8-参考文献" class="headerlink" title="8 参考文献"></a>8 参考文献</h1><ol>
<li>DataWhale开源文档：<a target="_blank" rel="noopener" href="https://github.com/datawhalechina/learn-nlp-with-transformers">https://github.com/datawhalechina/learn-nlp-with-transformers</a></li>
<li>“Relph Hu”个人博客：<a target="_blank" rel="noopener" href="https://relph1119.github.io/my-team-learning/#/transformers_nlp28/task07">https://relph1119.github.io/my-team-learning/#/transformers_nlp28/task07</a></li>
</ol>

    </div>

    
    
    

      <footer class="post-footer">

        


        
    <div class="post-nav">
      <div class="post-nav-item">
    <a href="/2021/08/27/Task06-Transformers%E8%A7%A3%E5%86%B3%E6%96%87%E6%9C%AC%E5%88%86%E7%B1%BB%E4%BB%BB%E5%8A%A1%E3%80%81%E8%B6%85%E5%8F%82%E6%90%9C%E7%B4%A2/" rel="prev" title="Transformers解决文本分类任务、超参搜索">
      <i class="fa fa-chevron-left"></i> Transformers解决文本分类任务、超参搜索
    </a></div>
      <div class="post-nav-item"></div>
    </div>
      </footer>
    
  </article>
  
  
  



          </div>
          

<script>
  window.addEventListener('tabs:register', () => {
    let { activeClass } = CONFIG.comments;
    if (CONFIG.comments.storage) {
      activeClass = localStorage.getItem('comments_active') || activeClass;
    }
    if (activeClass) {
      let activeTab = document.querySelector(`a[href="#comment-${activeClass}"]`);
      if (activeTab) {
        activeTab.click();
      }
    }
  });
  if (CONFIG.comments.storage) {
    window.addEventListener('tabs:click', event => {
      if (!event.target.matches('.tabs-comment .tab-content .tab-pane')) return;
      let commentClass = event.target.classList[1];
      localStorage.setItem('comments_active', commentClass);
    });
  }
</script>

        </div>
          
  
  <div class="toggle sidebar-toggle">
    <span class="toggle-line toggle-line-first"></span>
    <span class="toggle-line toggle-line-middle"></span>
    <span class="toggle-line toggle-line-last"></span>
  </div>

  <aside class="sidebar">
    <div class="sidebar-inner">

      <ul class="sidebar-nav motion-element">
        <li class="sidebar-nav-toc">
          Table of Contents
        </li>
        <li class="sidebar-nav-overview">
          Overview
        </li>
      </ul>

      <!--noindex-->
      <div class="post-toc-wrap sidebar-panel">
          <div class="post-toc motion-element"><ol class="nav"><li class="nav-item nav-level-1"><a class="nav-link" href="#0-%E6%80%BB%E7%BB%93"><span class="nav-number">1.</span> <span class="nav-text">0 总结</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#1-%E5%BA%8F%E5%88%97%E6%A0%87%E6%B3%A8%E4%BB%BB%E5%8A%A1%E7%AE%80%E4%BB%8B"><span class="nav-number">2.</span> <span class="nav-text">1 序列标注任务简介</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#2-%E9%80%89%E6%8B%A9%E4%B8%80%E7%A7%8D%E5%88%86%E7%B1%BB%E4%BB%BB%E5%8A%A1"><span class="nav-number">3.</span> <span class="nav-text">2 选择一种分类任务</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#3-%E5%8A%A0%E8%BD%BD%E6%95%B0%E6%8D%AE%E5%8F%8A%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90"><span class="nav-number">4.</span> <span class="nav-text">3 加载数据及数据分析</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#3-1-%E5%8A%A0%E8%BD%BD%E6%95%B0%E6%8D%AE"><span class="nav-number">4.1.</span> <span class="nav-text">3.1 加载数据</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#3-2-%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90"><span class="nav-number">4.2.</span> <span class="nav-text">3.2 数据分析</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#4-%E9%A2%84%E5%A4%84%E7%90%86%E6%95%B0%E6%8D%AE"><span class="nav-number">5.</span> <span class="nav-text">4 预处理数据</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#4-1-tokenizer%E4%BC%9A%E5%B0%86word%E7%BB%A7%E7%BB%AD%E5%88%87%E5%88%86"><span class="nav-number">5.1.</span> <span class="nav-text">4.1 tokenizer会将word继续切分</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#4-2-%E5%AF%B9%E5%88%87%E5%88%86%E5%90%8E%E7%9A%84token%E4%B8%8E%E5%8E%9Fword%E5%AF%B9%E9%BD%90"><span class="nav-number">5.2.</span> <span class="nav-text">4.2 对切分后的token与原word对齐</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#4-3-%E6%95%B4%E5%90%88%E9%A2%84%E5%A4%84%E7%90%86%E5%87%BD%E6%95%B0"><span class="nav-number">5.3.</span> <span class="nav-text">4.3 整合预处理函数</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#5-%E5%BE%AE%E8%B0%83%E9%A2%84%E8%AE%AD%E7%BB%83%E6%A8%A1%E5%9E%8B"><span class="nav-number">6.</span> <span class="nav-text">5 微调预训练模型</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#5-1-%E8%AE%BE%E7%BD%AETrainer"><span class="nav-number">6.1.</span> <span class="nav-text">5.1 设置Trainer</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#5-2-%E8%AE%BE%E7%BD%AE%E8%AF%84%E4%BC%B0%E6%96%B9%E6%B3%95"><span class="nav-number">6.2.</span> <span class="nav-text">5.2 设置评估方法</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#5-3-%E5%B0%86%E5%8F%82%E6%95%B0%E8%AE%BE%E7%BD%AE%E5%92%8C%E8%AF%84%E4%BC%B0%E6%96%B9%E6%B3%95%E4%B8%A4%E6%AD%A5%E6%95%B4%E5%90%88%E8%B5%B7%E6%9D%A5"><span class="nav-number">6.3.</span> <span class="nav-text">5.3 将参数设置和评估方法两步整合起来</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#6-%E5%AF%B9%E6%A8%A1%E5%9E%8B%E8%BF%9B%E8%A1%8C%E8%AF%84%E4%BC%B0"><span class="nav-number">7.</span> <span class="nav-text">6 对模型进行评估</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#6-1-%E5%AF%B9%E6%80%BB%E7%B1%BB%E5%88%AB%E8%BF%9B%E8%A1%8C%E8%AF%84%E4%BC%B0"><span class="nav-number">7.1.</span> <span class="nav-text">6.1 对总类别进行评估</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#6-2-%E5%AF%B9%E5%8D%95%E4%B8%AA%E7%B1%BB%E5%88%AB%E8%BF%9B%E8%A1%8C%E8%AF%84%E4%BC%B0"><span class="nav-number">7.2.</span> <span class="nav-text">6.2 对单个类别进行评估</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#7-%E5%B0%86%E8%AE%AD%E7%BB%83%E5%A5%BD%E7%9A%84%E8%87%AA%E5%B7%B1%E7%9A%84%E6%A8%A1%E5%9E%8B%E4%B8%8A%E4%BC%A0%E5%88%B0Model-Hub"><span class="nav-number">8.</span> <span class="nav-text">7 将训练好的自己的模型上传到Model-Hub</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#8-%E5%8F%82%E8%80%83%E6%96%87%E7%8C%AE"><span class="nav-number">9.</span> <span class="nav-text">8 参考文献</span></a></li></ol></div>
      </div>
      <!--/noindex-->

      <div class="site-overview-wrap sidebar-panel">
        <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
  <p class="site-author-name" itemprop="name">Ming Qin</p>
  <div class="site-description" itemprop="description"></div>
</div>
<div class="site-state-wrap motion-element">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
          <a href="/archives/">
        
          <span class="site-state-item-count">11</span>
          <span class="site-state-item-name">posts</span>
        </a>
      </div>
      <div class="site-state-item site-state-tags">
        <span class="site-state-item-count">4</span>
        <span class="site-state-item-name">tags</span>
      </div>
  </nav>
</div>



      </div>

    </div>
  </aside>
  <div id="sidebar-dimmer"></div>


      </div>
    </main>

    <footer class="footer">
      <div class="footer-inner">
        

        

<div class="copyright">
  
  &copy; 
  <span itemprop="copyrightYear">2021</span>
  <span class="with-love">
    <i class="fa fa-heart"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">Ming Qin</span>
</div>
  <div class="powered-by">Powered by <a href="https://hexo.io/" class="theme-link" rel="noopener" target="_blank">Hexo</a> & <a href="https://muse.theme-next.org/" class="theme-link" rel="noopener" target="_blank">NexT.Muse</a>
  </div>

        








      </div>
    </footer>
  </div>

  
  <script src="/lib/anime.min.js"></script>
  <script src="/lib/velocity/velocity.min.js"></script>
  <script src="/lib/velocity/velocity.ui.min.js"></script>

<script src="/js/utils.js"></script>

<script src="/js/motion.js"></script>


<script src="/js/schemes/muse.js"></script>


<script src="/js/next-boot.js"></script>




  















  

  

</body>
</html>
