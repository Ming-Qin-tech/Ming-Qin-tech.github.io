<?xml version="1.0" encoding="utf-8"?>
<search> 
  
    
    <entry>
      <title><![CDATA[Task07-Transformerè§£å†³åºåˆ—æ ‡æ³¨é—®é¢˜]]></title>
      <url>/2021/08/27/Task07-Transformer%E8%A7%A3%E5%86%B3%E5%BA%8F%E5%88%97%E6%A0%87%E6%B3%A8%E9%97%AE%E9%A2%98/</url>
      <content type="html"><![CDATA[<h1 id="0-æ€»ç»“"><a href="#0-æ€»ç»“" class="headerlink" title="0 æ€»ç»“"></a>0 æ€»ç»“</h1><p>ç‰ˆæœ¬é—®é¢˜å¯¼è‡´evaluateæ­¥éª¤å‡ºé”™<br>åºåˆ—æ ‡æ³¨ä»»åŠ¡å’Œæ–‡æœ¬åˆ†ç±»ä»»åŠ¡ç›¸æ¯”ï¼Œåªæ˜¯åœ¨æœ€åä¸€å±‚æœ‰æ‰€æ”¹åŠ¨</p>
<h1 id="1-åºåˆ—æ ‡æ³¨ä»»åŠ¡ç®€ä»‹"><a href="#1-åºåˆ—æ ‡æ³¨ä»»åŠ¡ç®€ä»‹" class="headerlink" title="1 åºåˆ—æ ‡æ³¨ä»»åŠ¡ç®€ä»‹"></a>1 åºåˆ—æ ‡æ³¨ä»»åŠ¡ç®€ä»‹</h1><p>å¸¸è§çš„ä¸‰ç§tokençº§åˆ«çš„åˆ†ç±»ä»»åŠ¡ï¼š</p>
<ul>
<li>NERï¼Œæ ‡æ³¨ personã€organization\location ç­‰</li>
<li>POS(Part-of-speech taggingï¼Œè¯æ€§æ ‡æ³¨) ï¼š åè¯ã€åŠ¨è¯å’Œå½¢å®¹è¯ç­‰</li>
<li>Chunkï¼ˆChunkingçŸ­è¯­ç»„å—ï¼‰ï¼šå°†åŒä¸€çŸ­è¯­çš„tokenç»„å—æ”¾åœ¨ä¸€èµ·ã€‚</li>
</ul>
<p>æ³¨æ„æ ¹æ®GPUæ˜¾å­˜è°ƒæ•´batch size çš„å¤§å°</p>
<h1 id="2-é€‰æ‹©ä¸€ç§åˆ†ç±»ä»»åŠ¡"><a href="#2-é€‰æ‹©ä¸€ç§åˆ†ç±»ä»»åŠ¡" class="headerlink" title="2 é€‰æ‹©ä¸€ç§åˆ†ç±»ä»»åŠ¡"></a>2 é€‰æ‹©ä¸€ç§åˆ†ç±»ä»»åŠ¡</h1><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">task = <span class="string">&quot;ner&quot;</span> <span class="comment">#éœ€è¦æ˜¯&quot;ner&quot;, &quot;pos&quot; æˆ–è€… &quot;chunk&quot;</span></span><br><span class="line">model_checkpoint = <span class="string">&quot;distilbert-base-uncased&quot;</span></span><br><span class="line">batch_size = <span class="number">16</span></span><br></pre></td></tr></table></figure>

<h1 id="3-åŠ è½½æ•°æ®åŠæ•°æ®åˆ†æ"><a href="#3-åŠ è½½æ•°æ®åŠæ•°æ®åˆ†æ" class="headerlink" title="3 åŠ è½½æ•°æ®åŠæ•°æ®åˆ†æ"></a>3 åŠ è½½æ•°æ®åŠæ•°æ®åˆ†æ</h1><h2 id="3-1-åŠ è½½æ•°æ®"><a href="#3-1-åŠ è½½æ•°æ®" class="headerlink" title="3.1 åŠ è½½æ•°æ®"></a>3.1 åŠ è½½æ•°æ®</h2><p>åŒTask06</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> datasets <span class="keyword">import</span> load_dataset, load_metric</span><br></pre></td></tr></table></figure>
<p>åŠ è½½æ•°æ®å®˜æ–¹æŒ‡å—ï¼š<a href="https://huggingface.co/docs/datasets/loading_datasets.html#from-local-files">æ•°æ®é›†æ–‡æ¡£</a></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">datasets = load_dataset(<span class="string">&quot;conll2003&quot;</span>)</span><br><span class="line"><span class="comment"># æ­¤å¤„åŠ è½½[CONLL 2003 dataset](https://www.aclweb.org/anthology/W03-0419.pdf)æ•°æ®é›†ã€‚</span></span><br></pre></td></tr></table></figure>

<h2 id="3-2-æ•°æ®åˆ†æ"><a href="#3-2-æ•°æ®åˆ†æ" class="headerlink" title="3.2 æ•°æ®åˆ†æ"></a>3.2 æ•°æ®åˆ†æ</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">datasets</span><br></pre></td></tr></table></figure>




<pre><code>DatasetDict(&#123;
    train: Dataset(&#123;
        features: [&#39;id&#39;, &#39;tokens&#39;, &#39;pos_tags&#39;, &#39;chunk_tags&#39;, &#39;ner_tags&#39;],
        num_rows: 14041
    &#125;)
    validation: Dataset(&#123;
        features: [&#39;id&#39;, &#39;tokens&#39;, &#39;pos_tags&#39;, &#39;chunk_tags&#39;, &#39;ner_tags&#39;],
        num_rows: 3250
    &#125;)
    test: Dataset(&#123;
        features: [&#39;id&#39;, &#39;tokens&#39;, &#39;pos_tags&#39;, &#39;chunk_tags&#39;, &#39;ner_tags&#39;],
        num_rows: 3453
    &#125;)
&#125;)
</code></pre>
<p>â€˜datasetsâ€™æœ¬èº«æ˜¯ä¸€ç§<a href="https://huggingface.co/docs/datasets/package_reference/main_classes.html#datasetdict"><code>DatasetDict</code></a>æ•°æ®ç»“æ„.æ‹¥æœ‰ï¼š</p>
<ul>
<li>è®­ç»ƒé›†</li>
<li>éªŒè¯é›†</li>
<li>æµ‹è¯•é›†<br>åªéœ€è¦ä½¿ç”¨å¯¹åº”çš„keyï¼ˆtrainï¼Œvalidationï¼Œsetï¼‰å³å¯å¾—åˆ°å¯¹åº”æ•°æ®ã€‚</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">datasets[<span class="string">&quot;train&quot;</span>][<span class="number">0</span>]</span><br><span class="line"><span class="comment"># ç»™å®šä¸€ä¸ªæ•°æ®åˆ‡åˆ†çš„keyï¼ˆtrainã€validationæˆ–è€…testï¼‰å’Œä¸‹æ ‡å³å¯æŸ¥çœ‹æ•°æ®ã€‚</span></span><br></pre></td></tr></table></figure>




<pre><code>&#123;&#39;chunk_tags&#39;: [11, 21, 11, 12, 21, 22, 11, 12, 0],
 &#39;id&#39;: &#39;0&#39;,
 &#39;ner_tags&#39;: [3, 0, 7, 0, 0, 0, 7, 0, 0],
 &#39;pos_tags&#39;: [22, 42, 16, 21, 35, 37, 16, 21, 7],
 &#39;tokens&#39;: [&#39;EU&#39;,
  &#39;rejects&#39;,
  &#39;German&#39;,
  &#39;call&#39;,
  &#39;to&#39;,
  &#39;boycott&#39;,
  &#39;British&#39;,
  &#39;lamb&#39;,
  &#39;.&#39;]&#125;
</code></pre>
<p>æ‰€æœ‰çš„æ•°æ®æ ‡ç­¾labelséƒ½å·²ç»è¢«ç¼–ç æˆäº†æ•´æ•°ï¼Œå¯ä»¥ç›´æ¥è¢«é¢„è®­ç»ƒtransformeræ¨¡å‹ä½¿ç”¨ã€‚è¿™äº›æ•´æ•°çš„ç¼–ç æ‰€å¯¹åº”çš„å®é™…ç±»åˆ«å‚¨å­˜åœ¨<code>features</code>ä¸­ã€‚</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">datasets[<span class="string">&quot;train&quot;</span>].features[<span class="string">f&quot;ner_tags&quot;</span>]</span><br></pre></td></tr></table></figure>
<pre><code>Sequence(feature=ClassLabel(num_classes=9, names=[&#39;O&#39;, &#39;B-PER&#39;, &#39;I-PER&#39;, &#39;B-ORG&#39;, &#39;I-ORG&#39;, &#39;B-LOC&#39;, &#39;I-LOC&#39;, &#39;B-MISC&#39;, &#39;I-MISC&#39;], names_file=None, id=None), length=-1, id=None)
- &#39;PER&#39; for person
- &#39;ORG&#39; for organization
- &#39;LOC&#39; for location
- &#39;MISC&#39; for miscellaneous
â€˜0â€™çš„æ„æ€æ˜¯æ²¡æœ‰å®ä½“ã€‚ â€˜B-â€™å‰ç¼€ä»£è¡¨å®ä½“å¼€å§‹çš„tokenï¼Œâ€˜I-â€™å‰ç¼€ä»£è¡¨å®ä½“ä¸­é—´çš„tokenã€‚
</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">label_list = datasets[<span class="string">&quot;train&quot;</span>].features[<span class="string">f&quot;<span class="subst">&#123;task&#125;</span>_tags&quot;</span>].feature.names</span><br><span class="line">label_list</span><br></pre></td></tr></table></figure>




<pre><code>[&#39;O&#39;, &#39;B-PER&#39;, &#39;I-PER&#39;, &#39;B-ORG&#39;, &#39;I-ORG&#39;, &#39;B-LOC&#39;, &#39;I-LOC&#39;, &#39;B-MISC&#39;, &#39;I-MISC&#39;]
</code></pre>
<p>åŒTask06ï¼Œ ä¸ºäº†èƒ½å¤Ÿè¿›ä¸€æ­¥ç†è§£æ•°æ®é•¿ä»€ä¹ˆæ ·å­ï¼Œä¸‹é¢çš„å‡½æ•°å°†ä»æ•°æ®é›†é‡Œéšæœºé€‰æ‹©å‡ ä¸ªä¾‹å­è¿›è¡Œå±•ç¤ºã€‚</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> datasets <span class="keyword">import</span> ClassLabel, <span class="type">Sequence</span></span><br><span class="line"><span class="keyword">import</span> random</span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">from</span> IPython.display <span class="keyword">import</span> display, HTML</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">show_random_elements</span>(<span class="params">dataset, num_examples=<span class="number">10</span></span>):</span></span><br><span class="line">    <span class="keyword">assert</span> num_examples &lt;= <span class="built_in">len</span>(dataset), <span class="string">&quot;Can&#x27;t pick more elements than there are in the dataset.&quot;</span></span><br><span class="line">    picks = []</span><br><span class="line">    <span class="keyword">for</span> _ <span class="keyword">in</span> <span class="built_in">range</span>(num_examples):</span><br><span class="line">        pick = random.randint(<span class="number">0</span>, <span class="built_in">len</span>(dataset)-<span class="number">1</span>)</span><br><span class="line">        <span class="keyword">while</span> pick <span class="keyword">in</span> picks:</span><br><span class="line">            pick = random.randint(<span class="number">0</span>, <span class="built_in">len</span>(dataset)-<span class="number">1</span>)</span><br><span class="line">        picks.append(pick)</span><br><span class="line">    </span><br><span class="line">    df = pd.DataFrame(dataset[picks])</span><br><span class="line">    <span class="keyword">for</span> column, typ <span class="keyword">in</span> dataset.features.items():</span><br><span class="line">        <span class="keyword">if</span> <span class="built_in">isinstance</span>(typ, ClassLabel):</span><br><span class="line">            df[column] = df[column].transform(<span class="keyword">lambda</span> i: typ.names[i])</span><br><span class="line">        <span class="keyword">elif</span> <span class="built_in">isinstance</span>(typ, <span class="type">Sequence</span>) <span class="keyword">and</span> <span class="built_in">isinstance</span>(typ.feature, ClassLabel):</span><br><span class="line">            df[column] = df[column].transform(<span class="keyword">lambda</span> x: [typ.feature.names[i] <span class="keyword">for</span> i <span class="keyword">in</span> x])</span><br><span class="line">    display(HTML(df.to_html()))</span><br></pre></td></tr></table></figure>


<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">show_random_elements(datasets[<span class="string">&quot;train&quot;</span>])</span><br></pre></td></tr></table></figure>


<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>id</th>
      <th>tokens</th>
      <th>pos_tags</th>
      <th>chunk_tags</th>
      <th>ner_tags</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>2227</td>
      <td>[Result, of, a, French, first, division, match, on, Friday, .]</td>
      <td>[NN, IN, DT, JJ, JJ, NN, NN, IN, NNP, .]</td>
      <td>[B-NP, B-PP, B-NP, I-NP, I-NP, I-NP, I-NP, B-PP, B-NP, O]</td>
      <td>[O, O, O, B-MISC, O, O, O, O, O, O]</td>
    </tr>
    <tr>
      <th>1</th>
      <td>2615</td>
      <td>[Mid-tier, golds, up, in, heavy, trading, .]</td>
      <td>[NN, NNS, IN, IN, JJ, NN, .]</td>
      <td>[B-NP, I-NP, B-PP, B-PP, B-NP, I-NP, O]</td>
      <td>[O, O, O, O, O, O, O]</td>
    </tr>
    <tr>
      <th>2</th>
      <td>10256</td>
      <td>[Neagle, (, 14-6, ), beat, the, Braves, for, the, third, time, this, season, ,, allowing, two, runs, and, six, hits, in, eight, innings, .]</td>
      <td>[NNP, (, CD, ), VB, DT, NNPS, IN, DT, JJ, NN, DT, NN, ,, VBG, CD, NNS, CC, CD, NNS, IN, CD, NN, .]</td>
      <td>[B-NP, O, B-NP, O, B-VP, B-NP, I-NP, B-PP, B-NP, I-NP, I-NP, B-NP, I-NP, O, B-VP, B-NP, I-NP, O, B-NP, I-NP, B-PP, B-NP, I-NP, O]</td>
      <td>[B-PER, O, O, O, O, O, B-ORG, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O]</td>
    </tr>
    <tr>
      <th>3</th>
      <td>10720</td>
      <td>[Hansa, Rostock, 4, 1, 2, 1, 5, 4, 5]</td>
      <td>[NNP, NNP, CD, CD, CD, CD, CD, CD, CD]</td>
      <td>[B-NP, I-NP, I-NP, I-NP, I-NP, I-NP, I-NP, I-NP, I-NP]</td>
      <td>[B-ORG, I-ORG, O, O, O, O, O, O, O]</td>
    </tr>
    <tr>
      <th>4</th>
      <td>7125</td>
      <td>[MONTREAL, 70, 59, .543, 11]</td>
      <td>[NNP, CD, CD, CD, CD]</td>
      <td>[B-NP, I-NP, I-NP, I-NP, I-NP]</td>
      <td>[B-ORG, O, O, O, O]</td>
    </tr>
    <tr>
      <th>5</th>
      <td>3316</td>
      <td>[Softbank, Corp, said, on, Friday, that, it, would, procure, $, 900, million, through, the, foreign, exchange, market, by, September, 5, as, part, of, its, acquisition, of, U.S., firm, ,, Kingston, Technology, Co, .]</td>
      <td>[NNP, NNP, VBD, IN, NNP, IN, PRP, MD, NN, $, CD, CD, IN, DT, JJ, NN, NN, IN, NNP, CD, IN, NN, IN, PRP$, NN, IN, NNP, NN, ,, NNP, NNP, NNP, .]</td>
      <td>[B-NP, I-NP, B-VP, B-PP, B-NP, B-SBAR, B-NP, B-VP, B-NP, I-NP, I-NP, I-NP, B-PP, B-NP, I-NP, I-NP, I-NP, B-PP, B-NP, I-NP, B-PP, B-NP, B-PP, B-NP, I-NP, B-PP, B-NP, I-NP, O, B-NP, I-NP, I-NP, O]</td>
      <td>[B-ORG, I-ORG, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, B-LOC, O, O, B-ORG, I-ORG, I-ORG, O]</td>
    </tr>
    <tr>
      <th>6</th>
      <td>3923</td>
      <td>[Ghent, 3, Aalst, 2]</td>
      <td>[NN, CD, NNP, CD]</td>
      <td>[B-NP, I-NP, I-NP, I-NP]</td>
      <td>[B-ORG, O, B-ORG, O]</td>
    </tr>
    <tr>
      <th>7</th>
      <td>2776</td>
      <td>[The, separatists, ,, who, swept, into, Grozny, on, August, 6, ,, still, control, large, areas, of, the, centre, of, town, ,, and, Russian, soldiers, are, based, at, checkpoints, on, the, approach, roads, .]</td>
      <td>[DT, NNS, ,, WP, VBD, IN, NNP, IN, NNP, CD, ,, RB, VBP, JJ, NNS, IN, DT, NN, IN, NN, ,, CC, JJ, NNS, VBP, VBN, IN, NNS, IN, DT, NN, NNS, .]</td>
      <td>[B-NP, I-NP, O, B-NP, B-VP, B-PP, B-NP, B-PP, B-NP, I-NP, O, B-ADVP, B-VP, B-NP, I-NP, B-PP, B-NP, I-NP, B-PP, B-NP, O, O, B-NP, I-NP, B-VP, I-VP, B-PP, B-NP, B-PP, B-NP, I-NP, I-NP, O]</td>
      <td>[O, O, O, O, O, O, B-LOC, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, B-MISC, O, O, O, O, O, O, O, O, O, O]</td>
    </tr>
    <tr>
      <th>8</th>
      <td>1178</td>
      <td>[Doctor, Masserigne, Ndiaye, said, medical, staff, were, overwhelmed, with, work, ., "]</td>
      <td>[NNP, NNP, NNP, VBD, JJ, NN, VBD, VBN, IN, NN, ., "]</td>
      <td>[B-NP, I-NP, I-NP, B-VP, B-NP, I-NP, B-VP, I-VP, B-PP, B-NP, O, O]</td>
      <td>[O, B-PER, I-PER, O, O, O, O, O, O, O, O, O]</td>
    </tr>
    <tr>
      <th>9</th>
      <td>10988</td>
      <td>[Reuters, historical, calendar, -, September, 4, .]</td>
      <td>[NNP, JJ, NN, :, NNP, CD, .]</td>
      <td>[B-NP, I-NP, I-NP, O, B-NP, I-NP, O]</td>
      <td>[B-ORG, O, O, O, O, O, O]</td>
    </tr>
  </tbody>
</table>

<h1 id="4-é¢„å¤„ç†æ•°æ®"><a href="#4-é¢„å¤„ç†æ•°æ®" class="headerlink" title="4 é¢„å¤„ç†æ•°æ®"></a>4 é¢„å¤„ç†æ•°æ®</h1><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> transformers <span class="keyword">import</span> AutoTokenizer</span><br><span class="line">    </span><br><span class="line">tokenizer = AutoTokenizer.from_pretrained(model_checkpoint)</span><br></pre></td></tr></table></figure>
<p>æ³¨æ„ï¼šä»¥ä¸‹ä»£ç è¦æ±‚tokenizerå¿…é¡»æ˜¯transformers.PreTrainedTokenizerFastç±»å‹ï¼Œå› ä¸ºæˆ‘ä»¬åœ¨é¢„å¤„ç†çš„æ—¶å€™éœ€è¦ç”¨åˆ°fast tokenizerçš„ä¸€äº›ç‰¹æ®Šç‰¹æ€§ï¼ˆæ¯”å¦‚å¤šçº¿ç¨‹å¿«é€Ÿtokenizerï¼‰ã€‚</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> transformers</span><br><span class="line"><span class="keyword">assert</span> <span class="built_in">isinstance</span>(tokenizer, transformers.PreTrainedTokenizerFast)</span><br></pre></td></tr></table></figure>

<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">tokenizer(<span class="string">&quot;Hello, this is one sentence!&quot;</span>)</span><br></pre></td></tr></table></figure>




<pre><code>&#123;&#39;input_ids&#39;: [101, 7592, 1010, 2023, 2003, 2028, 6251, 999, 102], &#39;attention_mask&#39;: [1, 1, 1, 1, 1, 1, 1, 1, 1]&#125;
</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">tokenizer([<span class="string">&quot;Hello&quot;</span>, <span class="string">&quot;,&quot;</span>, <span class="string">&quot;this&quot;</span>, <span class="string">&quot;is&quot;</span>, <span class="string">&quot;one&quot;</span>, <span class="string">&quot;sentence&quot;</span>, <span class="string">&quot;split&quot;</span>, <span class="string">&quot;into&quot;</span>, <span class="string">&quot;words&quot;</span>, <span class="string">&quot;.&quot;</span>], is_split_into_words=<span class="literal">True</span>)</span><br></pre></td></tr></table></figure>




<pre><code>&#123;&#39;input_ids&#39;: [101, 7592, 1010, 2023, 2003, 2028, 6251, 3975, 2046, 2616, 1012, 102], &#39;attention_mask&#39;: [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]&#125;
</code></pre>
<h2 id="4-1-tokenizerä¼šå°†wordç»§ç»­åˆ‡åˆ†"><a href="#4-1-tokenizerä¼šå°†wordç»§ç»­åˆ‡åˆ†" class="headerlink" title="4.1 tokenizerä¼šå°†wordç»§ç»­åˆ‡åˆ†"></a>4.1 tokenizerä¼šå°†wordç»§ç»­åˆ‡åˆ†</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">example = datasets[<span class="string">&quot;train&quot;</span>][<span class="number">4</span>]</span><br><span class="line"><span class="built_in">print</span>(example[<span class="string">&quot;tokens&quot;</span>])</span><br></pre></td></tr></table></figure>

<pre><code>[&#39;Germany&#39;, &quot;&#39;s&quot;, &#39;representative&#39;, &#39;to&#39;, &#39;the&#39;, &#39;European&#39;, &#39;Union&#39;, &quot;&#39;s&quot;, &#39;veterinary&#39;, &#39;committee&#39;, &#39;Werner&#39;, &#39;Zwingmann&#39;, &#39;said&#39;, &#39;on&#39;, &#39;Wednesday&#39;, &#39;consumers&#39;, &#39;should&#39;, &#39;buy&#39;, &#39;sheepmeat&#39;, &#39;from&#39;, &#39;countries&#39;, &#39;other&#39;, &#39;than&#39;, &#39;Britain&#39;, &#39;until&#39;, &#39;the&#39;, &#39;scientific&#39;, &#39;advice&#39;, &#39;was&#39;, &#39;clearer&#39;, &#39;.&#39;]
</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">tokenized_input = tokenizer(example[<span class="string">&quot;tokens&quot;</span>], is_split_into_words=<span class="literal">True</span>)</span><br><span class="line">tokens = tokenizer.convert_ids_to_tokens(tokenized_input[<span class="string">&quot;input_ids&quot;</span>])</span><br><span class="line"><span class="built_in">print</span>(tokens)</span><br></pre></td></tr></table></figure>

<pre><code>[&#39;[CLS]&#39;, &#39;germany&#39;, &quot;&#39;&quot;, &#39;s&#39;, &#39;representative&#39;, &#39;to&#39;, &#39;the&#39;, &#39;european&#39;, &#39;union&#39;, &quot;&#39;&quot;, &#39;s&#39;, &#39;veterinary&#39;, &#39;committee&#39;, &#39;werner&#39;, &#39;z&#39;, &#39;##wing&#39;, &#39;##mann&#39;, &#39;said&#39;, &#39;on&#39;, &#39;wednesday&#39;, &#39;consumers&#39;, &#39;should&#39;, &#39;buy&#39;, &#39;sheep&#39;, &#39;##me&#39;, &#39;##at&#39;, &#39;from&#39;, &#39;countries&#39;, &#39;other&#39;, &#39;than&#39;, &#39;britain&#39;, &#39;until&#39;, &#39;the&#39;, &#39;scientific&#39;, &#39;advice&#39;, &#39;was&#39;, &#39;clearer&#39;, &#39;.&#39;, &#39;[SEP]&#39;]
</code></pre>
<h2 id="4-2-å¯¹åˆ‡åˆ†åçš„tokenä¸åŸwordå¯¹é½"><a href="#4-2-å¯¹åˆ‡åˆ†åçš„tokenä¸åŸwordå¯¹é½" class="headerlink" title="4.2 å¯¹åˆ‡åˆ†åçš„tokenä¸åŸwordå¯¹é½"></a>4.2 å¯¹åˆ‡åˆ†åçš„tokenä¸åŸwordå¯¹é½</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">print</span>(tokenized_input.word_ids())</span><br><span class="line"><span class="comment"># word_idsæ–¹æ³•èƒ½å°†subtokenså’Œwordsè¿˜æœ‰æ ‡æ³¨çš„labelså¯¹é½ã€‚</span></span><br></pre></td></tr></table></figure>

<pre><code>[None, 0, 1, 1, 2, 3, 4, 5, 6, 7, 7, 8, 9, 10, 11, 11, 11, 12, 13, 14, 15, 16, 17, 18, 18, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, None]
</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">word_ids = tokenized_input.word_ids()</span><br><span class="line">aligned_labels = [-<span class="number">100</span> <span class="keyword">if</span> i <span class="keyword">is</span> <span class="literal">None</span> <span class="keyword">else</span> example[<span class="string">f&quot;<span class="subst">&#123;task&#125;</span>_tags&quot;</span>][i] <span class="keyword">for</span> i <span class="keyword">in</span> word_ids]</span><br><span class="line"><span class="built_in">print</span>(<span class="built_in">len</span>(aligned_labels), <span class="built_in">len</span>(tokenized_input[<span class="string">&quot;input_ids&quot;</span>]))</span><br></pre></td></tr></table></figure>

<pre><code>39 39
</code></pre>
<p>ä¸¤ç§å¯¹é½labelçš„æ–¹å¼ï¼š</p>
<ul>
<li>å¤šä¸ªsubtokenså¯¹é½ä¸€ä¸ªwordï¼Œå¯¹é½ä¸€ä¸ªlabel</li>
<li>å¤šä¸ªsubtokensçš„ç¬¬ä¸€ä¸ªsubtokenå¯¹é½wordï¼Œå¯¹é½ä¸€ä¸ªlabelï¼Œå…¶ä»–subtokensç›´æ¥èµ‹äºˆ-100.</li>
</ul>
<h2 id="4-3-æ•´åˆé¢„å¤„ç†å‡½æ•°"><a href="#4-3-æ•´åˆé¢„å¤„ç†å‡½æ•°" class="headerlink" title="4.3 æ•´åˆé¢„å¤„ç†å‡½æ•°"></a>4.3 æ•´åˆé¢„å¤„ç†å‡½æ•°</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">##ï¼Ÿï¼Ÿï¼Ÿï¼Ÿ</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">tokenize_and_align_labels</span>(<span class="params">examples</span>):</span></span><br><span class="line">    tokenized_inputs = tokenizer(examples[<span class="string">&quot;tokens&quot;</span>], truncation=<span class="literal">True</span>, is_split_into_words=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line">    labels = []</span><br><span class="line">    <span class="keyword">for</span> i, label <span class="keyword">in</span> <span class="built_in">enumerate</span>(examples[<span class="string">f&quot;<span class="subst">&#123;task&#125;</span>_tags&quot;</span>]):</span><br><span class="line">        word_ids = tokenized_inputs.word_ids(batch_index=i)</span><br><span class="line">        previous_word_idx = <span class="literal">None</span></span><br><span class="line">        label_ids = []</span><br><span class="line">        <span class="keyword">for</span> word_idx <span class="keyword">in</span> word_ids:</span><br><span class="line">            <span class="comment"># Special tokens have a word id that is None. We set the label to -100 so they are automatically</span></span><br><span class="line">            <span class="comment"># ignored in the loss function.</span></span><br><span class="line">            <span class="keyword">if</span> word_idx <span class="keyword">is</span> <span class="literal">None</span>:</span><br><span class="line">                label_ids.append(-<span class="number">100</span>)</span><br><span class="line">            <span class="comment"># We set the label for the first token of each word.</span></span><br><span class="line">            <span class="keyword">elif</span> word_idx != previous_word_idx:</span><br><span class="line">                label_ids.append(label[word_idx])</span><br><span class="line">            <span class="comment"># For the other tokens in a word, we set the label to either the current label or -100, depending on</span></span><br><span class="line">            <span class="comment"># the label_all_tokens flag.</span></span><br><span class="line">            <span class="keyword">else</span>:</span><br><span class="line">                label_ids.append(label[word_idx] <span class="keyword">if</span> label_all_tokens <span class="keyword">else</span> -<span class="number">100</span>)</span><br><span class="line">            previous_word_idx = word_idx</span><br><span class="line"></span><br><span class="line">        labels.append(label_ids)</span><br><span class="line"></span><br><span class="line">    tokenized_inputs[<span class="string">&quot;labels&quot;</span>] = labels</span><br><span class="line">    <span class="keyword">return</span> tokenized_inputs</span><br></pre></td></tr></table></figure>

<p>ä»¥ä¸Šçš„é¢„å¤„ç†å‡½æ•°å¯ä»¥å¤„ç†ä¸€ä¸ªæ ·æœ¬ï¼Œä¹Ÿå¯ä»¥å¤„ç†å¤šä¸ªæ ·æœ¬exapmlesã€‚å¦‚æœæ˜¯å¤„ç†å¤šä¸ªæ ·æœ¬ï¼Œåˆ™è¿”å›çš„æ˜¯å¤šä¸ªæ ·æœ¬è¢«é¢„å¤„ç†ä¹‹åçš„ç»“æœlistã€‚</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">tokenize_and_align_labels(datasets[<span class="string">&#x27;train&#x27;</span>][:<span class="number">5</span>])</span><br></pre></td></tr></table></figure>


<pre><code>&#123;&#39;input_ids&#39;: [[101, 7327, 19164, 2446, 2655, 2000, 17757, 2329, 12559, 1012, 102], [101, 2848, 13934, 102], [101, 9371, 2727, 1011, 5511, 1011, 2570, 102], [101, 1996, 2647, 3222, 2056, 2006, 9432, 2009, 18335, 2007, 2446, 6040, 2000, 10390, 2000, 18454, 2078, 2329, 12559, 2127, 6529, 5646, 3251, 5506, 11190, 4295, 2064, 2022, 11860, 2000, 8351, 1012, 102], [101, 2762, 1005, 1055, 4387, 2000, 1996, 2647, 2586, 1005, 1055, 15651, 2837, 14121, 1062, 9328, 5804, 2056, 2006, 9317, 10390, 2323, 4965, 8351, 4168, 4017, 2013, 3032, 2060, 2084, 3725, 2127, 1996, 4045, 6040, 2001, 24509, 1012, 102]], &#39;attention_mask&#39;: [[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]], &#39;labels&#39;: [[-100, 3, 0, 7, 0, 0, 0, 7, 0, 0, -100], [-100, 1, 2, -100], [-100, 5, 0, 0, 0, 0, 0, -100], [-100, 0, 3, 4, 0, 0, 0, 0, 0, 0, 7, 0, 0, 0, 0, 0, 0, 7, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, -100], [-100, 5, 0, 0, 0, 0, 0, 3, 4, 0, 0, 0, 0, 1, 2, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 5, 0, 0, 0, 0, 0, 0, 0, -100]]&#125;
</code></pre>
<p>æ¥ä¸‹æ¥å¯¹æ•°æ®é›†datasetsé‡Œé¢çš„æ‰€æœ‰æ ·æœ¬è¿›è¡Œé¢„å¤„ç†ï¼Œå¤„ç†çš„æ–¹å¼æ˜¯ä½¿ç”¨mapå‡½æ•°ï¼Œå°†é¢„å¤„ç†å‡½æ•°prepare_train_featuresåº”ç”¨åˆ°ï¼ˆmap)æ‰€æœ‰æ ·æœ¬ä¸Šã€‚</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">tokenized_datasets = datasets.<span class="built_in">map</span>(tokenize_and_align_labels, batched=<span class="literal">True</span>)</span><br></pre></td></tr></table></figure>

<h1 id="5-å¾®è°ƒé¢„è®­ç»ƒæ¨¡å‹"><a href="#5-å¾®è°ƒé¢„è®­ç»ƒæ¨¡å‹" class="headerlink" title="5 å¾®è°ƒé¢„è®­ç»ƒæ¨¡å‹"></a>5 å¾®è°ƒé¢„è®­ç»ƒæ¨¡å‹</h1><h2 id="5-1-è®¾ç½®Trainer"><a href="#5-1-è®¾ç½®Trainer" class="headerlink" title="5.1 è®¾ç½®Trainer"></a>5.1 è®¾ç½®Trainer</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"><span class="keyword">from</span> transformers <span class="keyword">import</span> AutoModelForTokenClassification, TrainingArguments, Trainer</span><br><span class="line"></span><br><span class="line">model = AutoModelForTokenClassification.from_pretrained(model_checkpoint, num_labels=<span class="built_in">len</span>(label_list))</span><br><span class="line"><span class="comment"># ä½¿ç”¨`AutoModelForTokenClassification` è¿™ä¸ªç±»åšseq2seqä»»åŠ¡</span></span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># åŒTask06</span></span><br><span class="line">args = TrainingArguments(</span><br><span class="line">    <span class="string">f&quot;test-<span class="subst">&#123;task&#125;</span>&quot;</span>,</span><br><span class="line">    evaluation_strategy = <span class="string">&quot;epoch&quot;</span>,</span><br><span class="line">    learning_rate=<span class="number">2e-5</span>,</span><br><span class="line">    per_device_train_batch_size=batch_size,</span><br><span class="line">    per_device_eval_batch_size=batch_size,</span><br><span class="line">    num_train_epochs=<span class="number">3</span>,</span><br><span class="line">    weight_decay=<span class="number">0.01</span>,</span><br><span class="line">)</span><br></pre></td></tr></table></figure>

<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> transformers <span class="keyword">import</span> DataCollatorForTokenClassification</span><br><span class="line"></span><br><span class="line">data_collator = DataCollatorForTokenClassification(tokenizer)</span><br><span class="line"><span class="comment"># éœ€è¦ä¸€ä¸ªæ•°æ®æ”¶é›†å™¨data collatorï¼Œå°†å¤„ç†å¥½çš„è¾“å…¥å–‚ç»™æ¨¡å‹</span></span><br></pre></td></tr></table></figure>

<h2 id="5-2-è®¾ç½®è¯„ä¼°æ–¹æ³•"><a href="#5-2-è®¾ç½®è¯„ä¼°æ–¹æ³•" class="headerlink" title="5.2 è®¾ç½®è¯„ä¼°æ–¹æ³•"></a>5.2 è®¾ç½®è¯„ä¼°æ–¹æ³•</h2><p>ä½¿ç”¨<a href="https://github.com/chakki-works/seqeval"><code>seqeval</code></a> metricæ¥å®Œæˆè¯„ä¼°ã€‚</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">metric = load_metric(<span class="string">&quot;seqeval&quot;</span>)</span><br></pre></td></tr></table></figure>

<p>è¯„ä¼°çš„è¾“å…¥æ˜¯é¢„æµ‹å’Œlabelçš„list</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">labels = [label_list[i] <span class="keyword">for</span> i <span class="keyword">in</span> example[<span class="string">f&quot;<span class="subst">&#123;task&#125;</span>_tags&quot;</span>]]</span><br><span class="line">metric.compute(predictions=[labels], references=[labels])</span><br></pre></td></tr></table></figure>




<pre><code>&#123;&#39;LOC&#39;: &#123;&#39;f1&#39;: 1.0, &#39;number&#39;: 2, &#39;precision&#39;: 1.0, &#39;recall&#39;: 1.0&#125;,
 &#39;ORG&#39;: &#123;&#39;f1&#39;: 1.0, &#39;number&#39;: 1, &#39;precision&#39;: 1.0, &#39;recall&#39;: 1.0&#125;,
 &#39;PER&#39;: &#123;&#39;f1&#39;: 1.0, &#39;number&#39;: 1, &#39;precision&#39;: 1.0, &#39;recall&#39;: 1.0&#125;,
 &#39;overall_accuracy&#39;: 1.0,
 &#39;overall_f1&#39;: 1.0,
 &#39;overall_precision&#39;: 1.0,
 &#39;overall_recall&#39;: 1.0&#125;
</code></pre>
<p>å¯¹æ¨¡å‹é¢„æµ‹ç»“æœåšä¸€äº›åå¤„ç†ï¼š</p>
<ul>
<li>é€‰æ‹©é¢„æµ‹åˆ†ç±»æœ€å¤§æ¦‚ç‡çš„ä¸‹æ ‡</li>
<li>å°†ä¸‹æ ‡è½¬åŒ–ä¸ºlabel</li>
<li>å¿½ç•¥-100æ‰€åœ¨åœ°æ–¹</li>
</ul>
<h2 id="5-3-å°†å‚æ•°è®¾ç½®å’Œè¯„ä¼°æ–¹æ³•ä¸¤æ­¥æ•´åˆèµ·æ¥"><a href="#5-3-å°†å‚æ•°è®¾ç½®å’Œè¯„ä¼°æ–¹æ³•ä¸¤æ­¥æ•´åˆèµ·æ¥" class="headerlink" title="5.3 å°†å‚æ•°è®¾ç½®å’Œè¯„ä¼°æ–¹æ³•ä¸¤æ­¥æ•´åˆèµ·æ¥"></a>5.3 å°†å‚æ•°è®¾ç½®å’Œè¯„ä¼°æ–¹æ³•ä¸¤æ­¥æ•´åˆèµ·æ¥</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">compute_metrics</span>(<span class="params">p</span>):</span></span><br><span class="line">    predictions, labels = p</span><br><span class="line">    predictions = np.argmax(predictions, axis=<span class="number">2</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># Remove ignored index (special tokens)</span></span><br><span class="line">    true_predictions = [</span><br><span class="line">        [label_list[p] <span class="keyword">for</span> (p, l) <span class="keyword">in</span> <span class="built_in">zip</span>(prediction, label) <span class="keyword">if</span> l != -<span class="number">100</span>]</span><br><span class="line">        <span class="keyword">for</span> prediction, label <span class="keyword">in</span> <span class="built_in">zip</span>(predictions, labels)</span><br><span class="line">    ]</span><br><span class="line">    true_labels = [</span><br><span class="line">        [label_list[l] <span class="keyword">for</span> (p, l) <span class="keyword">in</span> <span class="built_in">zip</span>(prediction, label) <span class="keyword">if</span> l != -<span class="number">100</span>]</span><br><span class="line">        <span class="keyword">for</span> prediction, label <span class="keyword">in</span> <span class="built_in">zip</span>(predictions, labels)</span><br><span class="line">    ]</span><br><span class="line"></span><br><span class="line">    results = metric.compute(predictions=true_predictions, references=true_labels)</span><br><span class="line">    <span class="keyword">return</span> &#123;</span><br><span class="line">        <span class="string">&quot;precision&quot;</span>: results[<span class="string">&quot;overall_precision&quot;</span>],</span><br><span class="line">        <span class="string">&quot;recall&quot;</span>: results[<span class="string">&quot;overall_recall&quot;</span>],</span><br><span class="line">        <span class="string">&quot;f1&quot;</span>: results[<span class="string">&quot;overall_f1&quot;</span>],</span><br><span class="line">        <span class="string">&quot;accuracy&quot;</span>: results[<span class="string">&quot;overall_accuracy&quot;</span>],</span><br><span class="line">    &#125;</span><br></pre></td></tr></table></figure>


<p>æˆ‘ä»¬è®¡ç®—æ‰€æœ‰ç±»åˆ«æ€»çš„precision/recall/f1ï¼Œæ‰€ä»¥ä¼šæ‰”æ‰å•ä¸ªç±»åˆ«çš„precision/recall/f1 </p>
<p>å°†æ•°æ®/æ¨¡å‹/å‚æ•°ä¼ å…¥<code>Trainer</code>å³å¯</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">trainer = Trainer(</span><br><span class="line">    model,</span><br><span class="line">    args,</span><br><span class="line">    train_dataset=tokenized_datasets[<span class="string">&quot;train&quot;</span>],</span><br><span class="line">    eval_dataset=tokenized_datasets[<span class="string">&quot;validation&quot;</span>],</span><br><span class="line">    data_collator=data_collator,</span><br><span class="line">    tokenizer=tokenizer,</span><br><span class="line">    compute_metrics=compute_metrics</span><br><span class="line">)</span><br></pre></td></tr></table></figure>

<p>è°ƒç”¨<code>train</code>æ–¹æ³•å¼€å§‹è®­ç»ƒ</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">trainer.train()</span><br></pre></td></tr></table></figure>



  <div>
      <style>
          /* Turns off some styling */
          progress {
              /* gets rid of default border in Firefox and Opera. */
              border: none;
              /* Needs to be in here for Safari polyfill so background images work as expected. */
              background-size: auto;
          }
      </style>

<p>  <progress value='2634' max='2634' style='width:300px; height:20px; vertical-align: middle;'></progress><br>  [2634/2634 01:45, Epoch 3/3]<br>  </div><br>  <table border="1" class="dataframe"></p>
<thead>
  <tr style="text-align: left;">
    <th>Epoch</th>
    <th>Training Loss</th>
    <th>Validation Loss</th>
    <th>Precision</th>
    <th>Recall</th>
    <th>F1</th>
    <th>Accuracy</th>
  </tr>
</thead>
<tbody>
  <tr>
    <td>1</td>
    <td>0.237721</td>
    <td>0.068198</td>
    <td>0.903148</td>
    <td>0.921132</td>
    <td>0.912051</td>
    <td>0.979713</td>
  </tr>
  <tr>
    <td>2</td>
    <td>0.053160</td>
    <td>0.059337</td>
    <td>0.927697</td>
    <td>0.932990</td>
    <td>0.930336</td>
    <td>0.983113</td>
  </tr>
  <tr>
    <td>3</td>
    <td>0.029850</td>
    <td>0.059346</td>
    <td>0.929267</td>
    <td>0.939143</td>
    <td>0.934179</td>
    <td>0.984257</td>
  </tr>
</tbody>
</table><p>





<pre><code>TrainOutput(global_step=2634, training_loss=0.08569671253227518)
</code></pre>
<h1 id="6-å¯¹æ¨¡å‹è¿›è¡Œè¯„ä¼°"><a href="#6-å¯¹æ¨¡å‹è¿›è¡Œè¯„ä¼°" class="headerlink" title="6 å¯¹æ¨¡å‹è¿›è¡Œè¯„ä¼°"></a>6 å¯¹æ¨¡å‹è¿›è¡Œè¯„ä¼°</h1><h2 id="6-1-å¯¹æ€»ç±»åˆ«è¿›è¡Œè¯„ä¼°"><a href="#6-1-å¯¹æ€»ç±»åˆ«è¿›è¡Œè¯„ä¼°" class="headerlink" title="6.1 å¯¹æ€»ç±»åˆ«è¿›è¡Œè¯„ä¼°"></a>6.1 å¯¹æ€»ç±»åˆ«è¿›è¡Œè¯„ä¼°</h2><p>æˆ‘ä»¬å¯ä»¥å†æ¬¡ä½¿ç”¨<code>evaluate</code>æ–¹æ³•è¯„ä¼°ï¼Œå¯ä»¥è¯„ä¼°å…¶ä»–æ•°æ®é›†ã€‚</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">trainer.evaluate()</span><br></pre></td></tr></table></figure>



<div>
    <style>
        /* Turns off some styling */
        progress {
            /* gets rid of default border in Firefox and Opera. */
            border: none;
            /* Needs to be in here for Safari polyfill so background images work as expected. */
            background-size: auto;
        }
    </style>

<p>  <progress value='408' max='204' style='width:300px; height:20px; vertical-align: middle;'></progress><br>  [204/204 00:05]</p>
</div>






<pre><code>&#123;&#39;eval_loss&#39;: 0.05934586375951767,
 &#39;eval_precision&#39;: 0.9292672127518264,
 &#39;eval_recall&#39;: 0.9391430808815304,
 &#39;eval_f1&#39;: 0.9341790463472988,
 &#39;eval_accuracy&#39;: 0.9842565968195466,
 &#39;epoch&#39;: 3.0&#125;
</code></pre>
<h2 id="6-2-å¯¹å•ä¸ªç±»åˆ«è¿›è¡Œè¯„ä¼°"><a href="#6-2-å¯¹å•ä¸ªç±»åˆ«è¿›è¡Œè¯„ä¼°" class="headerlink" title="6.2 å¯¹å•ä¸ªç±»åˆ«è¿›è¡Œè¯„ä¼°"></a>6.2 å¯¹å•ä¸ªç±»åˆ«è¿›è¡Œè¯„ä¼°</h2><p>å¦‚æœæƒ³è¦å¾—åˆ°å•ä¸ªç±»åˆ«çš„precision/recall/f1ï¼Œæˆ‘ä»¬ç›´æ¥å°†ç»“æœè¾“å…¥ç›¸åŒçš„è¯„ä¼°å‡½æ•°å³å¯ï¼š</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">predictions, labels, _ = trainer.predict(tokenized_datasets[<span class="string">&quot;validation&quot;</span>])</span><br><span class="line">predictions = np.argmax(predictions, axis=<span class="number">2</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Remove ignored index (special tokens)</span></span><br><span class="line">true_predictions = [</span><br><span class="line">    [label_list[p] <span class="keyword">for</span> (p, l) <span class="keyword">in</span> <span class="built_in">zip</span>(prediction, label) <span class="keyword">if</span> l != -<span class="number">100</span>]</span><br><span class="line">    <span class="keyword">for</span> prediction, label <span class="keyword">in</span> <span class="built_in">zip</span>(predictions, labels)</span><br><span class="line">]</span><br><span class="line">true_labels = [</span><br><span class="line">    [label_list[l] <span class="keyword">for</span> (p, l) <span class="keyword">in</span> <span class="built_in">zip</span>(prediction, label) <span class="keyword">if</span> l != -<span class="number">100</span>]</span><br><span class="line">    <span class="keyword">for</span> prediction, label <span class="keyword">in</span> <span class="built_in">zip</span>(predictions, labels)</span><br><span class="line">]</span><br><span class="line"></span><br><span class="line">results = metric.compute(predictions=true_predictions, references=true_labels)</span><br><span class="line">results</span><br></pre></td></tr></table></figure>




<pre><code>&#123;&#39;LOC&#39;: &#123;&#39;precision&#39;: 0.949718574108818,
  &#39;recall&#39;: 0.966768525592055,
  &#39;f1&#39;: 0.9581677077418134,
  &#39;number&#39;: 2618&#125;,
 &#39;MISC&#39;: &#123;&#39;precision&#39;: 0.8132387706855791,
  &#39;recall&#39;: 0.8383428107229894,
  &#39;f1&#39;: 0.8255999999999999,
  &#39;number&#39;: 1231&#125;,
 &#39;ORG&#39;: &#123;&#39;precision&#39;: 0.9055232558139535,
  &#39;recall&#39;: 0.9090466926070039,
  &#39;f1&#39;: 0.9072815533980583,
  &#39;number&#39;: 2056&#125;,
 &#39;PER&#39;: &#123;&#39;precision&#39;: 0.9759552042160737,
  &#39;recall&#39;: 0.9765985497692815,
  &#39;f1&#39;: 0.9762767710049424,
  &#39;number&#39;: 3034&#125;,
 &#39;overall_precision&#39;: 0.9292672127518264,
 &#39;overall_recall&#39;: 0.9391430808815304,
 &#39;overall_f1&#39;: 0.9341790463472988,
 &#39;overall_accuracy&#39;: 0.9842565968195466&#125;
</code></pre>
<h1 id="7-å°†è®­ç»ƒå¥½çš„è‡ªå·±çš„æ¨¡å‹ä¸Šä¼ åˆ°Model-Hub"><a href="#7-å°†è®­ç»ƒå¥½çš„è‡ªå·±çš„æ¨¡å‹ä¸Šä¼ åˆ°Model-Hub" class="headerlink" title="7 å°†è®­ç»ƒå¥½çš„è‡ªå·±çš„æ¨¡å‹ä¸Šä¼ åˆ°Model-Hub"></a>7 å°†è®­ç»ƒå¥½çš„è‡ªå·±çš„æ¨¡å‹ä¸Šä¼ åˆ°Model-Hub</h1><p>æœ€ååˆ«å¿˜äº†ï¼ŒæŸ¥çœ‹å¦‚ä½•ä¸Šä¼ æ¨¡å‹ ï¼Œä¸Šä¼ æ¨¡å‹åˆ°](<a href="https://huggingface.co/transformers/model_sharing.html">https://huggingface.co/transformers/model_sharing.html</a>) åˆ°<a href="https://huggingface.co/models">ğŸ¤— Model Hub</a>ã€‚éšåæ‚¨å°±å¯ä»¥åƒè¿™ä¸ªnotebookä¸€å¼€å§‹ä¸€æ ·ï¼Œç›´æ¥ç”¨æ¨¡å‹åå­—å°±èƒ½ä½¿ç”¨æ‚¨è‡ªå·±ä¸Šä¼ çš„æ¨¡å‹å•¦ã€‚</p>
]]></content>
      
        
    </entry>
    
    <entry>
      <title><![CDATA[Transformersè§£å†³æ–‡æœ¬åˆ†ç±»ä»»åŠ¡ã€è¶…å‚æœç´¢]]></title>
      <url>/2021/08/27/Task06-Transformers%E8%A7%A3%E5%86%B3%E6%96%87%E6%9C%AC%E5%88%86%E7%B1%BB%E4%BB%BB%E5%8A%A1%E3%80%81%E8%B6%85%E5%8F%82%E6%90%9C%E7%B4%A2/</url>
      <content type="html"><![CDATA[<h1 id="Task06-Transformersè§£å†³æ–‡æœ¬åˆ†ç±»ä»»åŠ¡ã€è¶…å‚æœç´¢"><a href="#Task06-Transformersè§£å†³æ–‡æœ¬åˆ†ç±»ä»»åŠ¡ã€è¶…å‚æœç´¢" class="headerlink" title="Task06-Transformersè§£å†³æ–‡æœ¬åˆ†ç±»ä»»åŠ¡ã€è¶…å‚æœç´¢"></a>Task06-Transformersè§£å†³æ–‡æœ¬åˆ†ç±»ä»»åŠ¡ã€è¶…å‚æœç´¢</h1><ul>
<li>Datawhale å¼€æºå­¦ä¹ åœ°å€ï¼š<a href="https://github.com/datawhalechina/learn-nlp-with-transformers">https://github.com/datawhalechina/learn-nlp-with-transformers</a></li>
</ul>
<h2 id="0-æ€»ç»“"><a href="#0-æ€»ç»“" class="headerlink" title="0 æ€»ç»“"></a>0 æ€»ç»“</h2><ul>
<li>å°†BERTåº”ç”¨äºæ–‡æœ¬åˆ†ç±»</li>
<li>æ•°æ®é¢„å¤„ç†ï¼ˆtokenizeï¼‰</li>
<li>è®­ç»ƒå‚æ•°è®¾å®š/æ¨¡å‹è¯„ä¼°</li>
<li>è¶…å‚æ•°è‡ªåŠ¨è°ƒä¼˜çš„ä¸¤ä¸ªåº“</li>
<li>ä¸Šä¼ è‡ªå·±è®­ç»ƒå¥½çš„æ¨¡å‹åˆ°ModelHubï¼Œå¤šç»ˆç«¯å…±äº«ä½¿ç”¨</li>
<li>å¦‚æœä½¿ç”¨condaå®‰è£…ray[tune]åŒ…æ—¶ï¼Œè¯·ä¸‹è½½ray-tuneä¾èµ–åŒ…<br>å‘½ä»¤ï¼šconda install ray-tune -c conda-forge</li>
</ul>
<h2 id="1-æ–‡æœ¬åˆ†ç±»ä»»åŠ¡ç®€ä»‹"><a href="#1-æ–‡æœ¬åˆ†ç±»ä»»åŠ¡ç®€ä»‹" class="headerlink" title="1 æ–‡æœ¬åˆ†ç±»ä»»åŠ¡ç®€ä»‹"></a>1 æ–‡æœ¬åˆ†ç±»ä»»åŠ¡ç®€ä»‹</h2><ul>
<li>ä½¿ç”¨Transformersä»£ç åº“ä¸­çš„æ¨¡å‹æ¥è§£å†³æ–‡æœ¬åˆ†ç±»ä»»åŠ¡ï¼Œä»»åŠ¡æ¥æºäº<a href="https://gluebenchmark.com/">GLUE Benchmark</a></li>
<li>GLUEæ¦œå•çš„9ä¸ªçº§åˆ«çš„åˆ†ç±»ä»»åŠ¡ï¼š<ol>
<li>CoLA (Corpus of Linguistic Acceptability)ï¼šé‰´åˆ«ä¸€ä¸ªå¥å­æ˜¯å¦è¯­æ³•æ­£ç¡®.</li>
<li>MNLI (Multi-Genre Natural Language Inference)ï¼šç»™å®šä¸€ä¸ªå‡è®¾ï¼Œåˆ¤æ–­å¦ä¸€ä¸ªå¥å­ä¸è¯¥å‡è®¾çš„å…³ç³»ï¼šentailsã€contradictsã€unrelatedã€‚</li>
<li>MRPC (Microsoft Research Paraphrase Corpus)ï¼šåˆ¤æ–­ä¸¤ä¸ªå¥å­æ˜¯å¦äº’ä¸ºparaphrases</li>
<li>QNLI (Question-answering Natural Language Inference)ï¼šåˆ¤æ–­ç¬¬2å¥æ˜¯å¦åŒ…å«ç¬¬1å¥é—®é¢˜çš„ç­”æ¡ˆ</li>
<li>QQP (Quora Question Pairs2)ï¼šåˆ¤æ–­ä¸¤ä¸ªé—®å¥æ˜¯å¦è¯­ä¹‰ç›¸åŒ</li>
<li>RTE (Recognizing Textual Entailment)ï¼šåˆ¤æ–­ä¸€ä¸ªå¥å­æ˜¯å¦ä¸å‡è®¾æˆentailå…³ç³»</li>
<li>SST-2 (Stanford Sentiment Treebank)ï¼šåˆ¤æ–­ä¸€ä¸ªå¥å­çš„æƒ…æ„Ÿæ­£è´Ÿå‘</li>
<li>STS-B (Semantic Textual Similarity Benchmark)ï¼šåˆ¤æ–­ä¸¤ä¸ªå¥å­çš„ç›¸ä¼¼æ€§ï¼ˆåˆ†æ•°ä¸º1-5åˆ†ï¼‰</li>
<li>WNLI (Winograd Natural Language Inference)ï¼šåˆ¤æ–­å¸¦æœ‰åŒ¿åä»£è¯çš„å¥å­ä¸­ï¼Œæ˜¯å¦å­˜åœ¨èƒ½å¤Ÿæ›¿æ¢è¯¥ä»£è¯çš„å­å¥</li>
</ol>
</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">GLUE_TASKS = [<span class="string">&quot;cola&quot;</span>, <span class="string">&quot;mnli&quot;</span>, <span class="string">&quot;mnli-mm&quot;</span>, <span class="string">&quot;mrpc&quot;</span>,</span><br><span class="line">              <span class="string">&quot;qnli&quot;</span>, <span class="string">&quot;qqp&quot;</span>, <span class="string">&quot;rte&quot;</span>, <span class="string">&quot;sst2&quot;</span>, <span class="string">&quot;stsb&quot;</span>, <span class="string">&quot;wnli&quot;</span>]</span><br></pre></td></tr></table></figure>

<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">task = <span class="string">&quot;cola&quot;</span></span><br><span class="line"><span class="comment"># ä»»åŠ¡ä¸ºCoLAä»»åŠ¡</span></span><br><span class="line">model_checkpoint = <span class="string">&quot;distilbert-base-uncased&quot;</span></span><br><span class="line"><span class="comment"># ä½¿ç”¨BERTè’¸é¦æ¨¡å‹</span></span><br><span class="line">batch_size = <span class="number">16</span></span><br><span class="line"><span class="comment"># æ ¹æ®GPUè°ƒæ•´batch_sizeå¤§å°ï¼Œé¿å…æ˜¾å­˜æº¢å‡º</span></span><br><span class="line"></span><br></pre></td></tr></table></figure>

<h2 id="2-åŠ è½½æ•°æ®"><a href="#2-åŠ è½½æ•°æ®" class="headerlink" title="2 åŠ è½½æ•°æ®"></a>2 åŠ è½½æ•°æ®</h2><h3 id="2-1-åŠ è½½æ•°æ®å’Œå¯¹åº”çš„è¯„æµ‹æ–¹å¼"><a href="#2-1-åŠ è½½æ•°æ®å’Œå¯¹åº”çš„è¯„æµ‹æ–¹å¼" class="headerlink" title="2.1 åŠ è½½æ•°æ®å’Œå¯¹åº”çš„è¯„æµ‹æ–¹å¼"></a>2.1 åŠ è½½æ•°æ®å’Œå¯¹åº”çš„è¯„æµ‹æ–¹å¼</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> datasets <span class="keyword">import</span> load_dataset, load_metric</span><br><span class="line"></span><br><span class="line">actual_task = <span class="string">&quot;mnli&quot;</span> <span class="keyword">if</span> task == <span class="string">&quot;mnli-mm&quot;</span> <span class="keyword">else</span> task</span><br><span class="line">dataset = load_dataset(<span class="string">&quot;glue&quot;</span>, actual_task)</span><br><span class="line">metric = load_metric(<span class="string">&#x27;glue&#x27;</span>, actual_task</span><br><span class="line"><span class="comment"># MNLI(The Multi-Genre Natural Language Inference Corpus, å¤šç±»å‹è‡ªç„¶è¯­è¨€æ¨ç†æ•°æ®åº“)ï¼Œè‡ªç„¶è¯­è¨€æ¨æ–­ä»»åŠ¡ï¼Œæ˜¯é€šè¿‡ä¼—åŒ…æ–¹å¼å¯¹å¥å­å¯¹è¿›è¡Œæ–‡æœ¬è•´å«æ ‡æ³¨çš„é›†åˆã€‚</span></span><br><span class="line"><span class="comment"># ä»»åŠ¡ï¼šå¥å­å¯¹ï¼Œä¸€ä¸ªå‰æï¼Œä¸€ä¸ªæ˜¯å‡è®¾ã€‚å‰æå’Œå‡è®¾çš„å…³ç³»æœ‰ä¸‰ç§æƒ…å†µï¼šè•´å«ï¼ˆentailmentï¼‰ï¼ŒçŸ›ç›¾ï¼ˆcontradictionï¼‰ï¼Œä¸­ç«‹ï¼ˆneutralï¼‰ã€‚å¥å­å¯¹ä¸‰åˆ†ç±»é—®é¢˜ã€‚</span></span><br><span class="line"></span><br></pre></td></tr></table></figure>
<h3 id="2-2-æŸ¥çœ‹æ•°æ®"><a href="#2-2-æŸ¥çœ‹æ•°æ®" class="headerlink" title="2.2 æŸ¥çœ‹æ•°æ®"></a>2.2 æŸ¥çœ‹æ•°æ®</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">dataset</span><br></pre></td></tr></table></figure>

<pre><code>DatasetDict(&#123;
    train: Dataset(&#123;
        features: [&#39;sentence&#39;, &#39;label&#39;, &#39;idx&#39;],
        num_rows: 8551
    &#125;)
    validation: Dataset(&#123;
        features: [&#39;sentence&#39;, &#39;label&#39;, &#39;idx&#39;],
        num_rows: 1043
    &#125;)
    test: Dataset(&#123;
        features: [&#39;sentence&#39;, &#39;label&#39;, &#39;idx&#39;],
        num_rows: 1063
    &#125;)
&#125;)
</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">dataset[<span class="string">&quot;train&quot;</span>][<span class="number">0</span>]</span><br><span class="line"><span class="comment"># ç»™å®šä¸€ä¸ªæ•°æ®åˆ‡åˆ†çš„keyï¼ˆtrainã€validationæˆ–è€…testï¼‰å’Œä¸‹æ ‡å³å¯æŸ¥çœ‹æ•°æ®ã€‚</span></span><br></pre></td></tr></table></figure>
<pre><code>&#123;&#39;sentence&#39;: &quot;Our friends won&#39;t buy this analysis, let alone the next one we propose.&quot;,
    &#39;label&#39;: 1,
    &#39;idx&#39;: 0&#125;
</code></pre>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">import datasets</span><br><span class="line">import random</span><br><span class="line">import pandas as pd</span><br><span class="line">from IPython.display import display, HTML</span><br><span class="line"></span><br><span class="line">def show_random_elements(dataset, num_examples&#x3D;10):</span><br><span class="line">    assert num_examples &lt;&#x3D; len(dataset), &quot;Can&#39;t pick more elements than there are in the dataset.&quot;</span><br><span class="line">    picks &#x3D; []</span><br><span class="line">    for _ in range(num_examples):</span><br><span class="line">        pick &#x3D; random.randint(0, len(dataset)-1)</span><br><span class="line">        while pick in picks:</span><br><span class="line">            pick &#x3D; random.randint(0, len(dataset)-1)</span><br><span class="line">        picks.append(pick)</span><br><span class="line">    </span><br><span class="line">    df &#x3D; pd.DataFrame(dataset[picks])</span><br><span class="line">    for column, typ in dataset.features.items():</span><br><span class="line">        if isinstance(typ, datasets.ClassLabel):</span><br><span class="line">            df[column] &#x3D; df[column].transform(lambda i: typ.names[i])</span><br><span class="line">    display(HTML(df.to_html()))</span><br></pre></td></tr></table></figure>


<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>sentence</th>
      <th>label</th>
      <th>idx</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>The more I talk to Joe, the less about linguistics I am inclined to think Sally has taught him to appreciate.</td>
      <td>acceptable</td>
      <td>196</td>
    </tr>
    <tr>
      <th>1</th>
      <td>Have in our class the kids arrived safely?</td>
      <td>unacceptable</td>
      <td>3748</td>
    </tr>
    <tr>
      <th>2</th>
      <td>I gave Mary a book.</td>
      <td>acceptable</td>
      <td>5302</td>
    </tr>
    <tr>
      <th>3</th>
      <td>Every student, who attended the party, had a good time.</td>
      <td>unacceptable</td>
      <td>4944</td>
    </tr>
    <tr>
      <th>4</th>
      <td>Bill pounded the metal fiat.</td>
      <td>acceptable</td>
      <td>2178</td>
    </tr>
    <tr>
      <th>5</th>
      <td>It bit me on the leg.</td>
      <td>acceptable</td>
      <td>5908</td>
    </tr>
    <tr>
      <th>6</th>
      <td>The boys were made a good mother by Aunt Mary.</td>
      <td>unacceptable</td>
      <td>736</td>
    </tr>
    <tr>
      <th>7</th>
      <td>More of a man is here.</td>
      <td>unacceptable</td>
      <td>5403</td>
    </tr>
    <tr>
      <th>8</th>
      <td>My mother baked me a birthday cake.</td>
      <td>acceptable</td>
      <td>3761</td>
    </tr>
    <tr>
      <th>9</th>
      <td>Gregory appears to have wanted to be loyal to the company.</td>
      <td>acceptable</td>
      <td>4334</td>
    </tr>
  </tbody>
</table>

<h3 id="2-3-æŸ¥çœ‹è¯„æµ‹æ–¹æ³•åŠå¸¸è§åˆ†ç±»"><a href="#2-3-æŸ¥çœ‹è¯„æµ‹æ–¹æ³•åŠå¸¸è§åˆ†ç±»" class="headerlink" title="2.3 æŸ¥çœ‹è¯„æµ‹æ–¹æ³•åŠå¸¸è§åˆ†ç±»"></a>2.3 æŸ¥çœ‹è¯„æµ‹æ–¹æ³•åŠå¸¸è§åˆ†ç±»</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">metric</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<ul>
<li>meticæ˜¯<a href="https://huggingface.co/docs/datasets/package_reference/main_classes.html#datasets.Metric"><code>datasets.Metric</code></a>çš„ä¸€ä¸ªå®ä¾‹:</li>
</ul>
<pre><code>Metric(name: &quot;glue&quot;, features: &#123;&#39;predictions&#39;: Value(dtype=&#39;int64&#39;, id=None), &#39;references&#39;: Value(dtype=&#39;int64&#39;, id=None)&#125;, usage: &quot;&quot;&quot;
Compute GLUE evaluation metric associated to each GLUE dataset.
Args:
    predictions: list of predictions to score.
        Each translation should be tokenized into a list of tokens.
    references: list of lists of references for each translation.
        Each reference should be tokenized into a list of tokens.
Returns: depending on the GLUE subset, one or several of:
    &quot;accuracy&quot;: Accuracy
    &quot;f1&quot;: F1 score
    &quot;pearson&quot;: Pearson Correlation
    &quot;spearmanr&quot;: Spearman Correlation
    &quot;matthews_correlation&quot;: Matthew Correlation
Examples:

    &gt;&gt;&gt; glue_metric = datasets.load_metric(&#39;glue&#39;, &#39;sst2&#39;)  # &#39;sst2&#39; or any of [&quot;mnli&quot;, &quot;mnli_mismatched&quot;, &quot;mnli_matched&quot;, &quot;qnli&quot;, &quot;rte&quot;, &quot;wnli&quot;, &quot;hans&quot;]
    &gt;&gt;&gt; references = [0, 1]
    &gt;&gt;&gt; predictions = [0, 1]
    &gt;&gt;&gt; results = glue_metric.compute(predictions=predictions, references=references)
    &gt;&gt;&gt; print(results)
    &#123;&#39;accuracy&#39;: 1.0&#125;

    &gt;&gt;&gt; glue_metric = datasets.load_metric(&#39;glue&#39;, &#39;mrpc&#39;)  # &#39;mrpc&#39; or &#39;qqp&#39;
    &gt;&gt;&gt; references = [0, 1]
    &gt;&gt;&gt; predictions = [0, 1]
    &gt;&gt;&gt; results = glue_metric.compute(predictions=predictions, references=references)
    &gt;&gt;&gt; print(results)
    &#123;&#39;accuracy&#39;: 1.0, &#39;f1&#39;: 1.0&#125;

    &gt;&gt;&gt; glue_metric = datasets.load_metric(&#39;glue&#39;, &#39;stsb&#39;)
    &gt;&gt;&gt; references = [0., 1., 2., 3., 4., 5.]
    &gt;&gt;&gt; predictions = [0., 1., 2., 3., 4., 5.]
    &gt;&gt;&gt; results = glue_metric.compute(predictions=predictions, references=references)
    &gt;&gt;&gt; print(&#123;&quot;pearson&quot;: round(results[&quot;pearson&quot;], 2), &quot;spearmanr&quot;: round(results[&quot;spearmanr&quot;], 2)&#125;)
    &#123;&#39;pearson&#39;: 1.0, &#39;spearmanr&#39;: 1.0&#125;

    &gt;&gt;&gt; glue_metric = datasets.load_metric(&#39;glue&#39;, &#39;cola&#39;)
    &gt;&gt;&gt; references = [0, 1]
    &gt;&gt;&gt; predictions = [0, 1]
    &gt;&gt;&gt; results = glue_metric.compute(predictions=predictions, references=references)
    &gt;&gt;&gt; print(results)
    &#123;&#39;matthews_correlation&#39;: 1.0&#125;
&quot;&quot;&quot;, stored examples: 0)
</code></pre>
<p>ç›´æ¥è°ƒç”¨metricçš„<code>compute</code>æ–¹æ³•ï¼Œä¼ å…¥<code>labels</code>å’Œ<code>predictions</code>å³å¯å¾—åˆ°metricçš„å€¼ï¼š</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"></span><br><span class="line">fake_preds = np.random.randint(<span class="number">0</span>, <span class="number">2</span>, size=(<span class="number">64</span>,))</span><br><span class="line">fake_labels = np.random.randint(<span class="number">0</span>, <span class="number">2</span>, size=(<span class="number">64</span>,))</span><br><span class="line">metric.compute(predictions=fake_preds, references=fake_labels)</span><br></pre></td></tr></table></figure>

<pre><code>&#123;&#39;matthews_correlation&#39;: 0.1513518081969605&#125;
</code></pre>
<p>æ¯ä¸€ä¸ªæ–‡æœ¬åˆ†ç±»ä»»åŠ¡æ‰€å¯¹åº”çš„meticæœ‰æ‰€ä¸åŒï¼Œå…·ä½“å¦‚ä¸‹:</p>
<table>
<thead>
<tr>
<th align="center">ä»»åŠ¡</th>
<th align="center">è¯„æµ‹æ–¹æ³•</th>
</tr>
</thead>
<tbody><tr>
<td align="center">CoLA</td>
<td align="center"><a href="https://en.wikipedia.org/wiki/Matthews_correlation_coefficient">Matthews Correlation Coefficient</a></td>
</tr>
<tr>
<td align="center">MNLI</td>
<td align="center">Accuracy</td>
</tr>
<tr>
<td align="center">MRPC</td>
<td align="center">Accuracy and <a href="https://en.wikipedia.org/wiki/F1_score">F1 score</a></td>
</tr>
<tr>
<td align="center">QNLI</td>
<td align="center">Accuracy</td>
</tr>
<tr>
<td align="center">QQP</td>
<td align="center">Accuracy and F1 score</td>
</tr>
<tr>
<td align="center">RTE</td>
<td align="center">Accuracy</td>
</tr>
<tr>
<td align="center">SST-2</td>
<td align="center">Accuracy</td>
</tr>
<tr>
<td align="center">STS-B</td>
<td align="center"><a href="https://en.wikipedia.org/wiki/Pearson_correlation_coefficient">Pearson Correlation Coefficient</a> and <a href="https://en.wikipedia.org/wiki/Spearman%27s_rank_correlation_coefficient">Spearmanâ€™s_Rank_Correlation_Coefficient</a></td>
</tr>
<tr>
<td align="center">WNLI</td>
<td align="center">Accuracy</td>
</tr>
</tbody></table>
<p>æ‰€ä»¥ä¸€å®šè¦å°†metricå’Œä»»åŠ¡å¯¹é½</p>
<h2 id="3-æ•°æ®é¢„å¤„ç†"><a href="#3-æ•°æ®é¢„å¤„ç†" class="headerlink" title="3 æ•°æ®é¢„å¤„ç†"></a>3 æ•°æ®é¢„å¤„ç†</h2><h3 id="3-1-æ•°æ®é¢„å¤„ç†æµç¨‹"><a href="#3-1-æ•°æ®é¢„å¤„ç†æµç¨‹" class="headerlink" title="3.1 æ•°æ®é¢„å¤„ç†æµç¨‹"></a>3.1 æ•°æ®é¢„å¤„ç†æµç¨‹</h3><p>é¢„å¤„ç†ç›®çš„ï¼šæ•°æ®åªæœ‰ç»è¿‡é¢„å¤„ç†åï¼Œæ‰èƒ½ä½œä¸ºå‘é‡å½¢å¼è¾“å…¥modelã€‚</p>
<ul>
<li>æµç¨‹ï¼š<ol>
<li>å¯¹è¾“å…¥æ•°æ®è¿›è¡Œtokenizeï¼Œå¾—åˆ°tokens</li>
<li>å°†tokensè½¬åŒ–ä¸ºé¢„è®­ç»ƒæ¨¡å‹ä¸­éœ€è¦å¯¹åº”çš„token ID</li>
<li>å°†token IDè½¬åŒ–ä¸ºæ¨¡å‹éœ€è¦çš„è¾“å…¥æ ¼å¼</li>
</ol>
</li>
</ul>
<p>ä¸ºäº†è¾¾åˆ°æ•°æ®é¢„å¤„ç†çš„ç›®çš„ï¼Œæˆ‘ä»¬ä½¿ç”¨<code>AutoTokenizer.from_pretrained</code>æ–¹æ³•å®ä¾‹åŒ–æˆ‘ä»¬çš„tokenizerï¼Œè¿™æ ·å¯ä»¥ç¡®ä¿ï¼šï¼ˆï¼Ÿï¼Ÿï¼Ÿï¼Ÿï¼‰</p>
<ul>
<li>æˆ‘ä»¬å¾—åˆ°ä¸€ä¸ªä¸é¢„è®­ç»ƒæ¨¡å‹ä¸€ä¸€å¯¹åº”çš„tokenizerã€‚</li>
<li>ä½¿ç”¨æŒ‡å®šçš„æ¨¡å‹checkpointå¯¹åº”çš„tokenizerçš„æ—¶å€™ï¼Œæˆ‘ä»¬ä¹Ÿä¸‹è½½äº†æ¨¡å‹éœ€è¦çš„è¯è¡¨åº“vocabularyï¼Œå‡†ç¡®æ¥è¯´æ˜¯tokens vocabularyã€‚</li>
</ul>
<p>è¿™ä¸ªè¢«ä¸‹è½½çš„tokens vocabularyä¼šè¢«ç¼“å­˜èµ·æ¥ï¼Œä»è€Œå†æ¬¡ä½¿ç”¨çš„æ—¶å€™ä¸ä¼šé‡æ–°ä¸‹è½½ã€‚</p>
<h3 id="3-2-æ„å»ºæ¨¡å‹å¯¹åº”çš„tokenizer"><a href="#3-2-æ„å»ºæ¨¡å‹å¯¹åº”çš„tokenizer" class="headerlink" title="3.2 æ„å»ºæ¨¡å‹å¯¹åº”çš„tokenizer"></a>3.2 æ„å»ºæ¨¡å‹å¯¹åº”çš„tokenizer</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> transformers <span class="keyword">import</span> AutoTokenizer</span><br><span class="line">    </span><br><span class="line">tokenizer = AutoTokenizer.from_pretrained(model_checkpoint, use_fast=<span class="literal">True</span>)</span><br></pre></td></tr></table></figure>
<p>æ³¨æ„ï¼š</p>
<ul>
<li><code>use_fast=True</code>è¦æ±‚tokenizerå¿…é¡»æ˜¯transformers.PreTrainedTokenizerFastç±»å‹ï¼Œ</li>
<li>å› ä¸ºæˆ‘ä»¬åœ¨é¢„å¤„ç†çš„æ—¶å€™éœ€è¦ç”¨åˆ°fast tokenizerçš„ä¸€äº›ç‰¹æ®Šç‰¹æ€§ï¼ˆæ¯”å¦‚å¤šçº¿ç¨‹å¿«é€Ÿtokenizerï¼‰ã€‚</li>
<li>å¦‚æœå¯¹åº”çš„æ¨¡å‹æ²¡æœ‰fast tokenizerï¼Œå»æ‰è¿™ä¸ªé€‰é¡¹å³å¯ã€‚</li>
<li>å‡ ä¹æ‰€æœ‰æ¨¡å‹å¯¹åº”çš„tokenizeréƒ½æœ‰å¯¹åº”çš„fast tokenizerã€‚æˆ‘ä»¬å¯ä»¥åœ¨<a href="https://huggingface.co/transformers/index.html#bigtable">æ¨¡å‹tokenizerå¯¹åº”è¡¨</a>é‡ŒæŸ¥çœ‹æ‰€æœ‰é¢„è®­ç»ƒæ¨¡å‹å¯¹åº”çš„tokenizeræ‰€æ‹¥æœ‰çš„ç‰¹ç‚¹ã€‚</li>
</ul>
<p>tokenizeræ—¢å¯ä»¥å¯¹å•ä¸ªæ–‡æœ¬è¿›è¡Œé¢„å¤„ç†ï¼Œä¹Ÿå¯ä»¥å¯¹ä¸€å¯¹æ–‡æœ¬è¿›è¡Œé¢„å¤„ç†ï¼Œtokenizeré¢„å¤„ç†åå¾—åˆ°çš„æ•°æ®æ»¡è¶³é¢„è®­ç»ƒæ¨¡å‹è¾“å…¥æ ¼å¼ã€‚</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">tokenizer(<span class="string">&quot;Hello, this one sentence!&quot;</span>, <span class="string">&quot;And this sentence goes with it.&quot;</span>)</span><br></pre></td></tr></table></figure>

<pre><code>&#123;&#39;input_ids&#39;: [101, 7592, 1010, 2023, 2028, 6251, 999, 102, 1998, 2023, 6251, 3632, 2007, 2009, 1012, 102], &#39;attention_mask&#39;: [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]&#125;
</code></pre>
<p>å–å†³äºæˆ‘ä»¬é€‰æ‹©çš„é¢„è®­ç»ƒæ¨¡å‹ï¼Œæˆ‘ä»¬å°†ä¼šçœ‹åˆ°tokenizeræœ‰ä¸åŒçš„è¿”å›ï¼Œtokenizerå’Œé¢„è®­ç»ƒæ¨¡å‹æ˜¯ä¸€ä¸€å¯¹åº”çš„ï¼Œæ›´å¤šä¿¡æ¯å¯ä»¥åœ¨<a href="https://huggingface.co/transformers/preprocessing.html">è¿™é‡Œ</a>è¿›è¡Œå­¦ä¹ ã€‚</p>
<h3 id="3-3-å¯¹æ•°æ®é›†datasetsæ‰€æœ‰æ ·æœ¬è¿›è¡Œé¢„å¤„ç†"><a href="#3-3-å¯¹æ•°æ®é›†datasetsæ‰€æœ‰æ ·æœ¬è¿›è¡Œé¢„å¤„ç†" class="headerlink" title="3.3  å¯¹æ•°æ®é›†datasetsæ‰€æœ‰æ ·æœ¬è¿›è¡Œé¢„å¤„ç†"></a>3.3  å¯¹æ•°æ®é›†datasetsæ‰€æœ‰æ ·æœ¬è¿›è¡Œé¢„å¤„ç†</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># å®šä¹‰å¦‚ä¸‹dictï¼Œç”¨äºå¯¹æ•°æ®æ ¼å¼è¿›è¡Œæ£€æŸ¥</span></span><br><span class="line">task_to_keys = &#123;</span><br><span class="line">    <span class="string">&quot;cola&quot;</span>: (<span class="string">&quot;sentence&quot;</span>, <span class="literal">None</span>),</span><br><span class="line">    <span class="string">&quot;mnli&quot;</span>: (<span class="string">&quot;premise&quot;</span>, <span class="string">&quot;hypothesis&quot;</span>),</span><br><span class="line">    <span class="string">&quot;mnli-mm&quot;</span>: (<span class="string">&quot;premise&quot;</span>, <span class="string">&quot;hypothesis&quot;</span>),</span><br><span class="line">    <span class="string">&quot;mrpc&quot;</span>: (<span class="string">&quot;sentence1&quot;</span>, <span class="string">&quot;sentence2&quot;</span>),</span><br><span class="line">    <span class="string">&quot;qnli&quot;</span>: (<span class="string">&quot;question&quot;</span>, <span class="string">&quot;sentence&quot;</span>),</span><br><span class="line">    <span class="string">&quot;qqp&quot;</span>: (<span class="string">&quot;question1&quot;</span>, <span class="string">&quot;question2&quot;</span>),</span><br><span class="line">    <span class="string">&quot;rte&quot;</span>: (<span class="string">&quot;sentence1&quot;</span>, <span class="string">&quot;sentence2&quot;</span>),</span><br><span class="line">    <span class="string">&quot;sst2&quot;</span>: (<span class="string">&quot;sentence&quot;</span>, <span class="literal">None</span>),</span><br><span class="line">    <span class="string">&quot;stsb&quot;</span>: (<span class="string">&quot;sentence1&quot;</span>, <span class="string">&quot;sentence2&quot;</span>),</span><br><span class="line">    <span class="string">&quot;wnli&quot;</span>: (<span class="string">&quot;sentence1&quot;</span>, <span class="string">&quot;sentence2&quot;</span>),</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>




<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># å¯¹æ•°æ®æ ¼å¼è¿›è¡Œæ£€æŸ¥</span></span><br><span class="line">sentence1_key, sentence2_key = task_to_keys[task]</span><br><span class="line"><span class="keyword">if</span> sentence2_key <span class="keyword">is</span> <span class="literal">None</span>:</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">f&quot;Sentence: <span class="subst">&#123;dataset[<span class="string">&#x27;train&#x27;</span>][<span class="number">0</span>][sentence1_key]&#125;</span>&quot;</span>)</span><br><span class="line"><span class="keyword">else</span>:</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">f&quot;Sentence 1: <span class="subst">&#123;dataset[<span class="string">&#x27;train&#x27;</span>][<span class="number">0</span>][sentence1_key]&#125;</span>&quot;</span>)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">f&quot;Sentence 2: <span class="subst">&#123;dataset[<span class="string">&#x27;train&#x27;</span>][<span class="number">0</span>][sentence2_key]&#125;</span>&quot;</span>)</span><br></pre></td></tr></table></figure>

<pre><code>Sentence: Our friends won&#39;t buy this analysis, let alone the next one we propose.
</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># ç”±ä¸Šé¢æ€è·¯æ„é€ é¢„å¤„ç†å‡½æ•°</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">preprocess_function</span>(<span class="params">examples</span>):</span></span><br><span class="line">    <span class="keyword">if</span> sentence2_key <span class="keyword">is</span> <span class="literal">None</span>:</span><br><span class="line">        <span class="keyword">return</span> tokenizer(examples[sentence1_key], truncation=<span class="literal">True</span>)</span><br><span class="line">    <span class="keyword">return</span> tokenizer(examples[sentence1_key], examples[sentence2_key], truncation=<span class="literal">True</span>)</span><br></pre></td></tr></table></figure>

<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># ä¸¾ä¾‹</span></span><br><span class="line"><span class="comment"># é¢„å¤„ç†å‡½æ•°å¯ä»¥å¤„ç†å•ä¸ªæ ·æœ¬ï¼Œä¹Ÿå¯ä»¥å¯¹å¤šä¸ªæ ·æœ¬è¿›è¡Œå¤„ç†ã€‚å¦‚æœè¾“å…¥æ˜¯å¤šä¸ªæ ·æœ¬ï¼Œé‚£ä¹ˆè¿”å›çš„æ˜¯ä¸€ä¸ªlistï¼š</span></span><br><span class="line">preprocess_function(dataset[<span class="string">&#x27;train&#x27;</span>][:<span class="number">5</span>])</span><br></pre></td></tr></table></figure>

<pre><code>&#123;&#39;input_ids&#39;: [[101, 2256, 2814, 2180, 1005, 1056, 4965, 2023, 4106, 1010, 2292, 2894, 1996, 2279, 2028, 2057, 16599, 1012, 102], [101, 2028, 2062, 18404, 2236, 3989, 1998, 1045, 1005, 1049, 3228, 2039, 1012, 102], [101, 2028, 2062, 18404, 2236, 3989, 2030, 1045, 1005, 1049, 3228, 2039, 1012, 102], [101, 1996, 2062, 2057, 2817, 16025, 1010, 1996, 13675, 16103, 2121, 2027, 2131, 1012, 102], [101, 2154, 2011, 2154, 1996, 8866, 2024, 2893, 14163, 8024, 3771, 1012, 102]], &#39;attention_mask&#39;: [[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]]&#125;
</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># å¯¹datasetsé‡Œæ‰€æœ‰æ ·æœ¬è¿›è¡Œé¢„å¤„ç†</span></span><br><span class="line">encoded_dataset = dataset.<span class="built_in">map</span>(preprocess_function, batched=<span class="literal">True</span>)</span><br><span class="line"><span class="comment"># ä½¿ç”¨mapï¼šå°†é¢„å¤„ç†å‡½æ•°prepare_train_featuresåº”ç”¨åˆ°ï¼ˆmap)æ‰€æœ‰æ ·æœ¬ä¸Šã€‚</span></span><br></pre></td></tr></table></figure>

<p>å¦å¤–ï¼Œè¿”å›çš„ç»“æœä¼šè‡ªåŠ¨è¢«ç¼“å­˜ï¼Œé¿å…ä¸‹æ¬¡å¤„ç†çš„æ—¶å€™é‡æ–°è®¡ç®—ï¼ˆä½†æ˜¯ä¹Ÿè¦æ³¨æ„ï¼Œå¦‚æœè¾“å…¥æœ‰æ”¹åŠ¨ï¼Œå¯èƒ½ä¼šè¢«ç¼“å­˜å½±å“ï¼ï¼‰ã€‚<br>datasetsåº“å‡½æ•°ä¼šå¯¹è¾“å…¥çš„å‚æ•°è¿›è¡Œæ£€æµ‹ï¼Œåˆ¤æ–­æ˜¯å¦æœ‰å˜åŒ–ï¼Œå¦‚æœæ²¡æœ‰å˜åŒ–å°±ä½¿ç”¨ç¼“å­˜æ•°æ®ï¼Œå¦‚æœæœ‰å˜åŒ–å°±é‡æ–°å¤„ç†ã€‚ä½†å¦‚æœè¾“å…¥å‚æ•°ä¸å˜ï¼Œåªæ˜¯æƒ³æ”¹å˜è¾“å…¥æ•°æ®çš„æ—¶å€™ï¼Œæœ€å¥½æ¸…ç†è°ƒè¿™ä¸ªç¼“å­˜ã€‚æ¸…ç†çš„æ–¹å¼æ˜¯ä½¿ç”¨<code>load_from_cache_file=False</code>å‚æ•°ã€‚<br>å¦å¤–ï¼Œä¸Šé¢ä½¿ç”¨åˆ°çš„<code>batched=True</code>è¿™ä¸ªå‚æ•°æ˜¯tokenizerçš„ç‰¹ç‚¹ï¼Œè¿™ä¼šä½¿ç”¨å¤šçº¿ç¨‹åŒæ—¶å¹¶è¡Œå¯¹è¾“å…¥è¿›è¡Œå¤„ç†ã€‚</p>
<h2 id="4-å¾®è°ƒé¢„è®­ç»ƒæ¨¡å‹"><a href="#4-å¾®è°ƒé¢„è®­ç»ƒæ¨¡å‹" class="headerlink" title="4 å¾®è°ƒé¢„è®­ç»ƒæ¨¡å‹"></a>4 å¾®è°ƒé¢„è®­ç»ƒæ¨¡å‹</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> transformers <span class="keyword">import</span> AutoModelForSequenceClassification, TrainingArguments, Trainer</span><br><span class="line"><span class="comment"># åšseq2seqä»»åŠ¡ï¼Œéœ€è¦ä¸€ä¸ªèƒ½è§£å†³è¿™ä¸ªä»»åŠ¡çš„æ¨¡å‹ç±»ã€‚è¿™é‡Œä½¿ç”¨`AutoModelForSequenceClassification`ç±» ã€‚</span></span><br><span class="line">num_labels = <span class="number">3</span> <span class="keyword">if</span> task.startswith(<span class="string">&quot;mnli&quot;</span>) <span class="keyword">else</span> <span class="number">1</span> <span class="keyword">if</span> task==<span class="string">&quot;stsb&quot;</span> <span class="keyword">else</span> <span class="number">2</span></span><br><span class="line">model = AutoModelForSequenceClassification.from_pretrained(model_checkpoint, num_labels=num_labels)</span><br><span class="line"><span class="comment"># `from_pretrained`æ–¹æ³•å¯ä»¥ä¸‹è½½å¹¶åŠ è½½æ¨¡å‹ï¼ŒåŒæ—¶ä¹Ÿä¼šå¯¹æ¨¡å‹è¿›è¡Œç¼“å­˜ã€‚</span></span><br></pre></td></tr></table></figure>
<p>éœ€è¦æ³¨æ„çš„æ˜¯ï¼šSTS-Bæ˜¯ä¸€ä¸ªå›å½’é—®é¢˜ï¼ŒMNLIæ˜¯ä¸€ä¸ª3åˆ†ç±»é—®é¢˜ã€‚</p>
<p>ç”±äºæˆ‘ä»¬å¾®è°ƒçš„ä»»åŠ¡æ˜¯æ–‡æœ¬åˆ†ç±»ä»»åŠ¡ï¼Œè€Œæˆ‘ä»¬åŠ è½½çš„æ˜¯é¢„è®­ç»ƒçš„è¯­è¨€æ¨¡å‹ï¼Œæ‰€ä»¥ä¼šæç¤ºæˆ‘ä»¬åŠ è½½æ¨¡å‹çš„æ—¶å€™æ‰”æ‰äº†ä¸€äº›ä¸åŒ¹é…çš„ç¥ç»ç½‘ç»œå‚æ•°ï¼ˆæ¯”å¦‚ï¼šé¢„è®­ç»ƒè¯­è¨€æ¨¡å‹çš„ç¥ç»ç½‘ç»œheadè¢«æ‰”æ‰äº†ï¼ŒåŒæ—¶éšæœºåˆå§‹åŒ–äº†æ–‡æœ¬åˆ†ç±»çš„ç¥ç»ç½‘ç»œheadï¼‰ã€‚ï¼Ÿï¼Ÿï¼Ÿï¼Ÿ</p>
<h3 id="4-1-è®­ç»ƒå‚æ•°"><a href="#4-1-è®­ç»ƒå‚æ•°" class="headerlink" title="4.1 è®­ç»ƒå‚æ•°"></a>4.1 è®­ç»ƒå‚æ•°</h3><p>è®­ç»ƒçš„è®¾å®š/å‚æ•° <a href="https://huggingface.co/transformers/main_classes/trainer.html#transformers.TrainingArguments"><code>TrainingArguments</code></a>ã€‚</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">metric_name = <span class="string">&quot;pearson&quot;</span> <span class="keyword">if</span> task == <span class="string">&quot;stsb&quot;</span> <span class="keyword">else</span> <span class="string">&quot;matthews_correlation&quot;</span> <span class="keyword">if</span> task == <span class="string">&quot;cola&quot;</span> <span class="keyword">else</span> <span class="string">&quot;accuracy&quot;</span></span><br><span class="line"></span><br><span class="line">args = TrainingArguments(</span><br><span class="line">    <span class="string">&quot;test-glue&quot;</span>,</span><br><span class="line">    evaluation_strategy = <span class="string">&quot;epoch&quot;</span>,</span><br><span class="line">    <span class="comment"># æ¯è®­ç»ƒä¸€ä¸ªepochåšä¸€æ¬¡éªŒè¯è¯„ä¼°</span></span><br><span class="line">    save_strategy = <span class="string">&quot;epoch&quot;</span>,</span><br><span class="line">    learning_rate=<span class="number">2e-5</span>,</span><br><span class="line">    per_device_train_batch_size=batch_size,</span><br><span class="line">    per_device_eval_batch_size=batch_size,</span><br><span class="line">    num_train_epochs=<span class="number">5</span>,</span><br><span class="line">    weight_decay=<span class="number">0.01</span>,</span><br><span class="line">    load_best_model_at_end=<span class="literal">True</span>,</span><br><span class="line">    metric_for_best_model=metric_name,</span><br><span class="line">    <span class="comment"># åŒ…å«äº†èƒ½å¤Ÿå®šä¹‰è®­ç»ƒè¿‡ç¨‹çš„æ‰€æœ‰å±æ€§</span></span><br><span class="line">)</span><br></pre></td></tr></table></figure>
<h3 id="4-2-è¯„ä¼°æ–¹æ³•"><a href="#4-2-è¯„ä¼°æ–¹æ³•" class="headerlink" title="4.2 è¯„ä¼°æ–¹æ³•"></a>4.2 è¯„ä¼°æ–¹æ³•</h3><p>ä¸åŒçš„ä»»åŠ¡éœ€è¦ä¸åŒçš„è¯„ä»·æŒ‡æ ‡ï¼Œå®šä¹‰ä¸€ä¸ªå‡½æ•°æ ¹æ®åå­—åŒ¹é…è¯„ä»·æ–¹æ³•ã€‚</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">compute_metrics</span>(<span class="params">eval_pred</span>):</span></span><br><span class="line">    predictions, labels = eval_pred</span><br><span class="line">    <span class="keyword">if</span> task != <span class="string">&quot;stsb&quot;</span>:</span><br><span class="line">        predictions = np.argmax(predictions, axis=<span class="number">1</span>)</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        predictions = predictions[:, <span class="number">0</span>]</span><br><span class="line">    <span class="keyword">return</span> metric.compute(predictions=predictions, references=labels)</span><br></pre></td></tr></table></figure>

<h3 id="4-3-å°†ä¸Šè¿°å®šä¹‰å¥½çš„å‚æ•°åŠæ–¹æ³•å…¨éƒ¨ä¼ å…¥Trainer"><a href="#4-3-å°†ä¸Šè¿°å®šä¹‰å¥½çš„å‚æ•°åŠæ–¹æ³•å…¨éƒ¨ä¼ å…¥Trainer" class="headerlink" title="4.3 å°†ä¸Šè¿°å®šä¹‰å¥½çš„å‚æ•°åŠæ–¹æ³•å…¨éƒ¨ä¼ å…¥Trainer"></a>4.3 å°†ä¸Šè¿°å®šä¹‰å¥½çš„å‚æ•°åŠæ–¹æ³•å…¨éƒ¨ä¼ å…¥Trainer</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">validation_key = <span class="string">&quot;validation_mismatched&quot;</span> <span class="keyword">if</span> task == <span class="string">&quot;mnli-mm&quot;</span> <span class="keyword">else</span> <span class="string">&quot;validation_matched&quot;</span> <span class="keyword">if</span> task == <span class="string">&quot;mnli&quot;</span> <span class="keyword">else</span> <span class="string">&quot;validation&quot;</span></span><br><span class="line">trainer = Trainer(</span><br><span class="line">    model,</span><br><span class="line">    args,</span><br><span class="line">    train_dataset=encoded_dataset[<span class="string">&quot;train&quot;</span>],</span><br><span class="line">    eval_dataset=encoded_dataset[validation_key],</span><br><span class="line">    tokenizer=tokenizer,</span><br><span class="line">    compute_metrics=compute_metrics</span><br><span class="line">)</span><br></pre></td></tr></table></figure>

<h3 id="4-4-è®­ç»ƒåŠè¯„ä¼°"><a href="#4-4-è®­ç»ƒåŠè¯„ä¼°" class="headerlink" title="4.4 è®­ç»ƒåŠè¯„ä¼°"></a>4.4 è®­ç»ƒåŠè¯„ä¼°</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">trainer.train()</span><br></pre></td></tr></table></figure>

<pre><code>TrainOutput(global_step=2675, training_loss=0.2717150308484229, metrics=&#123;&#39;train_runtime&#39;: 100.5668, &#39;train_samples_per_second&#39;: 425.14, &#39;train_steps_per_second&#39;: 26.599, &#39;total_flos&#39;: 229537542078168.0, &#39;train_loss&#39;: 0.2717150308484229, &#39;epoch&#39;: 5.0&#125;)
</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">trainer.evaluate()</span><br></pre></td></tr></table></figure>




<div>

<p>  <progress value='66' max='66' style='width:300px; height:20px; vertical-align: middle;'></progress><br>  [66/66 00:00]</p>
</div>






<pre><code>&#123;&#39;eval_loss&#39;: 0.8624260425567627,
 &#39;eval_matthews_correlation&#39;: 0.519563286537562,
 &#39;eval_runtime&#39;: 0.6501,
 &#39;eval_samples_per_second&#39;: 1604.31,
 &#39;eval_steps_per_second&#39;: 101.519,
 &#39;epoch&#39;: 5.0&#125;
</code></pre>
<h2 id="5-è¶…å‚æ•°æœç´¢"><a href="#5-è¶…å‚æ•°æœç´¢" class="headerlink" title="5. è¶…å‚æ•°æœç´¢"></a>5. è¶…å‚æ•°æœç´¢</h2><p><code>Trainer</code>åŒæ ·æ”¯æŒè¶…å‚æœç´¢ï¼Œä½¿ç”¨<a href="https://optuna.org/">optuna</a> or <a href="https://docs.ray.io/en/latest/tune/">Ray Tune</a>ä»£ç åº“ã€‚</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">! pip install optuna</span><br><span class="line">! pip install ray[tune]</span><br><span class="line"><span class="comment"># å®‰è£…ä¸¤ä¸ªè¶…å‚æ•°è‡ªåŠ¨è°ƒä¼˜åº“</span></span><br></pre></td></tr></table></figure>

<h3 id="5-1-è®¾ç½®åˆå§‹åŒ–æ¨¡å‹"><a href="#5-1-è®¾ç½®åˆå§‹åŒ–æ¨¡å‹" class="headerlink" title="5.1 è®¾ç½®åˆå§‹åŒ–æ¨¡å‹"></a>5.1 è®¾ç½®åˆå§‹åŒ–æ¨¡å‹</h3><p>è¶…å‚æœç´¢æ—¶ï¼Œ<code>Trainer</code>å°†ä¼šè¿”å›å¤šä¸ªè®­ç»ƒå¥½çš„æ¨¡å‹ï¼Œæ‰€ä»¥éœ€è¦ä¼ å…¥ä¸€ä¸ªå®šä¹‰å¥½çš„æ¨¡å‹ä»è€Œè®©<code>Trainer</code>å¯ä»¥ä¸æ–­é‡æ–°åˆå§‹åŒ–è¯¥ä¼ å…¥çš„æ¨¡å‹ï¼š</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">model_init</span>():</span></span><br><span class="line">    <span class="keyword">return</span> AutoModelForSequenceClassification.from_pretrained(model_checkpoint, num_labels=num_labels)</span><br></pre></td></tr></table></figure>

<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">trainer = Trainer(</span><br><span class="line">    model_init=model_init,</span><br><span class="line">    args=args,</span><br><span class="line">    train_dataset=encoded_dataset[<span class="string">&quot;train&quot;</span>],</span><br><span class="line">    eval_dataset=encoded_dataset[validation_key],</span><br><span class="line">    tokenizer=tokenizer,</span><br><span class="line">    compute_metrics=compute_metrics</span><br><span class="line">)</span><br></pre></td></tr></table></figure>
<h3 id="5-2-ä½¿ç”¨è¶…å‚è°ƒä¼˜åº“"><a href="#5-2-ä½¿ç”¨è¶…å‚è°ƒä¼˜åº“" class="headerlink" title="5.2 ä½¿ç”¨è¶…å‚è°ƒä¼˜åº“"></a>5.2 ä½¿ç”¨è¶…å‚è°ƒä¼˜åº“</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">best_run = trainer.hyperparameter_search(n_trials=<span class="number">10</span>, direction=<span class="string">&quot;maximize&quot;</span>)</span><br><span class="line"><span class="comment"># `hyperparameter_search`ä¼šè¿”å›æ•ˆæœæœ€å¥½çš„æ¨¡å‹ç›¸å…³çš„å‚æ•°</span></span><br></pre></td></tr></table></figure>

<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">best_run</span><br></pre></td></tr></table></figure>


<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">for</span> n, v <span class="keyword">in</span> best_run.hyperparameters.items():</span><br><span class="line">    <span class="built_in">setattr</span>(trainer.args, n, v)</span><br><span class="line"><span class="comment"># å°†æœ€å¥½çš„è¶…å‚æ•°åº”ç”¨äº`Trainner`</span></span><br><span class="line">trainer.train()</span><br></pre></td></tr></table></figure>

<h2 id="6-ä¸Šä¼ æ¨¡å‹åˆ°model-hub"><a href="#6-ä¸Šä¼ æ¨¡å‹åˆ°model-hub" class="headerlink" title="6 ä¸Šä¼ æ¨¡å‹åˆ°model-hub"></a>6 ä¸Šä¼ æ¨¡å‹åˆ°model-hub</h2><p>ç±»ä¼¼äºdocker-hubï¼Œå¯ä»¥ä¸Šä¼ è‡ªå·±é…ç½®å¥½çš„æ¨¡å‹</p>
<p><a href="https://huggingface.co/transformers/model_sharing.html">ä¸Šä¼ æ¨¡å‹åˆ°</a> åˆ°<a href="https://huggingface.co/models"> Model Hub</a></p>
]]></content>
      
        
    </entry>
    
    <entry>
      <title></title>
      <url>/2021/08/24/NLP-Transformer-task03/</url>
      <content type="html"><![CDATA[<p>authorï¼šTongMing<br>Datawhale å¼€æºå­¦ä¹ åœ°å€ï¼š<a href="https://github.com/datawhalechina/learn-nlp-with-transformers">https://github.com/datawhalechina/learn-nlp-with-transformers</a></p>
<h2 id="ä¸ªäººæ€»ç»“"><a href="#ä¸ªäººæ€»ç»“" class="headerlink" title="ä¸ªäººæ€»ç»“"></a>ä¸ªäººæ€»ç»“</h2><p>é¢„è®­ç»ƒï¼šæ ¹æ®MASKçš„æ–¹å¼è¿›è¡Œè‡ªç›‘ç£çš„å­¦ä¹ ï¼Œ<br>å¾®è°ƒï¼šç»“åˆç›‘ç£ä¿¡æ¯è¿›è¡ŒåŠç›‘ç£çš„å­¦ä¹ </p>
<p>BERTæ˜¯transformerçš„encoderéƒ¨åˆ†<br>ELMoå¯ä»¥è¡¨ç¤ºä¸åŒè¯­å¢ƒä¸‹çš„â€œå¤šä¹‰è¯â€</p>
<h2 id="å›¾è§£BERTï¼ˆç²¾åï¼‰"><a href="#å›¾è§£BERTï¼ˆç²¾åï¼‰" class="headerlink" title="å›¾è§£BERTï¼ˆç²¾åï¼‰"></a>å›¾è§£BERTï¼ˆç²¾åï¼‰</h2><h3 id="å‰è¨€"><a href="#å‰è¨€" class="headerlink" title="å‰è¨€"></a>å‰è¨€</h3><p>BERT å¼€å‘çš„ä¸¤ä¸ªæ­¥éª¤ï¼šç¬¬ 1 æ­¥ï¼Œä½ å¯ä»¥ä¸‹è½½é¢„è®­ç»ƒå¥½çš„æ¨¡å‹ï¼ˆè¿™ä¸ªæ¨¡å‹æ˜¯åœ¨æ— æ ‡æ³¨çš„æ•°æ®ä¸Šè®­ç»ƒçš„ï¼‰ã€‚ç„¶ååœ¨ç¬¬ 2 æ­¥åªéœ€è¦å…³å¿ƒæ¨¡å‹å¾®è°ƒå³å¯ã€‚</p>
<h3 id="å¥å­åˆ†ç±»"><a href="#å¥å­åˆ†ç±»" class="headerlink" title="å¥å­åˆ†ç±»"></a>å¥å­åˆ†ç±»</h3><p>ä½¿ç”¨ BERT æœ€ç›´æ¥çš„æ–¹æ³•å°±æ˜¯å¯¹ä¸€ä¸ªå¥å­è¿›è¡Œåˆ†ç±»ã€‚è¿™ä¸ªæ¨¡å‹å¦‚ä¸‹æ‰€ç¤ºï¼š</p>
<p><img src="3-bert-cls.png" alt="BERTå¥å­åˆ†ç±»">å›¾ï¼šBERTå¥å­åˆ†ç±»</p>
<p>ä¸ºäº†è®­ç»ƒè¿™æ ·ä¸€ä¸ªæ¨¡å‹ï¼Œä½ ä¸»è¦éœ€è¦è®­ç»ƒåˆ†ç±»å™¨ï¼ˆä¸Šå›¾ä¸­çš„ Classifierï¼‰ï¼Œåœ¨è®­ç»ƒè¿‡ç¨‹ä¸­ å‡ ä¹ä¸ç”¨æ”¹åŠ¨BERTæ¨¡å‹ã€‚è¿™ä¸ªè®­ç»ƒè¿‡ç¨‹ç§°ä¸ºå¾®è°ƒï¼Œå®ƒèµ·æºäºSemi-supervised Sequence Learning å’Œ ULMFiTã€‚</p>
<p>å…¶ä»–ä¾‹å­è¿˜åŒ…æ‹¬ï¼šé¢„æµ‹è¯­ä¹‰åˆ†æå’Œæ–­è¨€</p>
<h3 id="æ¨¡å‹æ¶æ„"><a href="#æ¨¡å‹æ¶æ„" class="headerlink" title="æ¨¡å‹æ¶æ„"></a>æ¨¡å‹æ¶æ„</h3><p>è®ºæ–‡é‡Œä»‹ç»äº†ä¸¤ç§ä¸åŒæ¨¡å‹å¤§å°çš„ BERTï¼š</p>
<ul>
<li>BERT BASE - ä¸ OpenAI çš„ Transformer å¤§å°ç›¸å½“ï¼Œä»¥ä¾¿æ¯”è¾ƒæ€§èƒ½</li>
<li>BERT LARGE - ä¸€ä¸ªéå¸¸å·¨å¤§çš„æ¨¡å‹ï¼Œå®ƒå–å¾—äº†æœ€å…ˆè¿›çš„ç»“æœ</li>
</ul>
<p>2 ç§ä¸åŒå¤§å°è§„æ¨¡çš„ BERT æ¨¡å‹éƒ½æœ‰å¤§é‡çš„ Encoder å±‚ï¼ˆè®ºæ–‡é‡ŒæŠŠè¿™äº›å±‚ç§°ä¸º Transformer Blocksï¼‰- BASE ç‰ˆæœ¬ç”± 12 å±‚ Encoderï¼ŒLarge ç‰ˆæœ¬æœ‰ 20 å±‚ Encoderã€‚åŒæ—¶ï¼Œè¿™äº› BERT æ¨¡å‹ä¹Ÿæœ‰æ›´å¤§çš„å‰é¦ˆç¥ç»ç½‘ç»œï¼ˆåˆ†åˆ«æœ‰ 768 ä¸ªå’Œ 1024 ä¸ªéšè—å±‚å•å…ƒï¼‰å’Œæ›´å¤šçš„ attention headsï¼ˆåˆ†åˆ«æœ‰ 12 ä¸ªå’Œ 16 ä¸ªï¼‰ï¼Œè¶…è¿‡äº†åŸå§‹ Transformer è®ºæ–‡ä¸­çš„é»˜è®¤é…ç½®å‚æ•°ï¼ˆåŸè®ºæ–‡ä¸­æœ‰ 6 ä¸ª Encoder å±‚ï¼Œ 512 ä¸ªéšè—å±‚å•å…ƒå’Œ 8 ä¸ª attention headsï¼‰ã€‚</p>
<h3 id="æ¨¡å‹è¾“å…¥"><a href="#æ¨¡å‹è¾“å…¥" class="headerlink" title="æ¨¡å‹è¾“å…¥"></a>æ¨¡å‹è¾“å…¥</h3><p><img src="3-bert-input.png" alt="æ¨¡å‹è¾“å…¥">å›¾ï¼šæ¨¡å‹è¾“å…¥</p>
<p>ç¬¬ä¸€ä¸ªè¾“å…¥çš„ token æ˜¯ç‰¹æ®Šçš„ [CLS]ï¼Œå®ƒ çš„å«ä¹‰æ˜¯åˆ†ç±»ï¼ˆclassçš„ç¼©å†™ï¼‰ã€‚</p>
<p>å°±åƒ Transformer ä¸­æ™®é€šçš„ Encoder ä¸€æ ·ï¼ŒBERT å°†ä¸€ä¸²å•è¯ä½œä¸ºè¾“å…¥ï¼Œè¿™äº›å•è¯åœ¨ Encoder çš„æ ˆä¸­ä¸æ–­å‘ä¸ŠæµåŠ¨ã€‚æ¯ä¸€å±‚éƒ½ä¼šç»è¿‡ Self Attention å±‚ï¼Œå¹¶é€šè¿‡ä¸€ä¸ªå‰é¦ˆç¥ç»ç½‘ç»œï¼Œç„¶åå°†ç»“æœä¼ ç»™ä¸‹ä¸€ä¸ª Encoderã€‚</p>
<p><img src="3-bert-encoder.webp" alt="BERT encoder">å›¾ï¼šBERT encoder</p>
<p>åœ¨æ¨¡å‹æ¶æ„æ–¹é¢ï¼Œåˆ°ç›®å‰ä¸ºæ­¢ï¼Œå’Œ Transformer æ˜¯ç›¸åŒçš„ï¼ˆé™¤äº†æ¨¡å‹å¤§å°ï¼Œå› ä¸ºè¿™æ˜¯æˆ‘ä»¬å¯ä»¥æ”¹å˜çš„å‚æ•°ï¼‰ã€‚æˆ‘ä»¬ä¼šåœ¨ä¸‹é¢çœ‹åˆ°ï¼ŒBERT å’Œ Transformer åœ¨æ¨¡å‹çš„è¾“å‡ºä¸Šæœ‰ä¸€äº›ä¸åŒã€‚</p>
<h3 id="æ¨¡å‹è¾“å‡º"><a href="#æ¨¡å‹è¾“å‡º" class="headerlink" title="æ¨¡å‹è¾“å‡º"></a>æ¨¡å‹è¾“å‡º</h3><p>æ¯ä¸ªä½ç½®è¾“å‡ºä¸€ä¸ªå¤§å°ä¸º hidden_sizeï¼ˆåœ¨ BERT Base ä¸­æ˜¯ 768ï¼‰çš„å‘é‡ã€‚å¯¹äºä¸Šé¢æåˆ°çš„å¥å­åˆ†ç±»çš„ä¾‹å­ï¼Œæˆ‘ä»¬åªå…³æ³¨ç¬¬ä¸€ä¸ªä½ç½®çš„è¾“å‡ºï¼ˆè¾“å…¥æ˜¯ [CLS] çš„é‚£ä¸ªä½ç½®ï¼‰ã€‚</p>
<p><img src="3-bert-output.png" alt="BERT output">å›¾ï¼šBERT output</p>
<p>è¿™ä¸ªè¾“å‡ºçš„å‘é‡ç°åœ¨å¯ä»¥ä½œä¸ºåé¢åˆ†ç±»å™¨çš„è¾“å…¥ã€‚è®ºæ–‡é‡Œç”¨å•å±‚ç¥ç»ç½‘ç»œä½œä¸ºåˆ†ç±»å™¨ï¼Œå–å¾—äº†å¾ˆå¥½çš„æ•ˆæœã€‚</p>
<p><img src="3-bert-clss.webp" alt="BERT æ¥åˆ†ç±»å™¨">å›¾ï¼šBERT æ¥åˆ†ç±»å™¨</p>
<p>å¦‚æœä½ æœ‰æ›´å¤šæ ‡ç­¾ï¼ˆä¾‹å¦‚ä½ æ˜¯ä¸€ä¸ªç”µå­é‚®ä»¶æœåŠ¡ï¼Œéœ€è¦å°†é‚®ä»¶æ ‡è®°ä¸º â€œåƒåœ¾é‚®ä»¶â€ã€â€œéåƒåœ¾é‚®ä»¶â€ã€â€œç¤¾äº¤â€ã€â€œæ¨å¹¿â€ï¼‰ï¼Œä½ åªéœ€è¦è°ƒæ•´åˆ†ç±»å™¨çš„ç¥ç»ç½‘ç»œï¼Œå¢åŠ è¾“å‡ºçš„ç¥ç»å…ƒä¸ªæ•°ï¼Œç„¶åç»è¿‡ softmax å³å¯ã€‚</p>
<h3 id="ä¸å·ç§¯ç¥ç»ç½‘ç»œè¿›è¡Œå¯¹æ¯”"><a href="#ä¸å·ç§¯ç¥ç»ç½‘ç»œè¿›è¡Œå¯¹æ¯”" class="headerlink" title="ä¸å·ç§¯ç¥ç»ç½‘ç»œè¿›è¡Œå¯¹æ¯”"></a>ä¸å·ç§¯ç¥ç»ç½‘ç»œè¿›è¡Œå¯¹æ¯”</h3><p>å¯¹äºé‚£äº›æœ‰è®¡ç®—æœºè§†è§‰èƒŒæ™¯çš„äººæ¥è¯´ï¼Œè¿™ä¸ªå‘é‡ä¼ é€’è¿‡ç¨‹ï¼Œä¼šè®©äººè”æƒ³åˆ° VGGNet ç­‰ç½‘ç»œçš„å·ç§¯éƒ¨åˆ†ï¼Œå’Œç½‘ç»œæœ€åçš„å…¨è¿æ¥åˆ†ç±»éƒ¨åˆ†ä¹‹é—´çš„è¿‡ç¨‹ã€‚</p>
<p><img src="3-cnn.png" alt="CNN">å›¾ï¼šCNN</p>
<h3 id="è¯åµŒå…¥ï¼ˆEmbeddingï¼‰çš„æ–°æ—¶ä»£"><a href="#è¯åµŒå…¥ï¼ˆEmbeddingï¼‰çš„æ–°æ—¶ä»£" class="headerlink" title="è¯åµŒå…¥ï¼ˆEmbeddingï¼‰çš„æ–°æ—¶ä»£"></a>è¯åµŒå…¥ï¼ˆEmbeddingï¼‰çš„æ–°æ—¶ä»£</h3><p>ä¸Šé¢æåˆ°çš„è¿™äº›æ–°å‘å±•å¸¦æ¥äº†æ–‡æœ¬ç¼–ç æ–¹å¼çš„æ–°è½¬å˜ã€‚åˆ°ç›®å‰ä¸ºæ­¢ï¼Œè¯åµŒå…¥ä¸€ç›´æ˜¯ NLP æ¨¡å‹å¤„ç†è¯­è¨€çš„ä¸»è¦è¡¨ç¤ºæ–¹æ³•ã€‚åƒ Word2Vec å’Œ Glove è¿™æ ·çš„æ–¹æ³•å·²ç»è¢«å¹¿æ³›åº”ç”¨äºæ­¤ç±»ä»»åŠ¡ã€‚åœ¨æˆ‘ä»¬è®¨è®ºæ–°çš„æ–¹æ³•ä¹‹å‰ï¼Œè®©æˆ‘ä»¬å›é¡¾ä¸€ä¸‹å®ƒä»¬æ˜¯å¦‚ä½•åº”ç”¨çš„ã€‚</p>
<h4 id="å›é¡¾è¯åµŒå…¥"><a href="#å›é¡¾è¯åµŒå…¥" class="headerlink" title="å›é¡¾è¯åµŒå…¥"></a>å›é¡¾è¯åµŒå…¥</h4><p>å•è¯ä¸èƒ½ç›´æ¥è¾“å…¥æœºå™¨å­¦ä¹ æ¨¡å‹ï¼Œè€Œéœ€è¦æŸç§æ•°å€¼è¡¨ç¤ºå½¢å¼ï¼Œä»¥ä¾¿æ¨¡å‹èƒ½å¤Ÿåœ¨è®¡ç®—ä¸­ä½¿ç”¨ã€‚é€šè¿‡ Word2Vecï¼Œæˆ‘ä»¬å¯ä»¥ä½¿ç”¨ä¸€ä¸ªå‘é‡ï¼ˆä¸€ç»„æ•°å­—ï¼‰æ¥æ°å½“åœ°è¡¨ç¤ºå•è¯ï¼Œå¹¶æ•æ‰å•è¯çš„è¯­ä¹‰ä»¥åŠå•è¯å’Œå•è¯ä¹‹é—´çš„å…³ç³»ï¼ˆä¾‹å¦‚ï¼Œåˆ¤æ–­å•è¯æ˜¯å¦ç›¸ä¼¼æˆ–è€…ç›¸åï¼Œæˆ–è€…åƒ â€œStockholmâ€ å’Œ â€œSwedenâ€ è¿™æ ·çš„ä¸€å¯¹è¯ï¼Œä¸ â€œCairoâ€ å’Œ â€œEgyptâ€è¿™ä¸€å¯¹è¯ï¼Œæ˜¯å¦æœ‰åŒæ ·çš„å…³ç³»ï¼‰ä»¥åŠå¥æ³•ã€è¯­æ³•å…³ç³»ï¼ˆä¾‹å¦‚ï¼Œâ€hadâ€ å’Œ â€œhasâ€ ä¹‹é—´çš„å…³ç³»ä¸ â€œwasâ€ å’Œ â€œisâ€ ä¹‹é—´çš„å…³ç³»ç›¸åŒï¼‰ã€‚</p>
<p>äººä»¬å¾ˆå¿«æ„è¯†åˆ°ï¼Œç›¸æ¯”äºåœ¨å°è§„æ¨¡æ•°æ®é›†ä¸Šå’Œæ¨¡å‹ä¸€èµ·è®­ç»ƒè¯åµŒå…¥ï¼Œæ›´å¥½çš„ä¸€ç§åšæ³•æ˜¯ï¼Œåœ¨å¤§è§„æ¨¡æ–‡æœ¬æ•°æ®ä¸Šé¢„è®­ç»ƒå¥½è¯åµŒå…¥ï¼Œç„¶åæ‹¿æ¥ä½¿ç”¨ã€‚å› æ­¤ï¼Œæˆ‘ä»¬å¯ä»¥ä¸‹è½½ç”± Word2Vec å’Œ GloVe é¢„è®­ç»ƒå¥½çš„å•è¯åˆ—è¡¨ï¼ŒåŠå…¶è¯åµŒå…¥ã€‚ä¸‹é¢æ˜¯å•è¯ â€œstickâ€ çš„ Glove è¯åµŒå…¥å‘é‡çš„ä¾‹å­ï¼ˆè¯åµŒå…¥å‘é‡é•¿åº¦æ˜¯ 200ï¼‰ã€‚</p>
<p><img src="3-wordvector.webp" alt="wrod vector">å›¾ï¼š wrod vector</p>
<p>å•è¯ â€œstickâ€ çš„ Glove è¯åµŒå…¥ - ä¸€ä¸ªç”±200ä¸ªæµ®ç‚¹æ•°ç»„æˆçš„å‘é‡ï¼ˆå››èˆäº”å…¥åˆ°å°æ•°ç‚¹åä¸¤ä½ï¼‰ã€‚</p>
<h4 id="è¯­å¢ƒé—®é¢˜"><a href="#è¯­å¢ƒé—®é¢˜" class="headerlink" title="è¯­å¢ƒé—®é¢˜"></a>è¯­å¢ƒé—®é¢˜</h4><p>å¦‚æœæˆ‘ä»¬ä½¿ç”¨ Glove çš„è¯åµŒå…¥è¡¨ç¤ºæ–¹æ³•ï¼Œé‚£ä¹ˆä¸ç®¡ä¸Šä¸‹æ–‡æ˜¯ä»€ä¹ˆï¼Œå•è¯ â€œstickâ€ éƒ½åªè¡¨ç¤ºä¸ºåŒä¸€ä¸ªå‘é‡ã€‚ä¸€äº›ç ”ç©¶äººå‘˜æŒ‡å‡ºï¼Œåƒ â€œstickâ€ è¿™æ ·çš„è¯æœ‰å¤šç§å«ä¹‰ã€‚ä¸ºä»€ä¹ˆä¸èƒ½æ ¹æ®å®ƒä½¿ç”¨çš„ä¸Šä¸‹æ–‡æ¥å­¦ä¹ å¯¹åº”çš„è¯åµŒå…¥å‘¢ï¼Ÿè¿™æ ·æ—¢èƒ½æ•æ‰å•è¯çš„è¯­ä¹‰ä¿¡æ¯ï¼Œåˆèƒ½æ•æ‰ä¸Šä¸‹æ–‡çš„è¯­ä¹‰ä¿¡æ¯ã€‚äºæ˜¯ï¼Œè¯­å¢ƒåŒ–çš„è¯åµŒå…¥æ¨¡å‹åº”è¿è€Œç”Ÿã€‚<br><img src="3-elmo.webp" alt="ELMO">å›¾ï¼šELMO<br>è¯­å¢ƒåŒ–çš„è¯åµŒå…¥ï¼Œå¯ä»¥æ ¹æ®å•è¯åœ¨å¥å­è¯­å¢ƒä¸­çš„å«ä¹‰ï¼Œèµ‹äºˆä¸åŒçš„è¯åµŒå…¥ã€‚ä½ å¯ä»¥æŸ¥çœ‹è¿™ä¸ªè§†é¢‘ RIP Robin Williamsï¼ˆ<a href="https://zhuanlan.zhihu.com/RIP">https://zhuanlan.zhihu.com/RIP</a> Robin Williamsï¼‰</p>
<p>ELMo æ²¡æœ‰å¯¹æ¯ä¸ªå•è¯ä½¿ç”¨å›ºå®šçš„è¯åµŒå…¥ï¼Œè€Œæ˜¯åœ¨ä¸ºæ¯ä¸ªè¯åˆ†é…è¯åµŒå…¥ä¹‹å‰ï¼ŒæŸ¥çœ‹æ•´ä¸ªå¥å­ï¼Œèåˆä¸Šä¸‹æ–‡ä¿¡æ¯ã€‚å®ƒä½¿ç”¨åœ¨ç‰¹å®šä»»åŠ¡ä¸Šç»è¿‡è®­ç»ƒçš„åŒå‘ LSTM æ¥åˆ›å»ºè¿™äº›è¯åµŒå…¥ã€‚</p>
<p>ELMo åœ¨è¯­å¢ƒåŒ–çš„é¢„è®­ç»ƒè¿™æ¡é“è·¯ä¸Šè¿ˆå‡ºäº†é‡è¦çš„ä¸€æ­¥ã€‚ELMo LSTM ä¼šåœ¨ä¸€ä¸ªå¤§è§„æ¨¡çš„æ•°æ®é›†ä¸Šè¿›è¡Œè®­ç»ƒï¼Œç„¶åæˆ‘ä»¬å¯ä»¥å°†å®ƒä½œä¸ºå…¶ä»–è¯­è¨€å¤„ç†æ¨¡å‹çš„ä¸€ä¸ªéƒ¨åˆ†ï¼Œæ¥å¤„ç†è‡ªç„¶è¯­è¨€ä»»åŠ¡ã€‚</p>
<p>é‚£ä¹ˆ ELMo çš„ç§˜å¯†æ˜¯ä»€ä¹ˆå‘¢ï¼Ÿ</p>
<p>ELMo é€šè¿‡è®­ç»ƒï¼Œé¢„æµ‹å•è¯åºåˆ—ä¸­çš„ä¸‹ä¸€ä¸ªè¯ï¼Œä»è€Œè·å¾—äº†è¯­è¨€ç†è§£èƒ½åŠ›ï¼Œè¿™é¡¹ä»»åŠ¡è¢«ç§°ä¸ºè¯­è¨€å»ºæ¨¡ã€‚è¦å®ç° ELMo å¾ˆæ–¹ä¾¿ï¼Œå› ä¸ºæˆ‘ä»¬æœ‰å¤§é‡æ–‡æœ¬æ•°æ®ï¼Œæ¨¡å‹å¯ä»¥ä»è¿™äº›æ•°æ®ä¸­å­¦ä¹ ï¼Œè€Œä¸éœ€è¦é¢å¤–çš„æ ‡ç­¾ã€‚</p>
<p><img src="3-elmo-pre.webp" alt="ELMO è®­ç»ƒ">å›¾ï¼š ELMO è®­ç»ƒ</p>
<p>ELMo é¢„è®­ç»ƒè¿‡ç¨‹çš„å…¶ä¸­ä¸€ä¸ªæ­¥éª¤ï¼šä»¥ â€œLetâ€™s stick toâ€ ä½œä¸ºè¾“å…¥ï¼Œé¢„æµ‹ä¸‹ä¸€ä¸ªæœ€æœ‰å¯èƒ½çš„å•è¯ã€‚è¿™æ˜¯ä¸€ä¸ªè¯­è¨€å»ºæ¨¡ä»»åŠ¡ã€‚å½“æˆ‘ä»¬åœ¨å¤§è§„æ¨¡æ•°æ®é›†ä¸Šè®­ç»ƒæ—¶ï¼Œæ¨¡å‹å¼€å§‹å­¦ä¹ è¯­è¨€çš„æ¨¡å¼ã€‚ä¾‹å¦‚ï¼Œåœ¨ â€œhangâ€ è¿™æ ·çš„è¯ä¹‹åï¼Œæ¨¡å‹å°†ä¼šèµ‹äºˆ â€œoutâ€ æ›´é«˜çš„æ¦‚ç‡ï¼ˆå› ä¸º â€œhang outâ€ æ˜¯ä¸€ä¸ªè¯ç»„ï¼‰ï¼Œè€Œä¸æ˜¯ â€œcameraâ€ã€‚</p>
<p>åœ¨ä¸Šå›¾ä¸­ï¼Œæˆ‘ä»¬å¯ä»¥çœ‹åˆ° ELMo å¤´éƒ¨ä¸Šæ–¹å±•ç¤ºäº† LSTM çš„æ¯ä¸€æ­¥çš„éšè—å±‚çŠ¶æ€å‘é‡ã€‚åœ¨è¿™ä¸ªé¢„è®­ç»ƒè¿‡ç¨‹å®Œæˆåï¼Œè¿™äº›éšè—å±‚çŠ¶æ€åœ¨è¯åµŒå…¥è¿‡ç¨‹ä¸­æ´¾ä¸Šç”¨åœºã€‚</p>
<p><img src="3-elmo-pre1.png" alt="ELMO è®­ç»ƒ stick">å›¾ï¼šELMO è®­ç»ƒ</p>
<p>ELMo é€šè¿‡å°†éšè—å±‚çŠ¶æ€ï¼ˆä»¥åŠåˆå§‹åŒ–çš„è¯åµŒå…¥ï¼‰ä»¥æŸç§æ–¹å¼ï¼ˆå‘é‡æ‹¼æ¥ä¹‹ååŠ æƒæ±‚å’Œï¼‰ç»“åˆåœ¨ä¸€èµ·ï¼Œå®ç°äº†å¸¦æœ‰è¯­å¢ƒåŒ–çš„è¯åµŒå…¥ã€‚</p>
<p><img src="3-elmo-pre2.webp" alt="ELMO è®­ç»ƒ stick">å›¾ï¼šELMO è®­ç»ƒ</p>
<p>ULM-FiTï¼šNLP é¢†åŸŸçš„è¿ç§»å­¦ä¹ <br>ULM-FiT æå‡ºäº†ä¸€äº›æ–¹æ³•æ¥æœ‰æ•ˆåœ°åˆ©ç”¨æ¨¡å‹åœ¨é¢„è®­ç»ƒæœŸé—´å­¦ä¹ åˆ°çš„ä¸œè¥¿ - è¿™äº›ä¸œè¥¿ä¸ä»…ä»…æ˜¯è¯åµŒå…¥ï¼Œè¿˜æœ‰è¯­å¢ƒåŒ–çš„è¯åµŒå…¥ã€‚ULM-FiT æå‡ºäº†ä¸€ä¸ªè¯­è¨€æ¨¡å‹å’Œä¸€å¥—æµç¨‹ï¼Œå¯ä»¥æœ‰æ•ˆåœ°ä¸ºå„ç§ä»»åŠ¡å¾®è°ƒè¿™ä¸ªè¯­è¨€æ¨¡å‹ã€‚</p>
<p>ç°åœ¨ï¼ŒNLP å¯èƒ½ç»ˆäºæ‰¾åˆ°äº†å¥½çš„æ–¹æ³•ï¼Œå¯ä»¥åƒè®¡ç®—æœºè§†è§‰é‚£æ ·è¿›è¡Œè¿ç§»å­¦ä¹ äº†ã€‚</p>
<h3 id="Transformerï¼šè¶…è¶Š-LSTM"><a href="#Transformerï¼šè¶…è¶Š-LSTM" class="headerlink" title="Transformerï¼šè¶…è¶Š LSTM"></a>Transformerï¼šè¶…è¶Š LSTM</h3><p>Transformer è®ºæ–‡å’Œä»£ç çš„å‘å¸ƒï¼Œä»¥åŠå®ƒåœ¨æœºå™¨ç¿»è¯‘ç­‰ä»»åŠ¡ä¸Šå–å¾—çš„æˆæœï¼Œå¼€å§‹è®©äººä»¬è®¤ä¸ºå®ƒæ˜¯ LSTM çš„æ›¿ä»£å“ã€‚è¿™æ˜¯å› ä¸º Transformer å¯ä»¥æ¯” LSTM æ›´å¥½åœ°å¤„ç†é•¿æœŸä¾èµ–ã€‚</p>
<p>Transformer çš„ Encoder-Decoder ç»“æ„ä½¿å¾—å®ƒéå¸¸é€‚åˆæœºå™¨ç¿»è¯‘ã€‚ä½†ä½ æ€ä¹ˆæ‰èƒ½ç”¨å®ƒæ¥åšæ–‡æœ¬åˆ†ç±»å‘¢ï¼Ÿä½ æ€ä¹ˆæ‰èƒ½ä½¿ç”¨å®ƒæ¥é¢„è®­ç»ƒä¸€ä¸ªè¯­è¨€æ¨¡å‹ï¼Œå¹¶èƒ½å¤Ÿåœ¨å…¶ä»–ä»»åŠ¡ä¸Šè¿›è¡Œå¾®è°ƒï¼ˆä¸‹æ¸¸ä»»åŠ¡æ˜¯æŒ‡é‚£äº›èƒ½å¤Ÿåˆ©ç”¨é¢„è®­ç»ƒæ¨¡å‹çš„ç›‘ç£å­¦ä¹ ä»»åŠ¡ï¼‰ï¼Ÿ</p>
<h3 id="OpenAI-Transformerï¼šé¢„è®­ç»ƒä¸€ä¸ª-Transformer-Decoder-æ¥è¿›è¡Œè¯­è¨€å»ºæ¨¡"><a href="#OpenAI-Transformerï¼šé¢„è®­ç»ƒä¸€ä¸ª-Transformer-Decoder-æ¥è¿›è¡Œè¯­è¨€å»ºæ¨¡" class="headerlink" title="OpenAI Transformerï¼šé¢„è®­ç»ƒä¸€ä¸ª Transformer Decoder æ¥è¿›è¡Œè¯­è¨€å»ºæ¨¡"></a>OpenAI Transformerï¼šé¢„è®­ç»ƒä¸€ä¸ª Transformer Decoder æ¥è¿›è¡Œè¯­è¨€å»ºæ¨¡</h3><p>äº‹å®è¯æ˜ï¼Œæˆ‘ä»¬ä¸éœ€è¦ä¸€ä¸ªå®Œæ•´çš„ Transformer æ¥è¿›è¡Œè¿ç§»å­¦ä¹ å’Œå¾®è°ƒã€‚æˆ‘ä»¬åªéœ€è¦ Transformer çš„ Decoder å°±å¯ä»¥äº†ã€‚Decoder æ˜¯ä¸€ä¸ªå¾ˆå¥½çš„é€‰æ‹©ï¼Œç”¨å®ƒæ¥åšè¯­è¨€å»ºæ¨¡ï¼ˆé¢„æµ‹ä¸‹ä¸€ä¸ªè¯ï¼‰æ˜¯å¾ˆè‡ªç„¶çš„ï¼Œå› ä¸ºå®ƒå¯ä»¥<strong>å±è”½åæ¥çš„è¯</strong> ã€‚å½“ä½ ä½¿ç”¨å®ƒè¿›è¡Œé€è¯ç¿»è¯‘æ—¶ï¼Œè¿™æ˜¯ä¸ªå¾ˆæœ‰ç”¨çš„ç‰¹æ€§ã€‚</p>
<p><img src="3-openai.webp" alt="open aiæ¨¡å‹">å›¾ï¼š open aiæ¨¡å‹</p>
<p>OpenAI Transformer æ˜¯ç”± Transformer çš„ Decoder å †å è€Œæˆçš„</p>
<p>è¿™ä¸ªæ¨¡å‹åŒ…æ‹¬ 12 ä¸ª Decoder å±‚ã€‚å› ä¸ºåœ¨è¿™ç§è®¾è®¡ä¸­æ²¡æœ‰ Encoderï¼Œ<strong>è¿™äº› Decoder å±‚ä¸ä¼šåƒæ™®é€šçš„ Transformer ä¸­çš„ Decoder å±‚é‚£æ ·æœ‰ Encoder-Decoder Attention å­å±‚</strong>ã€‚ä¸è¿‡ï¼Œå®ƒä»ç„¶ä¼šæœ‰ Self Attention å±‚ï¼ˆè¿™äº›å±‚ä½¿ç”¨äº† maskï¼Œå› æ­¤ä¸ä¼šçœ‹åˆ°å¥å­åæ¥çš„ tokenï¼‰ã€‚</p>
<p><img src="3-openai-next.webp" alt="open aiæ¨¡å‹é¢„æµ‹ä¸‹ä¸€ä¸ªè¯">å›¾ï¼š open aiæ¨¡å‹é¢„æµ‹ä¸‹ä¸€ä¸ªè¯</p>
<p>ä¸Šå›¾è¡¨ç¤ºï¼šOpenAI Transformer åœ¨ 7000 æœ¬ä¹¦çš„ç»„æˆçš„æ•°æ®é›†ä¸­é¢„æµ‹ä¸‹ä¸€ä¸ªå•è¯ã€‚</p>
<h3 id="ä¸‹æ¸¸ä»»åŠ¡çš„è¿ç§»å­¦ä¹ "><a href="#ä¸‹æ¸¸ä»»åŠ¡çš„è¿ç§»å­¦ä¹ " class="headerlink" title="ä¸‹æ¸¸ä»»åŠ¡çš„è¿ç§»å­¦ä¹ "></a>ä¸‹æ¸¸ä»»åŠ¡çš„è¿ç§»å­¦ä¹ </h3><p>ç°åœ¨ï¼ŒOpenAI Transformer å·²ç»ç»è¿‡äº†é¢„è®­ç»ƒï¼Œå®ƒçš„ç½‘ç»œå±‚ç»è¿‡è°ƒæ•´ï¼Œå¯ä»¥å¾ˆå¥½åœ°å¤„ç†æ–‡æœ¬è¯­è¨€ï¼Œæˆ‘ä»¬å¯ä»¥å¼€å§‹ä½¿ç”¨å®ƒæ¥å¤„ç†ä¸‹æ¸¸ä»»åŠ¡ã€‚è®©æˆ‘ä»¬å…ˆçœ‹ä¸‹å¥å­åˆ†ç±»ä»»åŠ¡ï¼ˆæŠŠç”µå­é‚®ä»¶åˆ†ç±»ä¸º â€åƒåœ¾é‚®ä»¶â€œ æˆ–è€… â€éåƒåœ¾é‚®ä»¶â€œï¼‰ï¼š</p>
<p><img src="3-openai-down.png" alt="open aiæ¨¡å‹ä¸‹æ¸¸ä»»åŠ¡">å›¾ï¼š open aiæ¨¡å‹ä¸‹æ¸¸ä»»åŠ¡</p>
<p>ä¸‹é¢è¿™å¼ å›¾ç‰‡æ¥æºäºè®ºæ–‡ï¼Œå±•ç¤ºäº†æ‰§è¡Œä¸åŒä»»åŠ¡çš„æ¨¡å‹ç»“æ„å’Œå¯¹åº”è¾“å…¥å˜æ¢ã€‚è¿™äº›éƒ½æ˜¯éå¸¸å¾ˆå·§å¦™çš„åšæ³•ã€‚</p>
<p><img src="3-openai-method.webp" alt="open aiå¾®è°ƒ">å›¾ï¼š open aiå¾®è°ƒ</p>
<h2 id="BERTï¼šä»-Decoder-åˆ°-Encoder"><a href="#BERTï¼šä»-Decoder-åˆ°-Encoder" class="headerlink" title="BERTï¼šä» Decoder åˆ° Encoder"></a>BERTï¼šä» Decoder åˆ° Encoder</h2><p>OpenAI Transformer ä¸ºæˆ‘ä»¬æä¾›äº†ä¸€ä¸ªåŸºäº Transformer çš„å¯ä»¥å¾®è°ƒçš„é¢„è®­ç»ƒç½‘ç»œã€‚ä½†æ˜¯åœ¨æŠŠ LSTM æ¢æˆ Transformer çš„è¿‡ç¨‹ä¸­ï¼Œæœ‰äº›ä¸œè¥¿ä¸¢å¤±äº†ã€‚ELMo çš„è¯­è¨€æ¨¡å‹æ˜¯åŒå‘çš„ï¼Œä½† OpenAI Transformer åªè®­ç»ƒäº†ä¸€ä¸ªå‰å‘çš„è¯­è¨€æ¨¡å‹ã€‚æˆ‘ä»¬æ˜¯å¦å¯ä»¥æ„å»ºä¸€ä¸ªåŸºäº Transformer çš„è¯­è¨€æ¨¡å‹ï¼Œå®ƒæ—¢å‘å‰çœ‹ï¼Œåˆå‘åçœ‹ï¼ˆç”¨æŠ€æœ¯æœ¯è¯­æ¥è¯´ - èåˆä¸Šæ–‡å’Œä¸‹æ–‡çš„ä¿¡æ¯ï¼‰ã€‚</p>
<p>ï¼Ÿï¼Ÿï¼Ÿï¼Ÿdecoderä¸­æ²¡æœ‰å‰åå‘çš„attentionå—ï¼Ÿ</p>
<h3 id="Masked-Language-Modelï¼ˆMLM-è¯­è¨€æ¨¡å‹ï¼‰"><a href="#Masked-Language-Modelï¼ˆMLM-è¯­è¨€æ¨¡å‹ï¼‰" class="headerlink" title="Masked Language Modelï¼ˆMLM è¯­è¨€æ¨¡å‹ï¼‰"></a>Masked Language Modelï¼ˆMLM è¯­è¨€æ¨¡å‹ï¼‰</h3><p>é‚£ä¹ˆå¦‚ä½•æ‰èƒ½åƒ LSTM é‚£æ ·ï¼Œèåˆä¸Šæ–‡å’Œä¸‹æ–‡çš„åŒå‘ä¿¡æ¯å‘¢ï¼Ÿ</p>
<p>ä¸€ç§ç›´è§‚çš„æƒ³æ³•æ˜¯ä½¿ç”¨ Transformer çš„ Encoderã€‚ä½†æ˜¯ Encoder çš„ Self Attention å±‚ï¼Œæ¯ä¸ª token ä¼šæŠŠå¤§éƒ¨åˆ†æ³¨æ„åŠ›é›†ä¸­åˆ°è‡ªå·±èº«ä¸Šï¼Œé‚£ä¹ˆè¿™æ ·å°†å®¹æ˜“é¢„æµ‹åˆ°æ¯ä¸ª tokenï¼Œæ¨¡å‹å­¦ä¸åˆ°æœ‰ç”¨çš„ä¿¡æ¯ã€‚BERT æå‡ºä½¿ç”¨ maskï¼ŒæŠŠéœ€è¦é¢„æµ‹çš„è¯å±è”½æ‰ã€‚</p>
<p>ä¸‹é¢è¿™æ®µé£è¶£çš„å¯¹è¯æ˜¯åšå®¢åŸæ–‡çš„ã€‚</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">BERT è¯´ï¼Œâ€œæˆ‘ä»¬è¦ç”¨ Transformer çš„ Encoderâ€ã€‚</span><br><span class="line"></span><br><span class="line">Ernie è¯´ï¼Œâ€è¿™æ²¡ä»€ä¹ˆç”¨ï¼Œå› ä¸ºæ¯ä¸ª token éƒ½ä¼šåœ¨å¤šå±‚çš„åŒå‘ä¸Šä¸‹æ–‡ä¸­çœ‹åˆ°è‡ªå·±â€œã€‚</span><br><span class="line"></span><br><span class="line">BERT è‡ªä¿¡åœ°è¯´ï¼Œâ€æˆ‘ä»¬ä¼šä½¿ç”¨ maskâ€œã€‚</span><br></pre></td></tr></table></figure>
<p><img src="3-bert-mask.webp" alt="BERT mask">å›¾ï¼š BERT mask</p>
<p>BERT åœ¨è¯­è¨€å»ºæ¨¡ä»»åŠ¡ä¸­ï¼Œå·§å¦™åœ°å±è”½äº†è¾“å…¥ä¸­ 15% çš„å•è¯ï¼Œå¹¶è®©æ¨¡å‹é¢„æµ‹è¿™äº›å±è”½ä½ç½®çš„å•è¯ã€‚</p>
<p>æ‰¾åˆ°åˆé€‚çš„ä»»åŠ¡æ¥è®­ç»ƒä¸€ä¸ª Transformer çš„ Encoder æ˜¯ä¸€ä¸ªå¤æ‚çš„é—®é¢˜ï¼ŒBERT é€šè¿‡ä½¿ç”¨æ—©æœŸæ–‡çŒ®ä¸­çš„ â€œmasked language modelâ€ æ¦‚å¿µï¼ˆåœ¨è¿™é‡Œè¢«ç§°ä¸ºå®Œå½¢å¡«ç©ºï¼‰æ¥è§£å†³è¿™ä¸ªé—®é¢˜ã€‚</p>
<p>é™¤äº†å±è”½è¾“å…¥ä¸­ 15% çš„å•è¯å¤–ï¼Œ BERT è¿˜æ··åˆä½¿ç”¨äº†å…¶ä»–çš„ä¸€äº›æŠ€å·§ï¼Œæ¥æ”¹è¿›æ¨¡å‹çš„å¾®è°ƒæ–¹å¼ã€‚ä¾‹å¦‚ï¼Œæœ‰æ—¶å®ƒä¼šéšæœºåœ°ç”¨ä¸€ä¸ªè¯æ›¿æ¢å¦ä¸€ä¸ªè¯ï¼Œç„¶åè®©æ¨¡å‹é¢„æµ‹è¿™ä¸ªä½ç½®åŸæ¥çš„å®é™…å•è¯ã€‚</p>
<p><img src="3-bert-mask.webp" alt="BERT mask">å›¾ï¼š BERT mask</p>
<p>BERT åœ¨è¯­è¨€å»ºæ¨¡ä»»åŠ¡ä¸­ï¼Œå·§å¦™åœ°å±è”½äº†è¾“å…¥ä¸­ 15% çš„å•è¯ï¼Œå¹¶è®©æ¨¡å‹é¢„æµ‹è¿™äº›å±è”½ä½ç½®çš„å•è¯ã€‚</p>
<p>æ‰¾åˆ°åˆé€‚çš„ä»»åŠ¡æ¥è®­ç»ƒä¸€ä¸ª Transformer çš„ Encoder æ˜¯ä¸€ä¸ªå¤æ‚çš„é—®é¢˜ï¼ŒBERT é€šè¿‡ä½¿ç”¨æ—©æœŸæ–‡çŒ®ä¸­çš„ â€œmasked language modelâ€ æ¦‚å¿µï¼ˆåœ¨è¿™é‡Œè¢«ç§°ä¸ºå®Œå½¢å¡«ç©ºï¼‰æ¥è§£å†³è¿™ä¸ªé—®é¢˜ã€‚</p>
<p>é™¤äº†å±è”½è¾“å…¥ä¸­ 15% çš„å•è¯å¤–ï¼Œ <strong>BERT è¿˜æ··åˆä½¿ç”¨äº†å…¶ä»–çš„ä¸€äº›æŠ€å·§</strong>ï¼Œ<strong>æ¥æ”¹è¿›æ¨¡å‹çš„å¾®è°ƒæ–¹å¼</strong>ã€‚ä¾‹å¦‚ï¼Œæœ‰<strong>æ—¶å®ƒä¼šéšæœºåœ°ç”¨ä¸€ä¸ªè¯æ›¿æ¢å¦ä¸€ä¸ªè¯ï¼Œç„¶åè®©æ¨¡å‹é¢„æµ‹è¿™ä¸ªä½ç½®åŸæ¥çš„å®é™…å•è¯</strong>ã€‚</p>
<h3 id="ä¸¤ä¸ªå¥å­çš„ä»»åŠ¡"><a href="#ä¸¤ä¸ªå¥å­çš„ä»»åŠ¡" class="headerlink" title="ä¸¤ä¸ªå¥å­çš„ä»»åŠ¡"></a>ä¸¤ä¸ªå¥å­çš„ä»»åŠ¡</h3><p>å¦‚æœä½ å›é¡¾ OpenAI Transformer åœ¨å¤„ç†ä¸åŒä»»åŠ¡æ—¶æ‰€åšçš„è¾“å…¥å˜æ¢ï¼Œä½ ä¼šæ³¨æ„åˆ°æœ‰äº›ä»»åŠ¡éœ€è¦æ¨¡å‹å¯¹ä¸¤ä¸ªå¥å­çš„ä¿¡æ¯åšä¸€äº›å¤„ç†ï¼ˆä¾‹å¦‚ï¼Œåˆ¤æ–­å®ƒä»¬æ˜¯ä¸æ˜¯åŒä¸€å¥è¯çš„ä¸åŒè§£é‡Šã€‚å°†ä¸€ä¸ªç»´åŸºç™¾ç§‘æ¡ç›®ä½œä¸ºè¾“å…¥ï¼Œå†å°†ä¸€ä¸ªç›¸å…³çš„é—®é¢˜ä½œä¸ºå¦ä¸€ä¸ªè¾“å…¥ï¼Œæ¨¡å‹åˆ¤æ–­æ˜¯å¦å¯ä»¥å›ç­”è¿™ä¸ªé—®é¢˜ï¼‰ã€‚</p>
<p>ä¸ºäº†è®© BERT æ›´å¥½åœ°å¤„ç†å¤šä¸ªå¥å­ä¹‹é—´çš„å…³ç³»ï¼Œé¢„è®­ç»ƒè¿‡ç¨‹è¿˜åŒ…æ‹¬ä¸€ä¸ªé¢å¤–çš„ä»»åŠ¡ï¼šç»™å‡ºä¸¤ä¸ªå¥å­ï¼ˆA å’Œ Bï¼‰ï¼Œåˆ¤æ–­ B æ˜¯å¦æ˜¯ A åé¢çš„ç›¸é‚»å¥å­ã€‚</p>
<p><img src="3-bert-2sent.webp" alt="2ä¸ªå¥å­ä»»åŠ¡">å›¾ï¼š 2ä¸ªå¥å­ä»»åŠ¡</p>
<p>BERT é¢„è®­ç»ƒçš„ç¬¬ 2 ä¸ªä»»åŠ¡æ˜¯ä¸¤ä¸ªå¥å­çš„åˆ†ç±»ä»»åŠ¡ã€‚<strong>åœ¨ä¸Šå›¾ä¸­</strong>ï¼Œ<strong>tokenization è¿™ä¸€æ­¥è¢«ç®€åŒ–äº†</strong>ï¼Œ<strong>å› ä¸º BERT å®é™…ä¸Šä½¿ç”¨äº† WordPieces ä½œä¸º token</strong>ï¼Œ<strong>è€Œä¸æ˜¯ä½¿ç”¨å•è¯æœ¬èº«</strong>ã€‚<strong>åœ¨ WordPiece ä¸­</strong>ï¼Œ<strong>æœ‰äº›è¯ä¼šè¢«æ‹†åˆ†æˆæ›´å°çš„éƒ¨åˆ†</strong>ã€‚</p>
<h3 id="BERT-åœ¨ä¸åŒä»»åŠ¡ä¸Šçš„åº”ç”¨"><a href="#BERT-åœ¨ä¸åŒä»»åŠ¡ä¸Šçš„åº”ç”¨" class="headerlink" title="BERT åœ¨ä¸åŒä»»åŠ¡ä¸Šçš„åº”ç”¨"></a>BERT åœ¨ä¸åŒä»»åŠ¡ä¸Šçš„åº”ç”¨</h3><p>BERT çš„è®ºæ–‡å±•ç¤ºäº† BERT åœ¨å¤šç§ä»»åŠ¡ä¸Šçš„åº”ç”¨ã€‚</p>
<p><img src="3-bert-app.png" alt="BERTåº”ç”¨">å›¾ï¼š BERTåº”ç”¨</p>
<h3 id="å°†-BERT-ç”¨äºç‰¹å¾æå–"><a href="#å°†-BERT-ç”¨äºç‰¹å¾æå–" class="headerlink" title="å°† BERT ç”¨äºç‰¹å¾æå–"></a>å°† BERT ç”¨äºç‰¹å¾æå–</h3><p>ä½¿ç”¨ BERT å¹¶ä¸æ˜¯åªæœ‰å¾®è°ƒè¿™ä¸€ç§æ–¹æ³•ã€‚å°±åƒ ELMo ä¸€æ ·ï¼Œä½ å¯ä»¥ä½¿ç”¨é¢„è®­ç»ƒçš„ BERT æ¥åˆ›å»ºè¯­å¢ƒåŒ–çš„word embeddingã€‚ç„¶åä½ å¯ä»¥æŠŠè¿™äº›word embeddingç”¨åˆ°ä½ ç°æœ‰çš„æ¨¡å‹ä¸­ã€‚è®ºæ–‡é‡Œä¹Ÿæåˆ°ï¼Œè¿™ç§æ–¹æ³•åœ¨å‘½åå®ä½“è¯†åˆ«ä»»åŠ¡ä¸­çš„æ•ˆæœï¼Œæ¥è¿‘äºå¾®è°ƒ BERT æ¨¡å‹çš„æ•ˆæœã€‚</p>
<p><img src="3-bert-feature.png" alt="BERTç‰¹å¾æå–">å›¾ï¼š BERTç‰¹å¾æå–</p>
<p>é‚£ä¹ˆå“ªç§å‘é‡æœ€é€‚åˆä½œä¸ºä¸Šä¸‹æ–‡è¯åµŒå…¥ï¼Ÿæˆ‘è®¤ä¸ºè¿™å–å†³äºä»»åŠ¡ã€‚è®ºæ–‡é‡ŒéªŒè¯äº† 6 ç§é€‰æ‹©ï¼ˆä¸å¾®è°ƒåçš„ 96.4 åˆ†çš„æ¨¡å‹ç›¸æ¯”ï¼‰ï¼š</p>
<p><img src="3-bert-fea.webp" alt="BERTç‰¹å¾é€‰æ‹©">å›¾ï¼š BERTç‰¹å¾é€‰æ‹©</p>
<p>ï¼Ÿï¼Ÿï¼Ÿï¼Ÿ</p>
<h3 id="å¦‚ä½•ä½¿ç”¨-BERT"><a href="#å¦‚ä½•ä½¿ç”¨-BERT" class="headerlink" title="å¦‚ä½•ä½¿ç”¨ BERT"></a>å¦‚ä½•ä½¿ç”¨ BERT</h3><p>å°†åœ¨ç¯‡ç« 3ä¸­è¿›è¡Œæ›´ä¸ºè¯¦ç»†çš„è®²è§£ã€‚</p>
<p>å°è¯• BERT çš„æœ€ä½³æ–¹å¼æ˜¯é€šè¿‡æ‰˜ç®¡åœ¨ Google Colab ä¸Šçš„ BERT FineTuning with Cloud TPUsã€‚å¦‚æœä½ ä¹‹å‰ä»æ¥æ²¡æœ‰ä½¿ç”¨è¿‡ Cloud TPUï¼Œé‚£è¿™ä¹Ÿæ˜¯ä¸€ä¸ªå¾ˆå¥½çš„å°è¯•å¼€ç«¯ï¼Œå› ä¸º BERT ä»£ç å¯ä»¥è¿è¡Œåœ¨ TPUã€CPU å’Œ GPUã€‚</p>
<p>ä¸‹ä¸€æ­¥æ˜¯æŸ¥çœ‹ BERT ä»“åº“ ä¸­çš„ä»£ç ï¼š</p>
<ul>
<li>æ¨¡å‹æ˜¯åœ¨ modeling.pyï¼ˆclass BertModelï¼‰ä¸­å®šä¹‰çš„ï¼Œå’Œæ™®é€šçš„ Transformer encoder å®Œå…¨ç›¸åŒã€‚</li>
<li>run_classifier.py æ˜¯å¾®è°ƒç½‘ç»œçš„ä¸€ä¸ªç¤ºä¾‹ã€‚å®ƒè¿˜æ„å»ºäº†ç›‘ç£æ¨¡å‹åˆ†ç±»å±‚ã€‚å¦‚æœä½ æƒ³æ„å»ºè‡ªå·±çš„- åˆ†ç±»å™¨ï¼Œè¯·æŸ¥çœ‹è¿™ä¸ªæ–‡ä»¶ä¸­çš„ create_model() æ–¹æ³•ã€‚</li>
<li>å¯ä»¥ä¸‹è½½ä¸€äº›é¢„è®­ç»ƒå¥½çš„æ¨¡å‹ã€‚è¿™äº›æ¨¡å‹åŒ…æ‹¬ BERT Baseã€BERT Largeï¼Œä»¥åŠè‹±è¯­ã€ä¸­æ–‡å’ŒåŒ…æ‹¬ 102 ç§è¯­è¨€çš„å¤šè¯­è¨€æ¨¡å‹ï¼Œè¿™äº›æ¨¡å‹éƒ½æ˜¯åœ¨ç»´åŸºç™¾ç§‘çš„æ•°æ®ä¸Šè¿›è¡Œè®­ç»ƒçš„ã€‚</li>
<li>BERT ä¸ä¼šå°†å•è¯ä½œä¸º tokenã€‚ç›¸åï¼Œå®ƒå…³æ³¨çš„æ˜¯ WordPieceã€‚tokenization.py å°±æ˜¯ tokenizerï¼Œå®ƒä¼šå°†ä½ çš„å•è¯è½¬æ¢ä¸ºé€‚åˆ BERT çš„ wordPieceã€‚</li>
</ul>
<h2 id="è‡´è°¢"><a href="#è‡´è°¢" class="headerlink" title="è‡´è°¢"></a>è‡´è°¢</h2><p>ä¸»è¦ç”±å“ˆå°”æ»¨å·¥ä¸šå¤§å­¦å¼ è´¤åŒå­¦ç¿»è¯‘ï¼ˆç»è¿‡åŸä½œè€…æˆæƒï¼‰æ’°å†™ï¼Œç”±æœ¬é¡¹ç›®åŒå­¦ç»„ç»‡å’Œæ•´ç†ã€‚æ„Ÿè°¢Jacob Devlinã€Matt Gardnerã€Kenton Leeã€Mark Neumann å’Œ <a href="https://twitter.com/mattthemathman">Matthew Peters</a> ä¸ºè¿™ç¯‡æ–‡ç« çš„æ—©æœŸç‰ˆæœ¬æä¾›äº†åé¦ˆ</p>
<h2 id="å›¾è§£GPT"><a href="#å›¾è§£GPT" class="headerlink" title="å›¾è§£GPT"></a>å›¾è§£GPT</h2><p>æœ€è‘—åçš„è¯­è¨€æ¨¡å‹å°±æ˜¯æ‰‹æœºé”®ç›˜ï¼Œå®ƒå¯ä»¥æ ¹æ®ä½ è¾“å…¥çš„å†…å®¹ï¼Œæç¤ºä¸‹ä¸€ä¸ªå•è¯ã€‚</p>
<p><img src="4-gpt-bert.webp" alt="gpt-bert">å›¾ï¼šgpt-bert</p>
<p>æˆ‘ä»¬å¯ä»¥å°†è¿™äº›æ¨¡å—å †å¾—å¤šé«˜å‘¢ï¼Ÿäº‹å®è¯æ˜ï¼Œè¿™æ˜¯åŒºåˆ†ä¸åŒçš„ GPT-2 çš„ä¸»è¦å› ç´ ä¹‹ä¸€ã€‚</p>
<p><img src="4-gpt-his2.webp" alt="gptåŒºåˆ†">å›¾ï¼šgptåŒºåˆ†</p>
<h3 id="ä¸-BERT-çš„ä¸€ä¸ªä¸åŒä¹‹å¤„"><a href="#ä¸-BERT-çš„ä¸€ä¸ªä¸åŒä¹‹å¤„" class="headerlink" title="ä¸ BERT çš„ä¸€ä¸ªä¸åŒä¹‹å¤„"></a>ä¸ BERT çš„ä¸€ä¸ªä¸åŒä¹‹å¤„</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">æœºå™¨äººç¬¬ä¸€å®šå¾‹ï¼š</span><br><span class="line"></span><br><span class="line">æœºå™¨äººä¸å¾—ä¼¤å®³äººç±»ï¼Œä¹Ÿä¸èƒ½å› ä¸ä½œä¸ºè€Œä½¿äººç±»å—åˆ°ä¼¤å®³ã€‚</span><br></pre></td></tr></table></figure>

<p>GPT-2 æ˜¯ä½¿ç”¨ Transformer çš„ Decoder æ¨¡å—æ„å»ºçš„ã€‚å¦ä¸€æ–¹é¢ï¼ŒBERT æ˜¯ä½¿ç”¨ Transformer çš„ Encoder æ¨¡å—æ„å»ºçš„ã€‚æˆ‘ä»¬å°†åœ¨ä¸‹ä¸€èŠ‚ä¸­ç ”ç©¶è¿™ç§å·®å¼‚ã€‚ä½†å®ƒä»¬ä¹‹é—´çš„ä¸€ä¸ªé‡è¦å·®å¼‚æ˜¯ï¼ŒGPT-2 å’Œä¼ ç»Ÿçš„è¯­è¨€æ¨¡å‹ä¸€æ ·ï¼Œä¸€æ¬¡è¾“å‡ºä¸€ä¸ª  tokenã€‚ä¾‹å¦‚ï¼Œè®©ä¸€ä¸ªè®­ç»ƒå¥½çš„ GPT-2 èƒŒè¯µæœºå™¨äººç¬¬ä¸€å®šå¾‹ï¼š</p>
<p><img src="4-gpt2-output.webp" alt="gpt2 output">å›¾ï¼š gpt2 output</p>
<p>è¿™äº›æ¨¡å‹çš„å®é™…å·¥ä½œæ–¹å¼æ˜¯ï¼Œåœ¨äº§ç”Ÿæ¯ä¸ª token ä¹‹åï¼Œå°†è¿™ä¸ª token æ·»åŠ åˆ°è¾“å…¥çš„åºåˆ—ä¸­ï¼Œå½¢æˆä¸€ä¸ªæ–°åºåˆ—ã€‚ç„¶åè¿™ä¸ªæ–°åºåˆ—æˆä¸ºæ¨¡å‹åœ¨ä¸‹ä¸€ä¸ªæ—¶é—´æ­¥çš„è¾“å…¥ã€‚è¿™æ˜¯ä¸€ç§å«â€œ<strong>è‡ªå›å½’</strong>ï¼ˆauto-regressionï¼‰â€çš„æ€æƒ³ã€‚è¿™ç§åšæ³•å¯ä»¥ä½¿å¾— RNN éå¸¸æœ‰æ•ˆã€‚</p>
<p><img src="4-gpt2-output2.webp" alt="gpt2 output">å›¾ï¼š gpt2 output</p>
<p>GPT-2ï¼Œå’Œåæ¥çš„ä¸€äº›æ¨¡å‹å¦‚ TransformerXL å’Œ XLNetï¼Œæœ¬è´¨ä¸Šéƒ½æ˜¯è‡ªå›å½’çš„æ¨¡å‹ã€‚ä½† BERT ä¸æ˜¯è‡ªå›å½’æ¨¡å‹ã€‚è¿™æ˜¯ä¸€ç§æƒè¡¡ã€‚å»æ‰äº†è‡ªå›å½’åï¼ŒBERT èƒ½å¤Ÿæ•´åˆå·¦å³ä¸¤è¾¹çš„ä¸Šä¸‹æ–‡ï¼Œä»è€Œè·å¾—æ›´å¥½çš„ç»“æœã€‚XLNet é‡æ–°ä½¿ç”¨äº† è‡ªå›å½’ï¼ŒåŒæ—¶ä¹Ÿæ‰¾åˆ°ä¸€ç§æ–¹æ³•èƒ½å¤Ÿç»“åˆä¸¤è¾¹çš„ä¸Šä¸‹æ–‡ã€‚</p>
<h3 id="Transformer-æ¨¡å—çš„è¿›åŒ–"><a href="#Transformer-æ¨¡å—çš„è¿›åŒ–" class="headerlink" title="Transformer æ¨¡å—çš„è¿›åŒ–"></a>Transformer æ¨¡å—çš„è¿›åŒ–</h3><p>Transformer åŸå§‹è®ºæ–‡(<a href="https://arxiv.org/abs/1706.03762">https://arxiv.org/abs/1706.03762</a>) ä»‹ç»äº†ä¸¤ç§æ¨¡å—ï¼š</p>
<p>Encoder æ¨¡å—</p>
<p>é¦–å…ˆæ˜¯ Encoder æ¨¡å—ã€‚</p>
<p><img src="4-encoder.webp" alt="encoder">å›¾ï¼š encoder</p>
<p>åŸå§‹çš„ Transformer è®ºæ–‡ä¸­çš„ Encoder æ¨¡å—æ¥å—ç‰¹å®šé•¿åº¦çš„è¾“å…¥ï¼ˆå¦‚ 512 ä¸ª tokenï¼‰ã€‚å¦‚æœä¸€ä¸ªè¾“å…¥åºåˆ—æ¯”è¿™ä¸ªé™åˆ¶çŸ­ï¼Œæˆ‘ä»¬å¯ä»¥å¡«å……åºåˆ—çš„å…¶ä½™éƒ¨åˆ†ã€‚</p>
<p>Decoder æ¨¡å—</p>
<p>å…¶æ¬¡æ˜¯ Decoderã€‚ä¸ Encoder ç›¸æ¯”ï¼Œå®ƒåœ¨ç»“æ„ä¸Šæœ‰ä¸€ä¸ªå¾ˆå°çš„å·®å¼‚ï¼šå®ƒæœ‰ä¸€ä¸ªå±‚ï¼Œä½¿å¾—å®ƒå¯ä»¥å…³æ³¨æ¥è‡ª Encoder ç‰¹å®šçš„æ®µã€‚</p>
<p><img src="4-decoder.webp" alt="decoder">å›¾ï¼š decoder</p>
<p>è¿™é‡Œçš„ <strong>Self Attention å±‚çš„ä¸€ä¸ªå…³é”®å·®å¼‚æ˜¯ï¼Œå®ƒä¼šå±è”½æœªæ¥çš„ token</strong>ã€‚å…·ä½“æ¥è¯´ï¼Œå®ƒä¸åƒ BERT é‚£æ ·å°†å•è¯æ”¹ä¸ºmaskï¼Œè€Œæ˜¯é€šè¿‡æ”¹å˜ Self Attention çš„è®¡ç®—ï¼Œé˜»æ­¢æ¥è‡ªè¢«è®¡ç®—ä½ç½®å³è¾¹çš„ tokenã€‚</p>
<p>ä¾‹å¦‚ï¼Œæˆ‘ä»¬æƒ³è¦è®¡ç®—ä½ç½® 4ï¼Œæˆ‘ä»¬å¯ä»¥çœ‹åˆ°åªå…è®¸å¤„ç†ä»¥å‰å’Œç°åœ¨çš„ tokenã€‚</p>
<p><img src="4-decoder1.webp" alt="decoderåªèƒ½çœ‹åˆ°ä»¥å‰å’Œç°åœ¨çš„token">å›¾ï¼š decoderåªèƒ½çœ‹åˆ°ä»¥å‰å’Œç°åœ¨çš„token</p>
<p>å¾ˆé‡è¦çš„ä¸€ç‚¹æ˜¯ï¼Œï¼ˆBERT ä½¿ç”¨çš„ï¼‰Self Attention å’Œ ï¼ˆGPT-2 ä½¿ç”¨çš„ï¼‰masked Self Attention æœ‰æ˜ç¡®çš„åŒºåˆ«ã€‚ä¸€ä¸ªæ­£å¸¸çš„ Self Attention æ¨¡å—å…è®¸ä¸€ä¸ªä½ç½®å…³æ³¨åˆ°å®ƒå³è¾¹çš„éƒ¨åˆ†ã€‚è€Œ <strong>masked Self Attention</strong> é˜»æ­¢äº†è¿™ç§æƒ…å†µçš„å‘ç”Ÿï¼š</p>
<p><img src="4-mask.png" alt="mask attention">å›¾ï¼š mask attention</p>
<p>åªæœ‰ Decoder çš„æ¨¡å—</p>
<p>åœ¨ Transformer åŸå§‹è®ºæ–‡å‘å¸ƒä¹‹åï¼ŒGenerating Wikipedia by Summarizing Long Sequences(<a href="https://arxiv.org/pdf/1801.10198.pdf">https://arxiv.org/pdf/1801.10198.pdf</a>) æå‡ºäº†å¦ä¸€ç§èƒ½å¤Ÿè¿›è¡Œè¯­è¨€å»ºæ¨¡çš„ Transformer æ¨¡å—çš„å¸ƒå±€ã€‚è¿™ä¸ªæ¨¡å‹ä¸¢å¼ƒäº† Transformer çš„ Encoderã€‚å› æ­¤ï¼Œæˆ‘ä»¬å¯ä»¥æŠŠè¿™ä¸ªæ¨¡å‹ç§°ä¸º Transformer-Decoderã€‚è¿™ç§æ—©æœŸçš„åŸºäº Transformer çš„è¯­è¨€æ¨¡å‹ç”± 6 ä¸ª Decoder æ¨¡å—ç»„æˆã€‚</p>
<p><img src="4-trans-decoder.webp" alt="transformer-decoder">å›¾ï¼š transformer-decoder</p>
<p>è¿™äº› Decoder æ¨¡å—éƒ½æ˜¯ç›¸åŒçš„ã€‚æˆ‘å·²ç»å±•å¼€äº†ç¬¬ä¸€ä¸ª Decoderï¼Œå› æ­¤ä½ å¯ä»¥çœ‹åˆ°å®ƒçš„ Self Attention å±‚æ˜¯ masked çš„ã€‚æ³¨æ„ï¼Œç°åœ¨è¿™ä¸ªæ¨¡å‹å¯ä»¥å¤„ç†å¤šè¾¾ 4000 ä¸ª tokenâ€“æ˜¯å¯¹åŸå§‹è®ºæ–‡ä¸­ 512 ä¸ª token çš„ä¸€ä¸ªå¤§å‡çº§ã€‚</p>
<p>è¿™äº›æ¨¡å—å’ŒåŸå§‹çš„ Decoder æ¨¡å—éå¸¸ç±»ä¼¼ï¼Œåªæ˜¯å®ƒä»¬å»æ‰äº†ç¬¬äºŒä¸ª Self Attention å±‚ã€‚åœ¨ Character-Level Language Modeling with Deeper Self-Attention(<a href="https://arxiv.org/pdf/1808.04444.pdf">https://arxiv.org/pdf/1808.04444.pdf</a>) ä¸­ä½¿ç”¨äº†ç±»ä¼¼çš„ç»“æ„ï¼Œæ¥åˆ›å»ºä¸€æ¬¡ä¸€ä¸ªå­—æ¯/å­—ç¬¦çš„è¯­è¨€æ¨¡å‹ã€‚</p>
<p>OpenAI çš„ GPT-2 ä½¿ç”¨äº†è¿™äº› Decoder æ¨¡å—ã€‚</p>
<h3 id="è¯­è¨€æ¨¡å‹å…¥é—¨ï¼šäº†è§£-GPT2"><a href="#è¯­è¨€æ¨¡å‹å…¥é—¨ï¼šäº†è§£-GPT2" class="headerlink" title="è¯­è¨€æ¨¡å‹å…¥é—¨ï¼šäº†è§£ GPT2"></a>è¯­è¨€æ¨¡å‹å…¥é—¨ï¼šäº†è§£ GPT2</h3><p>è®©æˆ‘ä»¬æ‹†è§£ä¸€ä¸ªè®­ç»ƒå¥½çš„ GPT-2ï¼Œçœ‹çœ‹å®ƒæ˜¯å¦‚ä½•å·¥ä½œçš„ã€‚</p>
<p><img src="4-gpt2-1.png" alt="æ‹†è§£GPT2">å›¾ï¼šæ‹†è§£GPT2</p>
<p>GPT-2 èƒ½å¤Ÿå¤„ç† 1024 ä¸ª tokenã€‚æ¯ä¸ª token æ²¿ç€è‡ªå·±çš„è·¯å¾„ç»è¿‡æ‰€æœ‰çš„ Decoder æ¨¡å—</p>
<p>è¿è¡Œä¸€ä¸ªè®­ç»ƒå¥½çš„ GPT-2 æ¨¡å‹çš„æœ€ç®€å•çš„æ–¹æ³•æ˜¯è®©å®ƒè‡ªå·±ç”Ÿæˆæ–‡æœ¬ï¼ˆè¿™åœ¨æŠ€æœ¯ä¸Šç§°ä¸º ç”Ÿæˆæ— æ¡ä»¶æ ·æœ¬ï¼‰ã€‚æˆ–è€…ï¼Œæˆ‘ä»¬å¯ä»¥ç»™å®ƒä¸€ä¸ªæç¤ºï¼Œè®©å®ƒè°ˆè®ºæŸä¸ªä¸»é¢˜ï¼ˆå³ç”Ÿæˆäº¤äº’å¼æ¡ä»¶æ ·æœ¬ï¼‰ã€‚åœ¨æ¼«æ— ç›®çš„æƒ…å†µä¸‹ï¼Œæˆ‘ä»¬å¯ä»¥ç®€å•åœ°ç»™å®ƒè¾“å…¥åˆå§‹ tokenï¼Œå¹¶è®©å®ƒå¼€å§‹ç”Ÿæˆå•è¯ï¼ˆè®­ç»ƒå¥½çš„æ¨¡å‹ä½¿ç”¨ &lt;|endoftext|&gt; ä½œä¸ºåˆå§‹çš„ tokenã€‚æˆ‘ä»¬ç§°ä¹‹ä¸º &lt;s&gt;ï¼‰ã€‚</p>
<p><img src="4-gpt2-start.webp" alt="æ‹†è§£GPT2åˆå§‹token">å›¾ï¼šæ‹†è§£GPT2åˆå§‹token</p>
<p>æ¨¡å‹åªæœ‰ä¸€ä¸ªè¾“å…¥çš„ tokenï¼Œå› æ­¤åªæœ‰ä¸€æ¡æ´»è·ƒè·¯å¾„ã€‚token åœ¨æ‰€æœ‰å±‚ä¸­ä¾æ¬¡è¢«å¤„ç†ï¼Œç„¶åæ²¿ç€è¯¥è·¯å¾„ç”Ÿæˆä¸€ä¸ªå‘é‡ã€‚è¿™ä¸ªå‘é‡å¯ä»¥æ ¹æ®æ¨¡å‹çš„è¯æ±‡è¡¨è®¡ç®—å‡ºä¸€ä¸ªåˆ†æ•°ï¼ˆæ¨¡å‹çŸ¥é“æ‰€æœ‰çš„ å•è¯ï¼Œåœ¨ GPT-2 ä¸­æ˜¯ 5000 ä¸ªè¯ï¼‰ã€‚åœ¨è¿™ä¸ªä¾‹å­ä¸­ï¼Œæˆ‘ä»¬é€‰æ‹©äº†æ¦‚ç‡æœ€é«˜çš„ theã€‚ä½†æˆ‘ä»¬å¯ä»¥æŠŠäº‹æƒ…ææ··â€“ä½ çŸ¥é“å¦‚æœä¸€ç›´åœ¨é”®ç›˜ app ä¸­é€‰æ‹©å»ºè®®çš„å•è¯ï¼Œå®ƒæœ‰æ—¶å€™ä¼šé™·å…¥é‡å¤çš„å¾ªç¯ä¸­ï¼Œå”¯ä¸€çš„å‡ºè·¯å°±æ˜¯ç‚¹å‡»ç¬¬äºŒä¸ªæˆ–è€…ç¬¬ä¸‰ä¸ªå»ºè®®çš„å•è¯ã€‚åŒæ ·çš„äº‹æƒ…ä¹Ÿä¼šå‘ç”Ÿåœ¨è¿™é‡Œï¼ŒGPT-2 æœ‰ä¸€ä¸ª top-k å‚æ•°ï¼Œæˆ‘ä»¬å¯ä»¥ä½¿ç”¨è¿™ä¸ªå‚æ•°ï¼Œè®©æ¨¡å‹è€ƒè™‘ç¬¬ä¸€ä¸ªè¯ï¼ˆtop-k =1ï¼‰ä¹‹å¤–çš„å…¶ä»–è¯ã€‚</p>
<p>ä¸‹ä¸€æ­¥ï¼Œæˆ‘ä»¬æŠŠç¬¬ä¸€æ­¥çš„è¾“å‡ºæ·»åŠ åˆ°æˆ‘ä»¬çš„è¾“å…¥åºåˆ—ï¼Œç„¶åè®©æ¨¡å‹åšä¸‹ä¸€ä¸ªé¢„æµ‹ã€‚</p>
<p><img src="4-gpt2-the.gif" alt="æ‹†è§£GPT2">åŠ¨æ€å›¾ï¼šæ‹†è§£GPT2</p>
<p>è¯·æ³¨æ„ï¼Œç¬¬äºŒæ¡è·¯å¾„æ˜¯æ­¤è®¡ç®—ä¸­å”¯ä¸€æ´»åŠ¨çš„è·¯å¾„ã€‚GPT-2 çš„æ¯ä¸€å±‚éƒ½ä¿ç•™äº†å®ƒè‡ªå·±å¯¹ç¬¬ä¸€ä¸ª token çš„è§£é‡Šï¼Œè€Œä¸”ä¼šåœ¨å¤„ç†ç¬¬äºŒä¸ª token æ—¶ä½¿ç”¨å®ƒï¼ˆæˆ‘ä»¬ä¼šåœ¨æ¥ä¸‹æ¥å…³äº Self Attention çš„ç« èŠ‚ä¸­å¯¹æ­¤è¿›è¡Œæ›´è¯¦ç»†çš„ä»‹ç»ï¼‰ã€‚GPT-2 ä¸ä¼šæ ¹æ®ç¬¬äºŒä¸ª token é‡æ–°è®¡ç®—ç¬¬ä¸€ä¸ª tokenã€‚</p>
<h3 id="æ·±å…¥ç†è§£-GPT2-çš„æ›´å¤šç»†èŠ‚"><a href="#æ·±å…¥ç†è§£-GPT2-çš„æ›´å¤šç»†èŠ‚" class="headerlink" title="æ·±å…¥ç†è§£ GPT2 çš„æ›´å¤šç»†èŠ‚"></a>æ·±å…¥ç†è§£ GPT2 çš„æ›´å¤šç»†èŠ‚</h3><p><strong>è¾“å…¥ç¼–ç </strong></p>
<p>è®©æˆ‘ä»¬æ›´æ·±å…¥åœ°äº†è§£æ¨¡å‹ã€‚é¦–å…ˆä»è¾“å…¥å¼€å§‹ã€‚ä¸ä¹‹å‰æˆ‘ä»¬è®¨è®ºçš„å…¶ä»– NLP æ¨¡å‹ä¸€æ ·ï¼ŒGPT-2 åœ¨åµŒå…¥çŸ©é˜µä¸­æŸ¥æ‰¾è¾“å…¥çš„å•è¯çš„å¯¹åº”çš„ embedding å‘é‡â€“è¿™æ˜¯æˆ‘ä»¬ä»è®­ç»ƒå¥½çš„æ¨¡å‹ä¸­å¾—åˆ°çš„ç»„ä»¶ä¹‹ä¸€ã€‚</p>
<p><img src="4-gpt-token.png" alt="token embedding">å›¾ï¼štoken embedding</p>
<p>æ¯ä¸€è¡Œéƒ½æ˜¯è¯çš„ embeddingï¼šè¿™æ˜¯ä¸€ä¸ªæ•°å­—åˆ—è¡¨ï¼Œå¯ä»¥è¡¨ç¤ºä¸€ä¸ªè¯å¹¶æ•è·ä¸€äº›å«ä¹‰ã€‚è¿™ä¸ªåˆ—è¡¨çš„å¤§å°åœ¨ä¸åŒçš„ GPT-2 æ¨¡å‹ä¸­æ˜¯ä¸åŒçš„ã€‚æœ€å°çš„æ¨¡å‹ä½¿ç”¨çš„ embedding å¤§å°æ˜¯ 768</p>
<p>å› æ­¤åœ¨å¼€å§‹æ—¶ï¼Œæˆ‘ä»¬ä¼šåœ¨åµŒå…¥çŸ©é˜µæŸ¥æ‰¾ç¬¬ä¸€ä¸ª token  çš„ embeddingã€‚åœ¨æŠŠè¿™ä¸ª embedding ä¼ ç»™æ¨¡å‹çš„ç¬¬ä¸€ä¸ªæ¨¡å—ä¹‹å‰ï¼Œæˆ‘ä»¬éœ€è¦èå…¥ä½ç½®ç¼–ç ï¼Œè¿™ä¸ªä½ç½®ç¼–ç èƒ½å¤ŸæŒ‡ç¤ºå•è¯åœ¨åºåˆ—ä¸­çš„é¡ºåºã€‚è®­ç»ƒå¥½çš„æ¨¡å‹ä¸­ï¼Œæœ‰ä¸€éƒ¨åˆ†æ˜¯ä¸€ä¸ªçŸ©é˜µï¼Œè¿™ä¸ªçŸ©é˜µåŒ…æ‹¬äº† 1024 ä¸ªä½ç½®ä¸­æ¯ä¸ªä½ç½®çš„ä½ç½®ç¼–ç å‘é‡ã€‚</p>
<p><img src="4-gpt-pos.webp" alt="ä½ç½®ç¼–ç ">å›¾ï¼šä½ç½®ç¼–ç </p>
<p>åœ¨è¿™é‡Œï¼Œæˆ‘ä»¬è®¨è®ºäº†è¾“å…¥å•è¯åœ¨ä¼ é€’åˆ°ç¬¬ä¸€ä¸ª Transformer æ¨¡å—ä¹‹å‰ï¼Œæ˜¯å¦‚ä½•è¢«å¤„ç†çš„ã€‚æˆ‘ä»¬è¿˜çŸ¥é“ï¼Œè®­ç»ƒå¥½çš„ GPT-2 åŒ…æ‹¬ä¸¤ä¸ªæƒé‡çŸ©é˜µã€‚</p>
<p><img src="4-gpt-token-pos.png" alt="token+position">å›¾ï¼š token+position</p>
<p>æŠŠä¸€ä¸ªå•è¯è¾“å…¥åˆ° Transformer çš„ç¬¬ä¸€ä¸ªæ¨¡å—ï¼Œæ„å‘³ç€å¯»æ‰¾è¿™ä¸ªå•è¯çš„ embeddingï¼Œå¹¶ä¸”æ·»åŠ ç¬¬ä¸€ä¸ªä½ç½®çš„ä½ç½®ç¼–ç å‘é‡</p>
<p><strong>åœ¨è¿™äº›å±‚ä¸­å‘ä¸ŠæµåŠ¨</strong></p>
<p>ç¬¬ä¸€ä¸ªæ¨¡å—ç°åœ¨å¯ä»¥å¤„ç† tokenï¼Œé¦–å…ˆé€šè¿‡ Self Attention å±‚ï¼Œç„¶åé€šè¿‡ç¥ç»ç½‘ç»œå±‚ã€‚ä¸€æ—¦ Transformer çš„ç¬¬ä¸€ä¸ªæ¨¡å—å¤„ç†äº† tokenï¼Œä¼šå¾—åˆ°ä¸€ä¸ªç»“æœå‘é‡ï¼Œè¿™ä¸ªç»“æœå‘é‡ä¼šè¢«å‘é€åˆ°å †æ ˆçš„ä¸‹ä¸€ä¸ªæ¨¡å—å¤„ç†ã€‚æ¯ä¸ªæ¨¡å—çš„å¤„ç†è¿‡ç¨‹éƒ½æ˜¯ç›¸åŒçš„ï¼Œä¸è¿‡æ¯ä¸ªæ¨¡å—éƒ½æœ‰è‡ªå·±çš„ Self Attention å’Œç¥ç»ç½‘ç»œå±‚ã€‚</p>
<p><img src="4-gpt-fllow.webp" alt="å‘ä¸ŠæµåŠ¨">å›¾ï¼šå‘ä¸ŠæµåŠ¨</p>
<p><strong>å›é¡¾ Self-Attention</strong></p>
<p>è¯­è¨€ä¸¥é‡ä¾èµ–äºä¸Šä¸‹æ–‡ã€‚ä¾‹å¦‚ï¼Œçœ‹çœ‹ä¸‹é¢çš„ç¬¬äºŒå®šå¾‹ï¼š</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">æœºå™¨äººç¬¬äºŒå®šå¾‹</span><br><span class="line"></span><br><span class="line">æœºå™¨äººå¿…é¡»æœä»äººç»™äºˆ**å®ƒ**çš„å‘½ä»¤ï¼Œå½“**è¯¥å‘½ä»¤**ä¸**ç¬¬ä¸€å®šå¾‹**å†²çªæ—¶ä¾‹å¤–ã€‚</span><br></pre></td></tr></table></figure>
<p>æˆ‘åœ¨å¥å­ä¸­åŠ ç²—äº† 3 ä¸ªéƒ¨åˆ†ï¼Œè¿™äº›éƒ¨åˆ†çš„è¯æ˜¯ç”¨äºæŒ‡ä»£å…¶ä»–çš„è¯ã€‚å¦‚æœä¸ç»“åˆå®ƒä»¬æ‰€æŒ‡çš„ä¸Šä¸‹æ–‡ï¼Œå°±æ— æ³•ç†è§£æˆ–è€…å¤„ç†è¿™äº›è¯ã€‚å½“ä¸€ä¸ªæ¨¡å‹å¤„ç†è¿™ä¸ªå¥å­ï¼Œå®ƒå¿…é¡»èƒ½å¤ŸçŸ¥é“ï¼š</p>
<ul>
<li>å®ƒ æŒ‡çš„æ˜¯æœºå™¨äºº</li>
<li>è¯¥å‘½ä»¤ æŒ‡çš„æ˜¯è¿™ä¸ªå®šå¾‹çš„å‰é¢éƒ¨åˆ†ï¼Œä¹Ÿå°±æ˜¯ äººç»™äºˆ å®ƒ çš„å‘½ä»¤</li>
<li>ç¬¬ä¸€å®šå¾‹ æŒ‡çš„æ˜¯æœºå™¨äººç¬¬ä¸€å®šå¾‹</li>
</ul>
<p>è¿™å°±æ˜¯ <strong>Self Attention</strong> æ‰€åšçš„äº‹ã€‚å®ƒåœ¨å¤„ç†æŸä¸ªè¯ä¹‹å‰ï¼Œå°†æ¨¡å‹å¯¹è¿™ä¸ªè¯çš„ç›¸å…³è¯å’Œå…³è”è¯çš„ç†è§£èåˆèµ·æ¥ï¼ˆå¹¶è¾“å…¥åˆ°ä¸€ä¸ªç¥ç»ç½‘ç»œï¼‰ã€‚å®ƒé€šè¿‡å¯¹å¥å­ç‰‡æ®µä¸­æ¯ä¸ªè¯çš„ç›¸å…³æ€§æ‰“åˆ†ï¼Œå¹¶å°†è¿™äº›è¯çš„è¡¨ç¤ºå‘é‡åŠ æƒæ±‚å’Œã€‚</p>
<p>ä¸¾ä¸ªä¾‹å­ï¼Œä¸‹å›¾é¡¶éƒ¨æ¨¡å—ä¸­çš„ Self Attention å±‚åœ¨å¤„ç†å•è¯ <code>it</code> çš„æ—¶å€™å…³æ³¨åˆ°<code> a robot</code>ã€‚å®ƒä¼ é€’ç»™ç¥ç»ç½‘ç»œçš„å‘é‡ï¼Œæ˜¯ 3 ä¸ªå•è¯å’Œå®ƒä»¬å„è‡ªåˆ†æ•°ç›¸ä¹˜å†ç›¸åŠ çš„å’Œã€‚</p>
<p><img src="4-gpt-it.webp" alt="itçš„attention">å›¾ï¼šitçš„attention</p>
<p><strong>Self-Attention è¿‡ç¨‹</strong></p>
<p>Self-Attention æ²¿ç€å¥å­ä¸­æ¯ä¸ª token çš„è·¯å¾„è¿›è¡Œå¤„ç†ï¼Œä¸»è¦ç»„æˆéƒ¨åˆ†åŒ…æ‹¬ 3 ä¸ªå‘é‡ã€‚</p>
<ul>
<li>Queryï¼šQuery å‘é‡æ˜¯å½“å‰å•è¯çš„è¡¨ç¤ºï¼Œç”¨äºå¯¹å…¶ä»–æ‰€æœ‰å•è¯ï¼ˆä½¿ç”¨è¿™äº›å•è¯çš„ key å‘é‡ï¼‰è¿›è¡Œè¯„åˆ†ã€‚æˆ‘ä»¬åªå…³æ³¨å½“å‰æ­£åœ¨å¤„ç†çš„ token çš„ query å‘é‡ã€‚</li>
<li>Keyï¼šKey å‘é‡å°±åƒå¥å­ä¸­æ‰€æœ‰å•è¯çš„æ ‡ç­¾ã€‚å®ƒä»¬å°±æ˜¯æˆ‘ä»¬åœ¨æœç´¢å•è¯æ—¶æ‰€è¦åŒ¹é…çš„ã€‚</li>
<li>Valueï¼šValue å‘é‡æ˜¯å®é™…çš„å•è¯è¡¨ç¤ºï¼Œä¸€æ—¦æˆ‘ä»¬å¯¹æ¯ä¸ªè¯çš„ç›¸å…³æ€§è¿›è¡Œäº†è¯„åˆ†ï¼Œæˆ‘ä»¬éœ€è¦å¯¹è¿™äº›å‘é‡è¿›è¡ŒåŠ æƒæ±‚å’Œï¼Œä»è€Œè¡¨ç¤ºå½“å‰çš„è¯ã€‚</li>
</ul>
<p><img src="4-gpt-query.webp" alt="query">å›¾ï¼š query<br>ä¸€ä¸ªç²—ç•¥çš„ç±»æ¯”æ˜¯æŠŠå®ƒçœ‹ä½œæ˜¯åœ¨ä¸€ä¸ªæ–‡ä»¶æŸœé‡Œé¢æœç´¢ï¼ŒQuery å‘é‡æ˜¯ä¸€ä¸ªä¾¿ç­¾ï¼Œä¸Šé¢å†™ç€ä½ æ­£åœ¨ç ”ç©¶çš„ä¸»é¢˜ï¼Œè€Œ Key å‘é‡å°±åƒæ˜¯æŸœå­é‡Œçš„æ–‡ä»¶å¤¹çš„æ ‡ç­¾ã€‚å½“ä½ å°†ä¾¿ç­¾ä¸æ ‡ç­¾åŒ¹é…æ—¶ï¼Œæˆ‘ä»¬å–å‡ºåŒ¹é…çš„é‚£äº›æ–‡ä»¶å¤¹çš„å†…å®¹ï¼Œè¿™äº›å†…å®¹å°±æ˜¯ Value å‘é‡ã€‚ä½†æ˜¯ä½ ä¸ä»…ä»…æ˜¯å¯»æ‰¾ä¸€ä¸ª Value å‘é‡ï¼Œè€Œæ˜¯åœ¨ä¸€ç³»åˆ—æ–‡ä»¶å¤¹é‡Œå¯»æ‰¾ä¸€ç³»åˆ— Value å‘é‡ã€‚</p>
<p>å°† Query å‘é‡ä¸æ¯ä¸ªæ–‡ä»¶å¤¹çš„ Key å‘é‡ç›¸ä¹˜ï¼Œä¼šä¸ºæ¯ä¸ªæ–‡ä»¶å¤¹äº§ç”Ÿä¸€ä¸ªåˆ†æ•°ï¼ˆä»æŠ€æœ¯ä¸Šæ¥è®²ï¼šå°±æ˜¯ç‚¹ç§¯åé¢è·Ÿç€ softmaxï¼‰ã€‚</p>
<p><img src="4-gpt-score.webp" alt="score">å›¾ï¼š score</p>
<p>æˆ‘ä»¬å°†æ¯ä¸ª Value å‘é‡ä¹˜ä»¥å¯¹åº”çš„åˆ†æ•°ï¼Œç„¶åæ±‚å’Œï¼Œå¾—åˆ° Self Attention çš„è¾“å‡ºã€‚</p>
<p><img src="4-gpt-out.webp" alt="Self Attention çš„è¾“å‡º">å›¾ï¼šSelf Attention çš„è¾“å‡º</p>
<p>è¿™äº›åŠ æƒçš„ Value å‘é‡ä¼šå¾—åˆ°ä¸€ä¸ªå‘é‡ï¼Œå®ƒå°† 50% çš„æ³¨æ„åŠ›æ”¾åˆ°å•è¯ robot ä¸Šï¼Œå°† 30% çš„æ³¨æ„åŠ›æ”¾åˆ°å•è¯ aï¼Œå°† 19% çš„æ³¨æ„åŠ›æ”¾åˆ°å•è¯ itã€‚åœ¨ä¸‹æ–‡ä¸­ï¼Œæˆ‘ä»¬ä¼šæ›´åŠ æ·±å…¥ Self Attentionï¼Œä½†ç°åœ¨ï¼Œé¦–å…ˆè®©æˆ‘ä»¬ç»§ç»­åœ¨æ¨¡å‹ä¸­å¾€ä¸Šèµ°ï¼Œç›´åˆ°æ¨¡å‹çš„è¾“å‡ºã€‚</p>
<p><strong>æ¨¡å‹è¾“å‡º</strong></p>
<p>å½“æ¨¡å‹é¡¶éƒ¨çš„æ¨¡å—äº§ç”Ÿè¾“å‡ºå‘é‡æ—¶ï¼ˆè¿™ä¸ªå‘é‡æ˜¯ç»è¿‡ Self Attention å±‚å’Œç¥ç»ç½‘ç»œå±‚å¾—åˆ°çš„ï¼‰ï¼Œæ¨¡å‹ä¼šå°†è¿™ä¸ªå‘é‡ä¹˜ä»¥åµŒå…¥çŸ©é˜µã€‚</p>
<p><img src="4-gpt-out1.webp" alt="é¡¶éƒ¨çš„æ¨¡å—äº§ç”Ÿè¾“å‡º">å›¾ï¼šé¡¶éƒ¨çš„æ¨¡å—äº§ç”Ÿè¾“å‡º</p>
<p>å›å¿†ä¸€ä¸‹ï¼ŒåµŒå…¥çŸ©é˜µä¸­çš„æ¯ä¸€è¡Œéƒ½å¯¹åº”äºæ¨¡å‹è¯æ±‡è¡¨ä¸­çš„ä¸€ä¸ªè¯ã€‚è¿™ä¸ªç›¸ä¹˜çš„ç»“æœï¼Œè¢«è§£é‡Šä¸ºæ¨¡å‹è¯æ±‡è¡¨ä¸­æ¯ä¸ªè¯çš„åˆ†æ•°ã€‚</p>
<p><img src="4-gpt-out3.webp" alt="tokenæ¦‚ç‡">å›¾ï¼štokenæ¦‚ç‡</p>
<p>æˆ‘ä»¬å¯ä»¥é€‰æ‹©æœ€é«˜åˆ†æ•°çš„ tokenï¼ˆtop_k=1ï¼‰ã€‚ä½†å¦‚æœæ¨¡å‹å¯ä»¥åŒæ—¶è€ƒè™‘å…¶ä»–è¯ï¼Œé‚£ä¹ˆå¯ä»¥å¾—åˆ°æ›´å¥½çš„ç»“æœã€‚æ‰€ä»¥ä¸€ä¸ªæ›´å¥½çš„ç­–ç•¥æ˜¯æŠŠåˆ†æ•°ä½œä¸ºå•è¯çš„æ¦‚ç‡ï¼Œä»æ•´ä¸ªåˆ—è¡¨ä¸­é€‰æ‹©ä¸€ä¸ªå•è¯ï¼ˆè¿™æ ·åˆ†æ•°è¶Šé«˜çš„å•è¯ï¼Œè¢«é€‰ä¸­çš„å‡ ç‡å°±è¶Šé«˜ï¼‰ã€‚ä¸€ä¸ªæŠ˜ä¸­çš„é€‰æ‹©æ˜¯æŠŠ top_k è®¾ç½®ä¸º 40ï¼Œè®©æ¨¡å‹è€ƒè™‘å¾—åˆ†æœ€é«˜çš„ 40 ä¸ªè¯ã€‚</p>
<p><img src="4-gpt-out4.webp" alt="top ké€‰æ‹©è¾“å‡º">å›¾ï¼štop ké€‰æ‹©è¾“å‡º</p>
<p>è¿™æ ·ï¼Œæ¨¡å‹å°±å®Œæˆäº†ä¸€æ¬¡è¿­ä»£ï¼Œè¾“å‡ºä¸€ä¸ªå•è¯ã€‚æ¨¡å‹ä¼šç»§ç»­è¿­ä»£ï¼Œç›´åˆ°æ‰€æœ‰çš„ä¸Šä¸‹æ–‡éƒ½å·²ç»ç”Ÿæˆï¼ˆ1024 ä¸ª tokenï¼‰ï¼Œæˆ–è€…ç›´åˆ°è¾“å‡ºäº†è¡¨ç¤ºå¥å­æœ«å°¾çš„ tokenã€‚</p>
<h3 id="GPT2-æ€»ç»“"><a href="#GPT2-æ€»ç»“" class="headerlink" title="GPT2 æ€»ç»“"></a>GPT2 æ€»ç»“</h3><p>ç°åœ¨æˆ‘ä»¬åŸºæœ¬çŸ¥é“äº† GPT-2 æ˜¯å¦‚ä½•å·¥ä½œçš„ã€‚å¦‚æœä½ æƒ³çŸ¥é“ Self Attention å±‚é‡Œé¢åˆ°åº•å‘ç”Ÿäº†ä»€ä¹ˆï¼Œé‚£ä¹ˆæ–‡ç« æ¥ä¸‹æ¥çš„é¢å¤–éƒ¨åˆ†å°±æ˜¯ä¸ºä½ å‡†å¤‡çš„ï¼Œæˆ‘æ·»åŠ è¿™ä¸ªé¢å¤–çš„éƒ¨åˆ†ï¼Œæ¥ä½¿ç”¨æ›´å¤šå¯è§†åŒ–è§£é‡Š Self Attentionï¼Œä»¥ä¾¿æ›´åŠ å®¹æ˜“è®²è§£åé¢çš„ Transformer æ¨¡å‹ï¼ˆTransformerXL å’Œ XLNetï¼‰ã€‚</p>
<p>æˆ‘æƒ³åœ¨è¿™é‡ŒæŒ‡å‡ºæ–‡ä¸­ä¸€äº›è¿‡äºç®€åŒ–çš„è¯´æ³•ï¼š</p>
<ul>
<li>æˆ‘åœ¨æ–‡ä¸­äº¤æ›¿ä½¿ç”¨ token å’Œ è¯ã€‚ä½†å®é™…ä¸Šï¼ŒGPT-2 ä½¿ç”¨ Byte Pair Encoding åœ¨è¯æ±‡è¡¨ä¸­åˆ›å»º tokenã€‚è¿™æ„å‘³ç€ token é€šå¸¸æ˜¯è¯çš„ä¸€éƒ¨åˆ†ã€‚</li>
<li>æˆ‘ä»¬å±•ç¤ºçš„ä¾‹å­æ˜¯åœ¨æ¨ç†æ¨¡å¼ä¸‹è¿è¡Œã€‚è¿™å°±æ˜¯ä¸ºä»€ä¹ˆå®ƒä¸€æ¬¡åªå¤„ç†ä¸€ä¸ª tokenã€‚åœ¨è®­ç»ƒæ—¶ï¼Œæ¨¡å‹å°†ä¼šé’ˆå¯¹æ›´é•¿çš„æ–‡æœ¬åºåˆ—è¿›è¡Œè®­ç»ƒï¼Œå¹¶ä¸”åŒæ—¶å¤„ç†å¤šä¸ª tokenã€‚åŒæ ·ï¼Œåœ¨è®­ç»ƒæ—¶ï¼Œæ¨¡å‹ä¼šå¤„ç†æ›´å¤§çš„ batch sizeï¼Œè€Œä¸æ˜¯æ¨ç†æ—¶ä½¿ç”¨çš„å¤§å°ä¸º 1 çš„ batch sizeã€‚</li>
<li>ä¸ºäº†æ›´åŠ æ–¹ä¾¿åœ°è¯´æ˜åŸç†ï¼Œæˆ‘åœ¨æœ¬æ–‡çš„å›¾ç‰‡ä¸­ä¸€èˆ¬ä¼šä½¿ç”¨è¡Œå‘é‡ã€‚ä½†æœ‰äº›å‘é‡å®é™…ä¸Šæ˜¯åˆ—å‘é‡ã€‚åœ¨ä»£ç å®ç°ä¸­ï¼Œä½ éœ€è¦æ³¨æ„è¿™äº›å‘é‡çš„å½¢å¼ã€‚</li>
<li>Transformer ä½¿ç”¨äº†å¤§é‡çš„å±‚å½’ä¸€åŒ–ï¼ˆlayer normalizationï¼‰ï¼Œè¿™ä¸€ç‚¹æ˜¯å¾ˆé‡è¦çš„ã€‚æˆ‘ä»¬åœ¨å›¾è§£Transformerä¸­å·²ç»æåŠåˆ°äº†ä¸€éƒ¨åˆ†è¿™ç‚¹ï¼Œä½†åœ¨è¿™ç¯‡æ–‡ç« ï¼Œæˆ‘ä»¬ä¼šæ›´åŠ å…³æ³¨ Self Attentionã€‚</li>
<li>æœ‰æ—¶æˆ‘éœ€è¦æ›´å¤šçš„æ¡†æ¥è¡¨ç¤ºä¸€ä¸ªå‘é‡ï¼Œä¾‹å¦‚ä¸‹é¢è¿™å¹…å›¾ï¼š</li>
</ul>
<p><img src="4-gpt-sum.webp" alt="è¾“å…¥ä¸è¾“å‡ºç»´åº¦">å›¾ï¼šè¾“å…¥ä¸è¾“å‡ºç»´åº¦</p>
<h3 id="å¯è§†åŒ–-Self-Attention"><a href="#å¯è§†åŒ–-Self-Attention" class="headerlink" title="å¯è§†åŒ– Self-Attention"></a>å¯è§†åŒ– Self-Attention</h3><p>åœ¨è¿™ç¯‡æ–‡ç« çš„å‰é¢ï¼Œæˆ‘ä»¬ä½¿ç”¨äº†è¿™å¼ å›¾ç‰‡æ¥å±•ç¤ºï¼Œå¦‚ä½•åœ¨ä¸€ä¸ªå±‚ä¸­ä½¿ç”¨ Self Attentionï¼Œè¿™ä¸ªå±‚æ­£åœ¨å¤„ç†å•è¯ <code>it</code>ã€‚</p>
<p><img src="4-att-it.png" alt="itçš„attention">å›¾ï¼šitçš„attention</p>
<p>åœ¨è¿™ä¸€èŠ‚ï¼Œæˆ‘ä»¬ä¼šè¯¦ç»†ä»‹ç»å¦‚ä½•å®ç°è¿™ä¸€ç‚¹ã€‚è¯·æ³¨æ„ï¼Œæˆ‘ä»¬ä¼šè®²è§£æ¸…æ¥šæ¯ä¸ªå•è¯éƒ½å‘ç”Ÿäº†ä»€ä¹ˆã€‚è¿™å°±æ˜¯ä¸ºä»€ä¹ˆæˆ‘ä»¬ä¼šå±•ç¤ºå¤§é‡çš„å•ä¸ªå‘é‡ã€‚è€Œå®é™…çš„ä»£ç å®ç°ï¼Œæ˜¯é€šè¿‡å·¨å¤§çš„çŸ©é˜µç›¸ä¹˜æ¥å®Œæˆçš„ã€‚ä½†æˆ‘æƒ³æŠŠé‡ç‚¹æ”¾åœ¨è¯æ±‡å±‚é¢ä¸Šã€‚</p>
<h3 id="Self-Attention"><a href="#Self-Attention" class="headerlink" title="Self-Attention"></a>Self-Attention</h3><p>è®©æˆ‘ä»¬å…ˆçœ‹çœ‹åŸå§‹çš„ Self Attentionï¼Œå®ƒè¢«ç”¨åœ¨ Encoder æ¨¡å—ä¸­è¿›è¡Œè®¡ç®—ã€‚è®©æˆ‘ä»¬çœ‹çœ‹ä¸€ä¸ªç©å…· Transformerï¼Œå®ƒä¸€æ¬¡åªèƒ½å¤„ç† 4 ä¸ª tokenã€‚</p>
<p>Self-Attention ä¸»è¦é€šè¿‡ 3 ä¸ªæ­¥éª¤æ¥å®ç°ï¼š</p>
<ul>
<li>ä¸ºæ¯ä¸ªè·¯å¾„åˆ›å»º Queryã€Keyã€Value çŸ©é˜µã€‚</li>
<li>å¯¹äºæ¯ä¸ªè¾“å…¥çš„ tokenï¼Œä½¿ç”¨å®ƒçš„ Query å‘é‡ä¸ºæ‰€æœ‰å…¶ä»–çš„ Key å‘é‡è¿›è¡Œæ‰“åˆ†ã€‚</li>
<li>å°† Value å‘é‡ä¹˜ä»¥å®ƒä»¬å¯¹åº”çš„åˆ†æ•°åæ±‚å’Œã€‚</li>
</ul>
<p><img src="4-att-3.webp" alt="3æ­¥">å›¾ï¼š3æ­¥</p>
<p>(1) åˆ›å»º Queryã€Key å’Œ Value å‘é‡</p>
<p>è®©æˆ‘ä»¬å…³æ³¨ç¬¬ä¸€æ¡è·¯å¾„ã€‚æˆ‘ä»¬ä¼šä½¿ç”¨å®ƒçš„ Query å‘é‡ï¼Œå¹¶æ¯”è¾ƒæ‰€æœ‰çš„ Key å‘é‡ã€‚è¿™ä¼šä¸ºæ¯ä¸ª Key å‘é‡äº§ç”Ÿä¸€ä¸ªåˆ†æ•°ã€‚Self Attention çš„ç¬¬ä¸€æ­¥æ˜¯ä¸ºæ¯ä¸ª token çš„è·¯å¾„è®¡ç®— 3 ä¸ªå‘é‡ã€‚</p>
<p><img src="4-att-31.webp" alt="ç¬¬1æ­¥">å›¾ï¼šç¬¬1æ­¥</p>
<p>(2) è®¡ç®—åˆ†æ•°</p>
<p>ç°åœ¨æˆ‘ä»¬æœ‰äº†è¿™äº›å‘é‡ï¼Œæˆ‘ä»¬åªå¯¹æ­¥éª¤ 2 ä½¿ç”¨ Query å‘é‡å’Œ Value å‘é‡ã€‚å› ä¸ºæˆ‘ä»¬å…³æ³¨çš„æ˜¯ç¬¬ä¸€ä¸ª token çš„å‘é‡ï¼Œæˆ‘ä»¬å°†ç¬¬ä¸€ä¸ª token çš„ Query å‘é‡å’Œå…¶ä»–æ‰€æœ‰çš„ token çš„ Key å‘é‡ç›¸ä¹˜ï¼Œå¾—åˆ° 4 ä¸ª token çš„åˆ†æ•°ã€‚</p>
<p><img src="4-att-32.webp" alt="ç¬¬2æ­¥">å›¾ï¼šç¬¬2æ­¥</p>
<p>(3) è®¡ç®—å’Œ</p>
<p>æˆ‘ä»¬ç°åœ¨å¯ä»¥å°†è¿™äº›åˆ†æ•°å’Œ Value å‘é‡ç›¸ä¹˜ã€‚åœ¨æˆ‘ä»¬å°†å®ƒä»¬ç›¸åŠ åï¼Œä¸€ä¸ªå…·æœ‰é«˜åˆ†æ•°çš„ Value å‘é‡ä¼šå æ®ç»“æœå‘é‡çš„å¾ˆå¤§ä¸€éƒ¨åˆ†ã€‚</p>
<p><img src="4-att-33.webp" alt="ç¬¬3æ­¥">å›¾ï¼šç¬¬3æ­¥</p>
<p>åˆ†æ•°è¶Šä½ï¼ŒValue å‘é‡å°±è¶Šé€æ˜ã€‚è¿™æ˜¯ä¸ºäº†è¯´æ˜ï¼Œä¹˜ä»¥ä¸€ä¸ªå°çš„æ•°å€¼ä¼šç¨€é‡Š Value å‘é‡ã€‚</p>
<p>å¦‚æœæˆ‘ä»¬å¯¹æ¯ä¸ªè·¯å¾„éƒ½æ‰§è¡Œç›¸åŒçš„æ“ä½œï¼Œæˆ‘ä»¬ä¼šå¾—åˆ°ä¸€ä¸ªå‘é‡ï¼Œå¯ä»¥è¡¨ç¤ºæ¯ä¸ª tokenï¼Œå…¶ä¸­åŒ…å«æ¯ä¸ª token åˆé€‚çš„ä¸Šä¸‹æ–‡ä¿¡æ¯ã€‚è¿™äº›å‘é‡ä¼šè¾“å…¥åˆ° Transformer æ¨¡å—çš„ä¸‹ä¸€ä¸ªå­å±‚ï¼ˆå‰é¦ˆç¥ç»ç½‘ç»œï¼‰ã€‚</p>
<p><img src="4-att-34.webp" alt="æ±‡æ€»">å›¾ï¼šæ±‡æ€»</p>
<h3 id="å›¾è§£-Masked-Self-attention"><a href="#å›¾è§£-Masked-Self-attention" class="headerlink" title="å›¾è§£ Masked Self_attention"></a>å›¾è§£ Masked Self_attention</h3><p>ç°åœ¨ï¼Œæˆ‘ä»¬å·²ç»äº†è§£äº† Transformer çš„ Self Attention æ­¥éª¤ï¼Œç°åœ¨è®©æˆ‘ä»¬ç»§ç»­ç ”ç©¶ masked Self Attentionã€‚Masked Self Attention å’Œ Self Attention æ˜¯ç›¸åŒçš„ï¼Œé™¤äº†ç¬¬ 2 ä¸ªæ­¥éª¤ã€‚å‡è®¾æ¨¡å‹åªæœ‰  2 ä¸ª token ä½œä¸ºè¾“å…¥ï¼Œæˆ‘ä»¬æ­£åœ¨è§‚å¯Ÿï¼ˆå¤„ç†ï¼‰ç¬¬äºŒä¸ª tokenã€‚åœ¨è¿™ç§æƒ…å†µä¸‹ï¼Œæœ€å 2 ä¸ª token æ˜¯è¢«å±è”½ï¼ˆmaskedï¼‰çš„ã€‚æ‰€ä»¥æ¨¡å‹ä¼šå¹²æ‰°è¯„åˆ†çš„æ­¥éª¤ã€‚å®ƒåŸºæœ¬ä¸Šæ€»æ˜¯æŠŠæœªæ¥çš„ token è¯„åˆ†ä¸º 0ï¼Œå› æ­¤æ¨¡å‹ä¸èƒ½çœ‹åˆ°æœªæ¥çš„è¯ï¼š</p>
<p><img src="4-mask.webp" alt="masked self attention">å›¾ï¼šmasked self attention</p>
<p>è¿™ä¸ªå±è”½ï¼ˆmaskingï¼‰ç»å¸¸ç”¨ä¸€ä¸ªçŸ©é˜µæ¥å®ç°ï¼Œç§°ä¸º attention maskã€‚æƒ³è±¡ä¸€ä¸‹æœ‰ 4 ä¸ªå•è¯çš„åºåˆ—ï¼ˆä¾‹å¦‚ï¼Œæœºå™¨äººå¿…é¡»éµå®ˆå‘½ä»¤ï¼‰ã€‚åœ¨ä¸€ä¸ªè¯­è¨€å»ºæ¨¡åœºæ™¯ä¸­ï¼Œè¿™ä¸ªåºåˆ—ä¼šåˆ†ä¸º 4 ä¸ªæ­¥éª¤å¤„ç†â€“æ¯ä¸ªæ­¥éª¤å¤„ç†ä¸€ä¸ªè¯ï¼ˆå‡è®¾ç°åœ¨æ¯ä¸ªè¯æ˜¯ä¸€ä¸ª tokenï¼‰ã€‚ç”±äºè¿™äº›æ¨¡å‹æ˜¯ä»¥ batch size çš„å½¢å¼å·¥ä½œçš„ï¼Œæˆ‘ä»¬å¯ä»¥å‡è®¾è¿™ä¸ªç©å…·æ¨¡å‹çš„ batch size ä¸º 4ï¼Œå®ƒä¼šå°†æ•´ä¸ªåºåˆ—ä½œï¼ˆåŒ…æ‹¬ 4 ä¸ªæ­¥éª¤ï¼‰ä¸ºä¸€ä¸ª batch å¤„ç†ã€‚</p>
<p><img src="4-mask-matrix.webp" alt="masked çŸ©é˜µ">å›¾ï¼šmasked çŸ©é˜µ</p>
<p>åœ¨çŸ©é˜µçš„å½¢å¼ä¸­ï¼Œæˆ‘ä»¬æŠŠ Query çŸ©é˜µå’Œ Key çŸ©é˜µç›¸ä¹˜æ¥è®¡ç®—åˆ†æ•°ã€‚è®©æˆ‘ä»¬å°†å…¶å¯è§†åŒ–å¦‚ä¸‹ï¼Œä¸åŒçš„æ˜¯ï¼Œæˆ‘ä»¬ä¸ä½¿ç”¨å•è¯ï¼Œè€Œæ˜¯ä½¿ç”¨ä¸æ ¼å­ä¸­å•è¯å¯¹åº”çš„ Query çŸ©é˜µï¼ˆæˆ–è€… Key çŸ©é˜µï¼‰ã€‚</p>
<p><img src="4-mask-q.webp" alt="QueryçŸ©é˜µ">å›¾ï¼šQueryçŸ©é˜µ</p>
<p>åœ¨åšå®Œä¹˜æ³•ä¹‹åï¼Œæˆ‘ä»¬åŠ ä¸Šä¸‰è§’å½¢çš„ attention maskã€‚å®ƒå°†æˆ‘ä»¬æƒ³è¦å±è”½çš„å•å…ƒæ ¼è®¾ç½®ä¸ºè´Ÿæ— ç©·å¤§æˆ–è€…ä¸€ä¸ªéå¸¸å¤§çš„è´Ÿæ•°ï¼ˆä¾‹å¦‚ GPT-2 ä¸­çš„ è´Ÿåäº¿ï¼‰ï¼š</p>
<p><img src="4-mask-s.webp" alt="åŠ ä¸Šattetnionçš„mask">å›¾ï¼šåŠ ä¸Šattetnionçš„mask</p>
<p>ç„¶åå¯¹æ¯ä¸€è¡Œåº”ç”¨ softmaxï¼Œä¼šäº§ç”Ÿå®é™…çš„åˆ†æ•°ï¼Œæˆ‘ä»¬ä¼šå°†è¿™äº›åˆ†æ•°ç”¨äº Self Attentionã€‚</p>
<p><img src="4-mask-soft.webp" alt="softmax">å›¾ï¼šsoftmax</p>
<p>è¿™ä¸ªåˆ†æ•°è¡¨çš„å«ä¹‰å¦‚ä¸‹ï¼š</p>
<ul>
<li>å½“æ¨¡å‹å¤„ç†æ•°æ®é›†ä¸­çš„ç¬¬ 1 ä¸ªæ•°æ®ï¼ˆç¬¬ 1 è¡Œï¼‰ï¼Œå…¶ä¸­åªåŒ…å«ç€ä¸€ä¸ªå•è¯ ï¼ˆrobotï¼‰ï¼Œå®ƒå°† 100% çš„æ³¨æ„åŠ›é›†ä¸­åœ¨è¿™ä¸ªå•è¯ä¸Šã€‚</li>
<li>å½“æ¨¡å‹å¤„ç†æ•°æ®é›†ä¸­çš„ç¬¬ 2 ä¸ªæ•°æ®ï¼ˆç¬¬ 2 è¡Œï¼‰ï¼Œå…¶ä¸­åŒ…å«ç€å•è¯ï¼ˆrobot mustï¼‰ã€‚å½“æ¨¡å‹å¤„ç†å•è¯ mustï¼Œå®ƒå°† 48% çš„æ³¨æ„åŠ›é›†ä¸­åœ¨ robotï¼Œå°† 52% çš„æ³¨æ„åŠ›é›†ä¸­åœ¨ mustã€‚</li>
<li>è¯¸å¦‚æ­¤ç±»ï¼Œç»§ç»­å¤„ç†åé¢çš„å•è¯ã€‚</li>
</ul>
<h3 id="GPT2-çš„-Self-Attention"><a href="#GPT2-çš„-Self-Attention" class="headerlink" title="GPT2 çš„ Self-Attention"></a>GPT2 çš„ Self-Attention</h3><p>è®©æˆ‘ä»¬æ›´è¯¦ç»†åœ°äº†è§£ GPT-2 çš„ masked attentionã€‚</p>
<p><em>è¯„ä»·æ¨¡å‹ï¼šæ¯æ¬¡å¤„ç†ä¸€ä¸ª token</em></p>
<p>æˆ‘ä»¬å¯ä»¥è®© GPT-2 åƒ mask Self Attention ä¸€æ ·å·¥ä½œã€‚ä½†æ˜¯åœ¨è¯„ä»·æ¨¡å‹æ—¶ï¼Œå½“æˆ‘ä»¬çš„æ¨¡å‹åœ¨æ¯æ¬¡è¿­ä»£ååªæ·»åŠ ä¸€ä¸ªæ–°è¯ï¼Œé‚£ä¹ˆå¯¹äºå·²ç»å¤„ç†è¿‡çš„ token æ¥è¯´ï¼Œæ²¿ç€ä¹‹å‰çš„è·¯å¾„é‡æ–°è®¡ç®— Self Attention æ˜¯ä½æ•ˆçš„ã€‚</p>
<p>åœ¨è¿™ç§æƒ…å†µä¸‹ï¼Œæˆ‘ä»¬å¤„ç†ç¬¬ä¸€ä¸ª tokenï¼ˆç°åœ¨æš‚æ—¶å¿½ç•¥ &lt;s&gt;ï¼‰ã€‚</p>
<p><img src="4-gpt2-self.png" alt="gpt2ç¬¬ä¸€ä¸ªtoken">å›¾ï¼šgpt2ç¬¬ä¸€ä¸ªtoken</p>
<p>GPT-2 ä¿å­˜ token <code>a</code> çš„ Key å‘é‡å’Œ Value å‘é‡ã€‚æ¯ä¸ª Self Attention å±‚éƒ½æŒæœ‰è¿™ä¸ª token å¯¹åº”çš„ Key å‘é‡å’Œ Value å‘é‡ï¼š</p>
<p><img src="4-gpt2-a.png" alt="gpt2çš„è¯a">å›¾ï¼šgpt2çš„è¯a</p>
<p>ç°åœ¨åœ¨ä¸‹ä¸€ä¸ªè¿­ä»£ï¼Œå½“æ¨¡å‹å¤„ç†å•è¯ robotï¼Œå®ƒä¸éœ€è¦ç”Ÿæˆ token a çš„ Queryã€Value ä»¥åŠ Key å‘é‡ã€‚å®ƒåªéœ€è¦é‡æ–°ä½¿ç”¨ç¬¬ä¸€æ¬¡è¿­ä»£ä¸­ä¿å­˜çš„å¯¹åº”å‘é‡ï¼š</p>
<p><img src="4-gpt2-r.png" alt="gpt2çš„è¯robot">å›¾ï¼šgpt2çš„è¯robot</p>
<p><code>(1) åˆ›å»º Queryã€Key å’Œ Value çŸ©é˜µ</code></p>
<p>è®©æˆ‘ä»¬å‡è®¾æ¨¡å‹æ­£åœ¨å¤„ç†å•è¯ <code>it</code>ã€‚å¦‚æœæˆ‘ä»¬è®¨è®ºæœ€ä¸‹é¢çš„æ¨¡å—ï¼ˆå¯¹äºæœ€ä¸‹é¢çš„æ¨¡å—æ¥è¯´ï¼‰ï¼Œè¿™ä¸ª token å¯¹åº”çš„è¾“å…¥å°±æ˜¯ <code>it</code> çš„ embedding åŠ ä¸Šç¬¬ 9 ä¸ªä½ç½®çš„ä½ç½®ç¼–ç ï¼š</p>
<p><img src="4-gpt2-it.webp" alt="å¤„ç†it">å›¾ï¼šå¤„ç†it</p>
<p>Transformer ä¸­æ¯ä¸ªæ¨¡å—éƒ½æœ‰å®ƒè‡ªå·±çš„æƒé‡ï¼ˆåœ¨åæ–‡ä¸­ä¼šæ‹†è§£å±•ç¤ºï¼‰ã€‚æˆ‘ä»¬é¦–å…ˆé‡åˆ°çš„æƒé‡çŸ©é˜µæ˜¯ç”¨äºåˆ›å»º Queryã€Keyã€å’Œ Value å‘é‡çš„ã€‚</p>
<p><img src="4-gpt2-it1.webp" alt="å¤„ç†it">å›¾ï¼šå¤„ç†it</p>
<p>Self-Attention å°†å®ƒçš„è¾“å…¥ä¹˜ä»¥æƒé‡çŸ©é˜µï¼ˆå¹¶æ·»åŠ ä¸€ä¸ª bias å‘é‡ï¼Œæ­¤å¤„æ²¡æœ‰ç”»å‡º)</p>
<p>è¿™ä¸ªç›¸ä¹˜ä¼šå¾—åˆ°ä¸€ä¸ªå‘é‡ï¼Œè¿™ä¸ªå‘é‡åŸºæœ¬ä¸Šæ˜¯ Queryã€Key å’Œ Value å‘é‡çš„æ‹¼æ¥ã€‚<br><img src="4-gpt2-it2.webp" alt="å¤„ç†it">å›¾ï¼šå¤„ç†it</p>
<p>å°†è¾“å…¥å‘é‡ä¸ attention æƒé‡å‘é‡ç›¸ä¹˜ï¼ˆå¹¶åŠ ä¸Šä¸€ä¸ª bias å‘é‡ï¼‰å¾—åˆ°è¿™ä¸ª token çš„ Keyã€Value å’Œ Query å‘é‡æ‹†åˆ†ä¸º attention headsã€‚</p>
<p>åœ¨ä¹‹å‰çš„ä¾‹å­ä¸­ï¼Œæˆ‘ä»¬åªå…³æ³¨äº† Self Attentionï¼Œå¿½ç•¥äº† multi-head çš„éƒ¨åˆ†ã€‚ç°åœ¨å¯¹è¿™ä¸ªæ¦‚å¿µåšä¸€äº›è®²è§£æ˜¯éå¸¸æœ‰å¸®åŠ©çš„ã€‚Self-attention åœ¨ Qã€Kã€V å‘é‡çš„ä¸åŒéƒ¨åˆ†è¿›è¡Œäº†å¤šæ¬¡è®¡ç®—ã€‚æ‹†åˆ† attention heads åªæ˜¯æŠŠä¸€ä¸ªé•¿å‘é‡å˜ä¸ºçŸ©é˜µã€‚å°çš„ GPT-2 æœ‰ 12 ä¸ª attention headsï¼Œå› æ­¤è¿™å°†æ˜¯å˜æ¢åçš„çŸ©é˜µçš„ç¬¬ä¸€ä¸ªç»´åº¦ï¼š</p>
<p><img src="4-gpt2-it3.png" alt="å¤„ç†it">å›¾ï¼šå¤„ç†it</p>
<p>åœ¨ä¹‹å‰çš„ä¾‹å­ä¸­ï¼Œæˆ‘ä»¬ç ”ç©¶äº†ä¸€ä¸ª attention head çš„å†…éƒ¨å‘ç”Ÿäº†ä»€ä¹ˆã€‚ç†è§£å¤šä¸ª attention-heads çš„ä¸€ç§æ–¹æ³•ï¼Œæ˜¯åƒä¸‹é¢è¿™æ ·ï¼ˆå¦‚æœæˆ‘ä»¬åªå¯è§†åŒ– 12 ä¸ª attention heads ä¸­çš„ 3 ä¸ªï¼‰ï¼š</p>
<p><img src="4-gpt2-it4.webp" alt="å¤„ç†it">å›¾ï¼šå¤„ç†it</p>
<p><code>(2) è¯„åˆ†</code></p>
<p>æˆ‘ä»¬ç°åœ¨å¯ä»¥ç»§ç»­è¿›è¡Œè¯„åˆ†ï¼Œè¿™é‡Œæˆ‘ä»¬åªå…³æ³¨ä¸€ä¸ª attention headï¼ˆå…¶ä»–çš„ attention head ä¹Ÿæ˜¯åœ¨è¿›è¡Œç±»ä¼¼çš„æ“ä½œï¼‰ã€‚</p>
<p><img src="4-gpt2-it5.webp">å›¾ï¼šå¤„ç†it</p>
<p>ç°åœ¨ï¼Œè¿™ä¸ª token å¯ä»¥æ ¹æ®å…¶ä»–æ‰€æœ‰ token çš„ Key å‘é‡è¿›è¡Œè¯„åˆ†ï¼ˆè¿™äº› Key å‘é‡æ˜¯åœ¨å‰é¢ä¸€ä¸ªè¿­ä»£ä¸­çš„ç¬¬ä¸€ä¸ª attention head è®¡ç®—å¾—åˆ°çš„ï¼‰ï¼š</p>
<p><img src="4-gpt2-it6.webp">å›¾ï¼š</p>
<p><code>(3) æ±‚å’Œ</code></p>
<p>æ­£å¦‚æˆ‘ä»¬ä¹‹å‰æ‰€çœ‹çš„é‚£æ ·ï¼Œæˆ‘ä»¬ç°åœ¨å°†æ¯ä¸ª Value å‘é‡ä¹˜ä»¥å¯¹åº”çš„åˆ†æ•°ï¼Œç„¶ååŠ èµ·æ¥æ±‚å’Œï¼Œå¾—åˆ°ç¬¬ä¸€ä¸ª attention head çš„ Self Attention ç»“æœï¼š</p>
<p><img src="4-gpt2-it7.webp" alt="å¤„ç†it">å›¾ï¼š</p>
<p><code>åˆå¹¶ attention heads</code></p>
<p>æˆ‘ä»¬å¤„ç†å„ç§æ³¨æ„åŠ›çš„æ–¹æ³•æ˜¯é¦–å…ˆæŠŠå®ƒä»¬è¿æ¥æˆä¸€ä¸ªå‘é‡ï¼š</p>
<p><img src="4-gpt2-it8.webp" alt="å¤„ç†it">å›¾ï¼šå¤„ç†it</p>
<p>ä½†è¿™ä¸ªå‘é‡è¿˜æ²¡æœ‰å‡†å¤‡å¥½å‘é€åˆ°ä¸‹ä¸€ä¸ªå­å±‚ï¼ˆå‘é‡çš„é•¿åº¦ä¸å¯¹ï¼‰ã€‚æˆ‘ä»¬é¦–å…ˆéœ€è¦æŠŠè¿™ä¸ªéšå±‚çŠ¶æ€çš„å·¨å¤§å‘é‡è½¬æ¢ä¸ºåŒè´¨çš„è¡¨ç¤ºã€‚</p>
<p><code>(4) æ˜ å°„ï¼ˆæŠ•å½±ï¼‰</code></p>
<p>æˆ‘ä»¬å°†è®©æ¨¡å‹å­¦ä¹ å¦‚ä½•å°†æ‹¼æ¥å¥½çš„ Self Attention ç»“æœè½¬æ¢ä¸ºå‰é¦ˆç¥ç»ç½‘ç»œèƒ½å¤Ÿå¤„ç†çš„å½¢çŠ¶ã€‚åœ¨è¿™é‡Œï¼Œæˆ‘ä»¬ä½¿ç”¨ç¬¬äºŒä¸ªå·¨å¤§çš„æƒé‡çŸ©é˜µï¼Œå°† attention heads çš„ç»“æœæ˜ å°„åˆ° Self Attention å­å±‚çš„è¾“å‡ºå‘é‡ï¼š</p>
<p><img src="4-project.png" alt="æ˜ å°„">å›¾ï¼šæ˜ å°„</p>
<p>é€šè¿‡è¿™ä¸ªï¼Œæˆ‘ä»¬äº§ç”Ÿäº†ä¸€ä¸ªå‘é‡ï¼Œæˆ‘ä»¬å¯ä»¥æŠŠè¿™ä¸ªå‘é‡ä¼ ç»™ä¸‹ä¸€å±‚ï¼š</p>
<p><img src="4-vector.webp" alt="ä¼ ç»™ä¸‹ä¸€å±‚">å›¾ï¼šä¼ ç»™ä¸‹ä¸€å±‚</p>
<h3 id="GPT-2-å…¨è¿æ¥ç¥ç»ç½‘ç»œ"><a href="#GPT-2-å…¨è¿æ¥ç¥ç»ç½‘ç»œ" class="headerlink" title="GPT-2 å…¨è¿æ¥ç¥ç»ç½‘ç»œ"></a>GPT-2 å…¨è¿æ¥ç¥ç»ç½‘ç»œ</h3><p><code>ç¬¬ 1 å±‚</code></p>
<p>å…¨è¿æ¥ç¥ç»ç½‘ç»œæ˜¯ç”¨äºå¤„ç† Self Attention å±‚çš„è¾“å‡ºï¼Œè¿™ä¸ªè¾“å‡ºçš„è¡¨ç¤ºåŒ…å«äº†åˆé€‚çš„ä¸Šä¸‹æ–‡ã€‚å…¨è¿æ¥ç¥ç»ç½‘ç»œç”±ä¸¤å±‚ç»„æˆã€‚ç¬¬ä¸€å±‚æ˜¯æ¨¡å‹å¤§å°çš„ 4 å€ï¼ˆç”±äº GPT-2 small æ˜¯ 768ï¼Œå› æ­¤è¿™ä¸ªç½‘ç»œä¼šæœ‰3072ä¸ªç¥ç»å…ƒï¼‰ã€‚ä¸ºä»€ä¹ˆæ˜¯å››å€ï¼Ÿè¿™åªæ˜¯å› ä¸ºè¿™æ˜¯åŸå§‹ Transformer çš„å¤§å°ï¼ˆå¦‚æœæ¨¡å‹çš„ç»´åº¦æ˜¯ 512ï¼Œé‚£ä¹ˆå…¨è¿æ¥ç¥ç»ç½‘ç»œä¸­ç¬¬ä¸€ä¸ªå±‚çš„ç»´åº¦æ˜¯ 2048ï¼‰ã€‚è¿™ä¼¼ä¹ç»™äº† Transformer è¶³å¤Ÿçš„è¡¨è¾¾èƒ½åŠ›ï¼Œæ¥å¤„ç†ç›®å‰çš„ä»»åŠ¡ã€‚</p>
<p><img src="4-full.gif" alt="å…¨è¿æ¥å±‚">åŠ¨æ€å›¾ï¼šå…¨è¿æ¥å±‚</p>
<p>æ²¡æœ‰å±•ç¤º bias å‘é‡</p>
<p><code>ç¬¬ 2 å±‚. æŠŠå‘é‡æ˜ å°„åˆ°æ¨¡å‹çš„ç»´åº¦</code></p>
<p>ç¬¬ 2 å±‚æŠŠç¬¬ä¸€å±‚å¾—åˆ°çš„ç»“æœæ˜ å°„å›æ¨¡å‹çš„ç»´åº¦ï¼ˆåœ¨ GPT-2 small ä¸­æ˜¯ 768ï¼‰ã€‚è¿™ä¸ªç›¸ä¹˜çš„ç»“æœæ˜¯ Transformer å¯¹è¿™ä¸ª token çš„è¾“å‡ºã€‚</p>
<p><img src="4-full.webp" alt="å…¨è¿æ¥å±‚">å›¾ï¼šå…¨è¿æ¥å±‚</p>
<p>æ²¡æœ‰å±•ç¤º bias å‘é‡</p>
<p>ä½ å®Œæˆäº†ï¼</p>
<p>è¿™å°±æ˜¯æˆ‘ä»¬è®¨è®ºçš„ Transformer çš„æœ€è¯¦ç»†çš„ç‰ˆæœ¬ï¼ç°åœ¨ï¼Œä½ å‡ ä¹å·²ç»äº†è§£äº† Transformer è¯­è¨€æ¨¡å‹å†…éƒ¨å‘ç”Ÿäº†ä»€ä¹ˆã€‚æ€»ç»“ä¸€ä¸‹ï¼Œæˆ‘ä»¬çš„è¾“å…¥ä¼šé‡åˆ°ä¸‹é¢è¿™äº›æƒé‡çŸ©é˜µï¼š</p>
<p><img src="4-sum.png" alt="æ€»ç»“">å›¾ï¼š</p>
<p>æ¯ä¸ªæ¨¡å—éƒ½æœ‰å®ƒè‡ªå·±çš„æƒé‡ã€‚å¦ä¸€æ–¹é¢ï¼Œæ¨¡å‹åªæœ‰ä¸€ä¸ª token embedding çŸ©é˜µå’Œä¸€ä¸ªä½ç½®ç¼–ç çŸ©é˜µã€‚</p>
<p><img src="4-sum1.png" alt="æ€»ç»“">å›¾ï¼šæ€»ç»“</p>
<p>å¦‚æœä½ æƒ³æŸ¥çœ‹æ¨¡å‹çš„æ‰€æœ‰å‚æ•°ï¼Œæˆ‘åœ¨è¿™é‡Œå¯¹å®ƒä»¬è¿›è¡Œäº†ç»Ÿè®¡ï¼š</p>
<p><img src="4-sum2.png" alt="æ€»ç»“">å›¾ï¼šæ€»ç»“<br>ç”±äºæŸäº›åŸå› ï¼Œå®ƒä»¬åŠ èµ·æ¥æ˜¯ 124 Mï¼Œè€Œä¸æ˜¯ 117 Mã€‚æˆ‘ä¸ç¡®å®šè¿™æ˜¯ä¸ºä»€ä¹ˆï¼Œä½†è¿™ä¸ªå°±æ˜¯åœ¨å‘å¸ƒçš„ä»£ç ä¸­å±•ç¤ºçš„å¤§å°ï¼ˆå¦‚æœæˆ‘é”™äº†ï¼Œè¯·çº æ­£æˆ‘ï¼‰ã€‚</p>
<h2 id="è¯­è¨€æ¨¡å‹ä¹‹å¤–"><a href="#è¯­è¨€æ¨¡å‹ä¹‹å¤–" class="headerlink" title="è¯­è¨€æ¨¡å‹ä¹‹å¤–"></a>è¯­è¨€æ¨¡å‹ä¹‹å¤–</h2><p>åªæœ‰ Decoder çš„ Transformer åœ¨è¯­è¨€æ¨¡å‹ä¹‹å¤–ä¸€ç›´å±•ç°å‡ºä¸é”™çš„åº”ç”¨ã€‚å®ƒå·²ç»è¢«æˆåŠŸåº”ç”¨åœ¨äº†è®¸å¤šåº”ç”¨ä¸­ï¼Œæˆ‘ä»¬å¯ä»¥ç”¨ç±»ä¼¼ä¸Šé¢çš„å¯è§†åŒ–æ¥æè¿°è¿™äº›æˆåŠŸåº”ç”¨ã€‚è®©æˆ‘ä»¬çœ‹çœ‹è¿™äº›åº”ç”¨ï¼Œä½œä¸ºè¿™ç¯‡æ–‡ç« çš„ç»“å°¾ã€‚</p>
<h3 id="æœºå™¨ç¿»è¯‘"><a href="#æœºå™¨ç¿»è¯‘" class="headerlink" title="æœºå™¨ç¿»è¯‘"></a>æœºå™¨ç¿»è¯‘</h3><p>è¿›è¡Œæœºå™¨ç¿»è¯‘æ—¶ï¼ŒEncoder ä¸æ˜¯å¿…é¡»çš„ã€‚æˆ‘ä»¬å¯ä»¥ç”¨åªæœ‰ Decoder çš„ Transformer æ¥è§£å†³åŒæ ·çš„ä»»åŠ¡ï¼š</p>
<p><img src="4-trans.png" alt="ç¿»è¯‘">å›¾ï¼šç¿»è¯‘</p>
<h3 id="ç”Ÿæˆæ‘˜è¦"><a href="#ç”Ÿæˆæ‘˜è¦" class="headerlink" title="ç”Ÿæˆæ‘˜è¦"></a>ç”Ÿæˆæ‘˜è¦</h3><p>è¿™æ˜¯ç¬¬ä¸€ä¸ªåªä½¿ç”¨ Decoder çš„ Transformer æ¥è®­ç»ƒçš„ä»»åŠ¡ã€‚å®ƒè¢«è®­ç»ƒç”¨äºé˜…è¯»ä¸€ç¯‡ç»´åŸºç™¾ç§‘çš„æ–‡ç« ï¼ˆç›®å½•å‰é¢å»æ‰äº†å¼€å¤´éƒ¨åˆ†ï¼‰ï¼Œç„¶åç”Ÿæˆæ‘˜è¦ã€‚æ–‡ç« çš„å®é™…å¼€å¤´éƒ¨åˆ†ç”¨ä½œè®­ç»ƒæ•°æ®çš„æ ‡ç­¾ï¼š<br><img src="4-wiki.png" alt="æ‘˜è¦">å›¾ï¼š</p>
<p>è®ºæ–‡é‡Œé’ˆå¯¹ç»´åŸºç™¾ç§‘çš„æ–‡ç« å¯¹æ¨¡å‹è¿›è¡Œäº†è®­ç»ƒï¼Œå› æ­¤è¿™ä¸ªæ¨¡å‹èƒ½å¤Ÿæ€»ç»“æ–‡ç« ï¼Œç”Ÿæˆæ‘˜è¦ï¼š</p>
<p><img src="4-wiki1.webp" alt="æ‘˜è¦">å›¾ï¼šæ‘˜è¦</p>
<h3 id="è¿ç§»å­¦ä¹ "><a href="#è¿ç§»å­¦ä¹ " class="headerlink" title="è¿ç§»å­¦ä¹ "></a>è¿ç§»å­¦ä¹ </h3><p>åœ¨ Sample Efficient Text Summarization Using a Single Pre-Trained Transformer(<a href="https://arxiv.org/abs/1905.08836">https://arxiv.org/abs/1905.08836</a>) ä¸­ï¼Œä¸€ä¸ªåªæœ‰ Decoder çš„ Transformer é¦–å…ˆåœ¨è¯­è¨€æ¨¡å‹ä¸Šè¿›è¡Œé¢„è®­ç»ƒï¼Œç„¶åå¾®è°ƒè¿›è¡Œç”Ÿæˆæ‘˜è¦ã€‚ç»“æœè¡¨æ˜ï¼Œåœ¨æ•°æ®é‡æœ‰é™åˆ¶æ—¶ï¼Œå®ƒæ¯”é¢„è®­ç»ƒçš„ Encoder-Decoder Transformer èƒ½å¤Ÿè·å¾—æ›´å¥½çš„ç»“æœã€‚</p>
<p>GPT-2 çš„è®ºæ–‡ä¹Ÿå±•ç¤ºäº†åœ¨è¯­è¨€æ¨¡å‹è¿›è¡Œé¢„è®­ç»ƒçš„ç”Ÿæˆæ‘˜è¦çš„ç»“æœã€‚</p>
<h3 id="éŸ³ä¹ç”Ÿæˆ"><a href="#éŸ³ä¹ç”Ÿæˆ" class="headerlink" title="éŸ³ä¹ç”Ÿæˆ"></a>éŸ³ä¹ç”Ÿæˆ</h3><p>Music Transformer(<a href="https://magenta.tensorflow.org/music-transformer">https://magenta.tensorflow.org/music-transformer</a>) è®ºæ–‡ä½¿ç”¨äº†åªæœ‰ Decoder çš„ Transformer æ¥ç”Ÿæˆå…·æœ‰è¡¨ç°åŠ›çš„æ—¶åºå’ŒåŠ¨æ€æ€§çš„éŸ³ä¹ã€‚éŸ³ä¹å»ºæ¨¡ å°±åƒè¯­è¨€å»ºæ¨¡ä¸€æ ·ï¼Œåªéœ€è¦è®©æ¨¡å‹ä»¥æ— ç›‘ç£çš„æ–¹å¼å­¦ä¹ éŸ³ä¹ï¼Œç„¶åè®©å®ƒé‡‡æ ·è¾“å‡ºï¼ˆå‰é¢æˆ‘ä»¬ç§°è¿™ä¸ªä¸º æ¼«æ­¥ï¼‰ã€‚</p>
<p>ä½ å¯èƒ½ä¼šå¥½å¥‡åœ¨è¿™ä¸ªåœºæ™¯ä¸­ï¼ŒéŸ³ä¹æ˜¯å¦‚ä½•è¡¨ç°çš„ã€‚è¯·è®°ä½ï¼Œè¯­è¨€å»ºæ¨¡å¯ä»¥æŠŠå­—ç¬¦ã€å•è¯ã€æˆ–è€…å•è¯çš„ä¸€éƒ¨åˆ†ï¼ˆtokenï¼‰ï¼Œè¡¨ç¤ºä¸ºå‘é‡ã€‚åœ¨éŸ³ä¹è¡¨æ¼”ä¸­ï¼ˆè®©æˆ‘ä»¬è€ƒè™‘ä¸€ä¸‹é’¢ç´ï¼‰ï¼Œæˆ‘ä»¬ä¸ä»…è¦è¡¨ç¤ºéŸ³ç¬¦ï¼Œè¿˜è¦è¡¨ç¤ºé€Ÿåº¦â€“è¡¡é‡é’¢ç´é”®è¢«æŒ‰ä¸‹çš„åŠ›åº¦ã€‚</p>
<p><img src="4-music.webp" alt="éŸ³ä¹ç”Ÿæˆ">å›¾ï¼šéŸ³ä¹ç”Ÿæˆ</p>
<p>ä¸€åœºè¡¨æ¼”å°±æ˜¯ä¸€ç³»åˆ—çš„ one-hot å‘é‡ã€‚ä¸€ä¸ª midi æ–‡ä»¶å¯ä»¥è½¬æ¢ä¸ºä¸‹é¢è¿™ç§æ ¼å¼ã€‚è®ºæ–‡é‡Œä½¿ç”¨äº†ä¸‹é¢è¿™ç§è¾“å…¥åºåˆ—ä½œä¸ºä¾‹å­ï¼š</p>
<p><img src="4-music1.png" alt="éŸ³ä¹ç”Ÿæˆ">å›¾ï¼šéŸ³ä¹ç”Ÿæˆ</p>
<p>è¿™ä¸ªè¾“å…¥ç³»åˆ—çš„ one-hot å‘é‡è¡¨ç¤ºå¦‚ä¸‹ï¼š</p>
<p><img src="4-music2.png" alt="éŸ³ä¹ç”Ÿæˆ">å›¾ï¼šéŸ³ä¹ç”Ÿæˆ</p>
<p>æˆ‘å–œæ¬¢è®ºæ–‡ä¸­çš„éŸ³ä¹ Transformer å±•ç¤ºçš„ä¸€ä¸ª Self Attention çš„å¯è§†åŒ–ã€‚æˆ‘åœ¨è¿™åŸºç¡€ä¹‹ä¸Šæ·»åŠ äº†ä¸€äº›æ³¨é‡Šï¼š</p>
<p><img src="4-music3.png" alt="éŸ³ä¹ç”Ÿæˆ">å›¾ï¼šéŸ³ä¹ç”Ÿæˆ</p>
<p>è¿™æ®µéŸ³ä¹æœ‰ä¸€ä¸ªåå¤å‡ºç°çš„ä¸‰è§’å½¢è½®å»“ã€‚Query çŸ©é˜µä½äºåé¢çš„ä¸€ä¸ªå³°å€¼ï¼Œå®ƒæ³¨æ„åˆ°å‰é¢æ‰€æœ‰å³°å€¼çš„é«˜éŸ³ç¬¦ï¼Œä»¥çŸ¥é“éŸ³ä¹çš„å¼€å¤´ã€‚è¿™å¹…å›¾å±•ç¤ºäº†ä¸€ä¸ª Query å‘é‡ï¼ˆæ‰€æœ‰ attention çº¿çš„æ¥æºï¼‰å’Œå‰é¢è¢«å…³æ³¨çš„è®°å¿†ï¼ˆé‚£äº›å—åˆ°æ›´å¤§çš„softmax æ¦‚ç‡çš„é«˜äº®éŸ³ç¬¦ï¼‰ã€‚attention çº¿çš„é¢œè‰²å¯¹åº”ä¸åŒçš„ attention headsï¼Œå®½åº¦å¯¹åº”äº softmax æ¦‚ç‡çš„æƒé‡ã€‚</p>
<h2 id="æ€»ç»“"><a href="#æ€»ç»“" class="headerlink" title="æ€»ç»“"></a>æ€»ç»“</h2><p>ç°åœ¨ï¼Œæˆ‘ä»¬ç»“æŸäº† GPT-2 çš„æ—…ç¨‹ï¼Œä»¥åŠå¯¹å…¶çˆ¶æ¨¡å‹ï¼ˆåªæœ‰ Decoder çš„ Transformerï¼‰çš„æ¢ç´¢ã€‚æˆ‘å¸Œæœ›ä½ çœ‹å®Œè¿™ç¯‡æ–‡ç« åï¼Œèƒ½å¯¹ Self Attention æœ‰ä¸€ä¸ªæ›´å¥½çš„ç†è§£ï¼Œä¹Ÿå¸Œæœ›ä½ èƒ½å¯¹ Transformer å†…éƒ¨å‘ç”Ÿçš„äº‹æƒ…æœ‰æ›´å¤šçš„ç†è§£ã€‚</p>
<h2 id="è‡´è°¢-1"><a href="#è‡´è°¢-1" class="headerlink" title="è‡´è°¢"></a>è‡´è°¢</h2><p>ä¸»è¦ç”±å“ˆå°”æ»¨å·¥ä¸šå¤§å­¦å¼ è´¤åŒå­¦ç¿»è¯‘ï¼ˆç»è¿‡åŸä½œè€…æˆæƒï¼‰æ’°å†™ï¼Œç”±æœ¬é¡¹ç›®åŒå­¦ç»„ç»‡å’Œæ•´ç†ã€‚</p>
]]></content>
      
        
    </entry>
    
    <entry>
      <title><![CDATA[NLP-transformer]]></title>
      <url>/2021/08/18/NLP-transformer/</url>
      <content type="html"><![CDATA[<ul>
<li>DataWhaleå¼€æºå­¦ä¹ èµ„æ–™:<a href="https://github.com/datawhalechina/learn-nlp-with-transformers">https://github.com/datawhalechina/learn-nlp-with-transformers</a><h2 id="å›¾è§£Attention"><a href="#å›¾è§£Attention" class="headerlink" title="å›¾è§£Attention"></a>å›¾è§£Attention</h2></li>
</ul>
<p>Seq2seqï¼šæœ‰2ç¯‡å¼€åˆ›æ€§çš„è®ºæ–‡ï¼š<a href="https://papers.nips.cc/paper/5346-sequence-to-sequence-learning-with-neural-networks.pdf">Sutskeverç­‰2014å¹´å‘è¡¨çš„Sequence to Sequence Learning<br>with Neural Networks</a>å’Œ<a href="http://emnlp2014.org/papers/pdf/EMNLP2014179.pdf">Choç­‰2014å¹´å‘è¡¨çš„Learning Phrase Representations using RNN Encoderâ€“Decoder<br>for Statistical Machine Translation</a>éƒ½å¯¹è¿™äº›æ¨¡å‹è¿›è¡Œäº†è§£é‡Šã€‚</p>
<p>ç¼–ç å™¨å’Œè§£ç å™¨åœ¨Transformerå‡ºç°ä¹‹å‰ä¸€èˆ¬é‡‡ç”¨çš„æ˜¯å¾ªç¯ç¥ç»ç½‘ç»œã€‚å…³äºå¾ªç¯ç¥ç»ç½‘ç»œï¼Œå»ºè®®é˜…è¯» <a href="https://www.youtube.com/watch?v=UNmqTiOnRfg">Luis Serranoå†™çš„ä¸€ç¯‡å…³äºå¾ªç¯ç¥ç»ç½‘ç»œ</a>çš„ç²¾å½©ä»‹ç».</p>
<p>å¦‚æœä½ è§‰å¾—ä½ å‡†å¤‡å¥½äº†å­¦ä¹ æ³¨æ„åŠ›æœºåˆ¶çš„ä»£ç å®ç°ï¼Œä¸€å®šè¦çœ‹çœ‹åŸºäº TensorFlow çš„ ç¥ç»æœºå™¨ç¿»è¯‘ (seq2seq) <a href="https://github.com/tensorflow/nmt">æŒ‡å—</a>ã€‚</p>
<h2 id="å›¾è§£transformer"><a href="#å›¾è§£transformer" class="headerlink" title="å›¾è§£transformer"></a>å›¾è§£transformer</h2><p>æœ¬æ–‡ç¿»è¯‘è‡ª<a href="http://jalammar.github.io/illustrated-transformer">illustrated-transformer</a></p>
<p>æ·»åŠ äº†ä¸€äº›ç®€å•çš„ä»£ç ï¼Œå®ç°äº†ä¸€ä¸ªåŸºæœ¬çš„ Self Attention ä»¥åŠ multi-head attention çš„çŸ©é˜µè¿ç®—ã€‚</p>
<p>2017 å¹´ï¼ŒGoogle æå‡ºäº† Transformer æ¨¡å‹ï¼Œç”¨ <strong>Self Attention</strong> çš„ç»“æ„ï¼Œå–ä»£äº†ä»¥å¾€ NLP ä»»åŠ¡ä¸­çš„ <strong>RNN</strong> ç½‘ç»œç»“æ„</p>
<p>ç”¨Self Attentionæœºåˆ¶æ•ˆæœåˆå¥½ï¼Œè€Œä¸”è¿˜å¯ä»¥å¹¶è¡Œè®¡ç®—ã€‚<br>ï¼ˆè¿™ä¸ªæ¨¡å‹çš„å…¶ä¸­ä¸€ä¸ªä¼˜ç‚¹ï¼Œå°±æ˜¯ä½¿å¾—æ¨¡å‹è®­ç»ƒè¿‡ç¨‹èƒ½å¤Ÿå¹¶è¡Œè®¡ç®—ã€‚åœ¨ RNN ä¸­ï¼Œæ¯ä¸€ä¸ª time step çš„è®¡ç®—éƒ½ä¾èµ–äºä¸Šä¸€ä¸ª time step çš„è¾“å‡ºï¼Œè¿™å°±ä½¿å¾—æ‰€æœ‰çš„ time step å¿…é¡»ä¸²è¡ŒåŒ–ï¼Œæ— æ³•å¹¶è¡Œè®¡ç®—ã€‚ï¼‰</p>
<p>ç¼–ç éƒ¨åˆ†æ˜¯å¤šå±‚çš„ç¼–ç å™¨(Encoder)ç»„æˆï¼ˆTransformer çš„è®ºæ–‡ä¸­ä½¿ç”¨äº† 6 å±‚ç¼–ç å™¨ï¼Œè¿™é‡Œçš„å±‚æ•° 6 å¹¶ä¸æ˜¯å›ºå®šçš„ï¼Œä½ ä¹Ÿå¯ä»¥æ ¹æ®å®éªŒæ•ˆæœæ¥ä¿®æ”¹å±‚æ•°ï¼‰ã€‚åŒç†ï¼Œè§£ç éƒ¨åˆ†ä¹Ÿæ˜¯ç”±å¤šå±‚çš„è§£ç å™¨(Decoder)ç»„æˆï¼ˆè®ºæ–‡é‡Œä¹Ÿä½¿ç”¨äº† 6 å±‚çš„è§£ç å™¨ï¼‰ã€‚æ¯å±‚ç¼–ç å™¨åœ¨ç»“æ„ä¸Šéƒ½æ˜¯ä¸€æ ·çš„ï¼Œä½†ä¸åŒå±‚ç¼–ç å™¨çš„æƒé‡å‚æ•°æ˜¯ä¸åŒçš„ã€‚</p>
<h3 id="ç¼–ç å™¨"><a href="#ç¼–ç å™¨" class="headerlink" title="ç¼–ç å™¨"></a>ç¼–ç å™¨</h3><p>æ¯å±‚ç¼–ç å™¨é‡Œé¢ï¼Œä¸»è¦ç”±ä»¥ä¸‹ä¸¤éƒ¨åˆ†ç»„æˆï¼š</p>
<ul>
<li>Self-Attention Layer</li>
<li>Feed Forward Neural Networkï¼ˆå‰é¦ˆç¥ç»ç½‘ç»œï¼Œç¼©å†™ä¸º FFNNï¼‰<br><img src="2-encoder.png" alt="encoder"></li>
</ul>
<h3 id="è§£ç å™¨"><a href="#è§£ç å™¨" class="headerlink" title="è§£ç å™¨"></a>è§£ç å™¨</h3><p>åŒç†ï¼Œè§£ç å™¨ä¹Ÿå…·æœ‰è¿™ä¸¤å±‚ï¼Œ<strong>ä½†æ˜¯è¿™ä¸¤å±‚ä¸­é—´è¿˜æ’å…¥äº†ä¸€ä¸ª Encoder-Decoder Attention å±‚</strong>ï¼Œè¿™ä¸ªå±‚èƒ½å¸®åŠ©è§£ç å™¨èšç„¦äºè¾“å…¥å¥å­çš„ç›¸å…³éƒ¨åˆ†ï¼ˆç±»ä¼¼äº seq2seq æ¨¡å‹ ä¸­çš„ Attentionï¼‰ã€‚<br><img src="2-decoder.webp" alt="decoder"></p>
<h3 id="Transformerç»†èŠ‚"><a href="#Transformerç»†èŠ‚" class="headerlink" title="Transformerç»†èŠ‚"></a>Transformerç»†èŠ‚</h3><h4 id="Transformer-çš„è¾“å…¥"><a href="#Transformer-çš„è¾“å…¥" class="headerlink" title="Transformer çš„è¾“å…¥"></a>Transformer çš„è¾“å…¥</h4><p>å’Œé€šå¸¸çš„ NLP ä»»åŠ¡ä¸€æ ·ï¼Œæˆ‘ä»¬<strong>é¦–å…ˆä¼šä½¿ç”¨è¯åµŒå…¥ç®—æ³•ï¼ˆembedding algorithmï¼‰</strong>ï¼Œå°†æ¯ä¸ªè¯è½¬æ¢ä¸ºä¸€ä¸ªè¯å‘é‡ã€‚å®é™…ä¸­å‘é‡ä¸€èˆ¬æ˜¯ 256 æˆ–è€… 512 ç»´ã€‚</p>
<p>é‚£ä¹ˆæ•´ä¸ªè¾“å…¥çš„å¥å­æ˜¯ä¸€ä¸ªå‘é‡åˆ—è¡¨ï¼Œå…¶ä¸­æœ‰ 3 ä¸ªè¯å‘é‡ã€‚åœ¨å®é™…ä¸­ï¼Œæ¯ä¸ªå¥å­çš„é•¿åº¦ä¸ä¸€æ ·ï¼Œæˆ‘ä»¬ä¼šå–ä¸€ä¸ªé€‚å½“çš„å€¼ï¼Œä½œä¸ºå‘é‡åˆ—è¡¨çš„é•¿åº¦ã€‚<strong>å¦‚æœä¸€ä¸ªå¥å­è¾¾ä¸åˆ°è¿™ä¸ªé•¿åº¦</strong>ï¼Œ<strong>é‚£ä¹ˆå°±å¡«å……å…¨ä¸º 0 çš„è¯å‘é‡</strong>ï¼›<strong>å¦‚æœå¥å­è¶…å‡ºè¿™ä¸ªé•¿åº¦ï¼Œåˆ™åšæˆªæ–­</strong>ã€‚å¥å­é•¿åº¦æ˜¯ä¸€ä¸ªè¶…å‚æ•°ï¼Œé€šå¸¸æ˜¯è®­ç»ƒé›†ä¸­çš„å¥å­çš„æœ€å¤§é•¿åº¦ï¼Œä½ å¯ä»¥å°è¯•ä¸åŒé•¿åº¦çš„æ•ˆæœã€‚</p>
<p>ç¼–ç å™¨ï¼ˆEncoderï¼‰æ¥æ”¶çš„è¾“å…¥éƒ½æ˜¯ä¸€ä¸ªå‘é‡åˆ—è¡¨ï¼Œè¾“å‡ºä¹Ÿæ˜¯å¤§å°åŒæ ·çš„å‘é‡åˆ—è¡¨ã€‚</p>
<p><img src="2-x-encoder.png" alt="è¾“å…¥encoder"><br>å›¾ï¼šè¾“å…¥encoder</p>
<p><img src="2-multi-encoder.webp" alt="ä¸€å±‚ä¼ ä¸€å±‚"><br>å›¾ï¼šä¸€å±‚ä¼ ä¸€å±‚</p>
<p>æ¯ä¸€ä¸ªäººéƒ½ç»å†è¿‡ç±»ä¼¼çš„æ— çŸ¥çš„ç‹¼ç‹ˆï¼Œå…¶å®æ¯ä¸€ä¸ªäººéƒ½ç»å†äº†è‡ªæˆ‘æ€€ç–‘ä¹‹åæ‰èƒ½å¦‚é‡Šé‡è´Ÿã€‚<br><strong>åˆ«è¢«â€œSelf-Attentionâ€è¿™ä¹ˆé«˜å¤§ä¸Šçš„è¯ç»™å”¬ä½äº†ï¼Œä¹ä¸€å¬å¥½åƒæ¯ä¸ªäººéƒ½åº”è¯¥å¯¹è¿™ä¸ªè¯ç†Ÿæ‚‰ä¸€æ ·</strong>ã€‚</p>
<p>å½“æ¨¡å‹å¤„ç†å¥å­ä¸­çš„æ¯ä¸ªè¯æ—¶ï¼ŒSelf Attentionæœºåˆ¶ä½¿å¾—æ¨¡å‹ä¸ä»…èƒ½å¤Ÿå…³æ³¨è¿™ä¸ªä½ç½®çš„è¯ï¼Œè€Œä¸”èƒ½å¤Ÿå…³æ³¨å¥å­ä¸­å…¶ä»–ä½ç½®çš„è¯ï¼Œä½œä¸ºè¾…åŠ©çº¿ç´¢ï¼Œè¿›è€Œå¯ä»¥æ›´å¥½åœ°ç¼–ç å½“å‰ä½ç½®çš„è¯ã€‚å¦‚æœä½ ç†Ÿæ‚‰ RNNï¼Œå›å¿†ä¸€ä¸‹ï¼šRNN åœ¨å¤„ç†ä¸€ä¸ªè¯æ—¶ï¼Œä¼šè€ƒè™‘å‰é¢ä¼ è¿‡æ¥çš„hidden stateï¼Œè€Œhidden stateå°±åŒ…å«äº†å‰é¢çš„è¯çš„ä¿¡æ¯ã€‚è€Œ Transformer ä½¿ç”¨Self Attentionæœºåˆ¶ï¼Œä¼šæŠŠå…¶ä»–å•è¯çš„ç†è§£èå…¥å¤„ç†å½“å‰çš„å•è¯ã€‚</p>
<h3 id="Self-Attentionçš„ç»†èŠ‚"><a href="#Self-Attentionçš„ç»†èŠ‚" class="headerlink" title="Self-Attentionçš„ç»†èŠ‚"></a>Self-Attentionçš„ç»†èŠ‚</h3><p>è®¡ç®—Query å‘é‡ï¼ŒKey å‘é‡ï¼ŒValue å‘é‡</p>
<p>ä¸‹é¢æˆ‘ä»¬å…ˆçœ‹ä¸‹å¦‚ä½•ä½¿ç”¨å‘é‡æ¥è®¡ç®— Self Attentionï¼Œç„¶åå†çœ‹ä¸‹å¦‚ä½•ä½¿ç”¨çŸ©é˜µæ¥å®ç° Self Attentionã€‚ï¼ˆçŸ©é˜µè¿ç®—çš„æ–¹å¼ï¼Œä½¿å¾— Self Attention çš„è®¡ç®—èƒ½å¤Ÿå¹¶è¡ŒåŒ–ï¼Œè¿™ä¹Ÿæ˜¯ Self Attention æœ€ç»ˆçš„å®ç°æ–¹å¼ï¼‰ã€‚</p>
<p>è®¡ç®— Self Attention çš„ç¬¬ 1 æ­¥æ˜¯ï¼šå¯¹è¾“å…¥ç¼–ç å™¨çš„æ¯ä¸ªè¯å‘é‡ï¼Œéƒ½åˆ›å»º 3 ä¸ªå‘é‡ï¼Œåˆ†åˆ«æ˜¯ï¼šQuery å‘é‡ï¼ŒKey å‘é‡ï¼ŒValue å‘é‡ã€‚è¿™ 3 ä¸ªå‘é‡æ˜¯è¯å‘é‡åˆ†åˆ«å’Œ 3 ä¸ªçŸ©é˜µç›¸ä¹˜å¾—åˆ°çš„ï¼Œè€Œè¿™ä¸ªçŸ©é˜µæ˜¯æˆ‘ä»¬è¦å­¦ä¹ çš„å‚æ•°ã€‚</p>
<p>æ³¨æ„ï¼Œè¿™ 3 ä¸ªæ–°å¾—åˆ°çš„å‘é‡ä¸€èˆ¬æ¯”åŸæ¥çš„è¯å‘é‡çš„é•¿åº¦æ›´å°ã€‚å‡è®¾è¿™ 3 ä¸ªå‘é‡çš„é•¿åº¦æ˜¯$d_{key}$ï¼Œè€ŒåŸå§‹çš„è¯å‘é‡æˆ–è€…æœ€ç»ˆè¾“å‡ºçš„å‘é‡çš„é•¿åº¦æ˜¯ 512ï¼ˆ<strong>è¿™ 3 ä¸ªå‘é‡çš„é•¿åº¦ï¼Œå’Œæœ€ç»ˆè¾“å‡ºçš„å‘é‡é•¿åº¦ï¼Œæ˜¯æœ‰å€æ•°å…³ç³»çš„</strong>ï¼‰ã€‚å…³äº Multi-head Attentionï¼Œåé¢ä¼šç»™å‡ºå®é™…ä»£ç ã€‚è¿™é‡Œä¸ºäº†ç®€åŒ–ï¼Œå‡è®¾åªæœ‰ä¸€ä¸ª head çš„ Self-Attentionã€‚</p>
<p><img src="2-qkv.png" alt="Q,K,V">å›¾ï¼šQ,K,V</p>
<p>è¿™é‡Œå¯ä»¥é”»ç‚¼ä¸€ä¸‹githubçš„æäº¤ï¼Œä¸Šä¸‹è§’æ ‡ï¼Ÿï¼Ÿï¼Ÿï¼Ÿï¼Ÿï¼Ÿ</p>
<p>ä¸Šå›¾ä¸­ï¼Œæœ‰ä¸¤ä¸ªè¯å‘é‡ï¼šThinking çš„è¯å‘é‡ x1 å’Œ Machines çš„è¯å‘é‡ x2ã€‚ä»¥ x1 ä¸ºä¾‹ï¼ŒX1 ä¹˜ä»¥ WQ å¾—åˆ° q1ï¼Œq1 å°±æ˜¯ X1 å¯¹åº”çš„ Query å‘é‡ã€‚åŒç†ï¼ŒX1 ä¹˜ä»¥ WK å¾—åˆ° k1ï¼Œk1 æ˜¯ X1 å¯¹åº”çš„ Key å‘é‡ï¼›X1 ä¹˜ä»¥ WV å¾—åˆ° v1ï¼Œv1 æ˜¯ X1 å¯¹åº”çš„ Value å‘é‡ã€‚</p>
<p><strong>Query å‘é‡ï¼ŒKey å‘é‡ï¼ŒValue å‘é‡æ˜¯ä»€ä¹ˆå«ä¹‰å‘¢</strong>ï¼Ÿ</p>
<h4 id="è®¡ç®—-Attention-Scoreï¼ˆæ³¨æ„åŠ›åˆ†æ•°ï¼‰"><a href="#è®¡ç®—-Attention-Scoreï¼ˆæ³¨æ„åŠ›åˆ†æ•°ï¼‰" class="headerlink" title="è®¡ç®— Attention Scoreï¼ˆæ³¨æ„åŠ›åˆ†æ•°ï¼‰"></a>è®¡ç®— Attention Scoreï¼ˆæ³¨æ„åŠ›åˆ†æ•°ï¼‰</h4><p>ç¬¬ 2 æ­¥ï¼Œæ˜¯è®¡ç®— Attention Scoreï¼ˆæ³¨æ„åŠ›åˆ†æ•°ï¼‰ã€‚å‡è®¾æˆ‘ä»¬ç°åœ¨è®¡ç®—ç¬¬ä¸€ä¸ªè¯ Thinking çš„ Attention Scoreï¼ˆæ³¨æ„åŠ›åˆ†æ•°ï¼‰ï¼Œ<strong>éœ€è¦æ ¹æ® Thinking è¿™ä¸ªè¯ï¼Œå¯¹å¥å­ä¸­çš„å…¶ä»–æ¯ä¸ªè¯éƒ½è®¡ç®—ä¸€ä¸ªåˆ†æ•°</strong>ã€‚è¿™äº›åˆ†æ•°å†³å®šäº†æˆ‘ä»¬åœ¨ç¼–ç Thinkingè¿™ä¸ªè¯æ—¶ï¼Œéœ€è¦å¯¹å¥å­ä¸­å…¶ä»–ä½ç½®çš„æ¯ä¸ªè¯æ”¾ç½®å¤šå°‘çš„æ³¨æ„åŠ›ã€‚</p>
<p>è¿™äº›åˆ†æ•°ï¼Œæ˜¯é€šè¿‡è®¡ç®— â€œThinkingâ€ å¯¹åº”çš„ Query å‘é‡å’Œå…¶ä»–ä½ç½®çš„æ¯ä¸ªè¯çš„ Key å‘é‡çš„ç‚¹ç§¯ï¼Œè€Œå¾—åˆ°çš„ã€‚å¦‚æœæˆ‘ä»¬è®¡ç®—å¥å­ä¸­ç¬¬ä¸€ä¸ªä½ç½®å•è¯çš„ Attention Scoreï¼ˆæ³¨æ„åŠ›åˆ†æ•°ï¼‰ï¼Œé‚£ä¹ˆç¬¬ä¸€ä¸ªåˆ†æ•°å°±æ˜¯ q1 å’Œ k1 çš„å†…ç§¯ï¼Œç¬¬äºŒä¸ªåˆ†æ•°å°±æ˜¯ q1 å’Œ k2 çš„ç‚¹ç§¯ã€‚</p>
<p><img src="2-think.png" alt="Thinkingè®¡ç®—"><br>å›¾ï¼šThinkingè®¡ç®—</p>
<p>ç¬¬ 3 æ­¥å°±æ˜¯æŠŠæ¯ä¸ªåˆ†æ•°é™¤ä»¥ $\sqrt(d_{key})$ ï¼ˆ$d_{key}$æ˜¯ Key å‘é‡çš„é•¿åº¦ï¼‰ã€‚ä½ ä¹Ÿå¯ä»¥é™¤ä»¥å…¶ä»–æ•°ï¼Œé™¤ä»¥ä¸€ä¸ªæ•°æ˜¯ä¸ºäº†åœ¨åå‘ä¼ æ’­æ—¶ï¼Œæ±‚å–æ¢¯åº¦æ›´åŠ ç¨³å®šã€‚</p>
<p>ç¬¬ 4 æ­¥ï¼Œæ¥ç€æŠŠè¿™äº›åˆ†æ•°ç»è¿‡ä¸€ä¸ª Softmax å±‚ï¼ŒSoftmaxå¯ä»¥å°†åˆ†æ•°å½’ä¸€åŒ–ï¼Œè¿™æ ·ä½¿å¾—åˆ†æ•°éƒ½æ˜¯æ­£æ•°å¹¶ä¸”åŠ èµ·æ¥ç­‰äº 1ã€‚</p>
<p><img src="2-think2.png" alt="Thinkingè®¡ç®—"><br>å›¾ï¼šThinkingè®¡ç®—</p>
<p>è¿™äº›åˆ†æ•°å†³å®šäº†åœ¨ç¼–ç å½“å‰ä½ç½®ï¼ˆè¿™é‡Œçš„ä¾‹å­æ˜¯ç¬¬ä¸€ä¸ªä½ç½®ï¼‰çš„è¯æ—¶ï¼Œå¯¹æ‰€æœ‰ä½ç½®çš„è¯åˆ†åˆ«æœ‰å¤šå°‘çš„æ³¨æ„åŠ›ã€‚å¾ˆæ˜æ˜¾ï¼Œåœ¨ä¸Šå›¾çš„ä¾‹å­ä¸­ï¼Œå½“å‰ä½ç½®ï¼ˆè¿™é‡Œçš„ä¾‹å­æ˜¯ç¬¬ä¸€ä¸ªä½ç½®ï¼‰çš„è¯ä¼šæœ‰æœ€é«˜çš„åˆ†æ•°ï¼Œä½†æœ‰æ—¶ï¼Œå…³æ³¨åˆ°å…¶ä»–ä½ç½®ä¸Šç›¸å…³çš„è¯ä¹Ÿå¾ˆæœ‰ç”¨ã€‚</p>
<p>ç¬¬ 5 æ­¥ï¼Œå¾—åˆ°æ¯ä¸ªä½ç½®çš„åˆ†æ•°åï¼Œå°†æ¯ä¸ªåˆ†æ•°åˆ†åˆ«ä¸æ¯ä¸ª Value å‘é‡ç›¸ä¹˜ã€‚è¿™ç§åšæ³•èƒŒåçš„ç›´è§‰ç†è§£å°±æ˜¯ï¼šå¯¹äºåˆ†æ•°é«˜çš„ä½ç½®ï¼Œç›¸ä¹˜åçš„å€¼å°±è¶Šå¤§ï¼Œæˆ‘ä»¬æŠŠæ›´å¤šçš„æ³¨æ„åŠ›æ”¾åˆ°äº†å®ƒä»¬èº«ä¸Šï¼›å¯¹äºåˆ†æ•°ä½çš„ä½ç½®ï¼Œç›¸ä¹˜åçš„å€¼å°±è¶Šå°ï¼Œè¿™äº›ä½ç½®çš„è¯å¯èƒ½æ˜¯ç›¸å…³æ€§ä¸å¤§çš„ï¼Œè¿™æ ·æˆ‘ä»¬å°±å¿½ç•¥äº†è¿™äº›ä½ç½®çš„è¯ã€‚</p>
<p>ç¬¬ 6 æ­¥æ˜¯æŠŠä¸Šä¸€æ­¥å¾—åˆ°çš„å‘é‡ç›¸åŠ ï¼Œå°±å¾—åˆ°äº† Self Attention å±‚åœ¨è¿™ä¸ªä½ç½®ï¼ˆè¿™é‡Œçš„ä¾‹å­æ˜¯ç¬¬ä¸€ä¸ªä½ç½®ï¼‰çš„è¾“å‡ºã€‚</p>
<p><img src="2-sum.png" alt="Thinkè®¡ç®—"><br>å›¾ï¼šThinkè®¡ç®—</p>
<p>ä¸Šé¢è¿™å¼ å›¾ï¼ŒåŒ…å«äº† Self Attention çš„å…¨è¿‡ç¨‹ï¼Œæœ€ç»ˆå¾—åˆ°çš„å½“å‰ä½ç½®ï¼ˆè¿™é‡Œçš„ä¾‹å­æ˜¯ç¬¬ä¸€ä¸ªä½ç½®ï¼‰çš„å‘é‡ä¼šè¾“å…¥åˆ°å‰é¦ˆç¥ç»ç½‘ç»œã€‚ä½†è¿™æ ·æ¯æ¬¡åªèƒ½è®¡ç®—ä¸€ä¸ªä½ç½®çš„è¾“å‡ºå‘é‡ï¼Œåœ¨å®é™…çš„ä»£ç å®ç°ä¸­ï¼ŒSelf Attention çš„è®¡ç®—è¿‡ç¨‹æ˜¯ä½¿ç”¨çŸ©é˜µæ¥å®ç°çš„ï¼Œè¿™æ ·å¯ä»¥åŠ é€Ÿè®¡ç®—ï¼Œä¸€æ¬¡å°±å¾—åˆ°æ‰€æœ‰ä½ç½®çš„è¾“å‡ºå‘é‡ã€‚ä¸‹é¢è®©æˆ‘ä»¬æ¥çœ‹ï¼Œå¦‚ä½•ä½¿ç”¨çŸ©é˜µæ¥è®¡ç®—æ‰€æœ‰ä½ç½®çš„è¾“å‡ºå‘é‡ã€‚</p>
<h4 id="ä½¿ç”¨çŸ©é˜µè®¡ç®—Self-Attention"><a href="#ä½¿ç”¨çŸ©é˜µè®¡ç®—Self-Attention" class="headerlink" title="ä½¿ç”¨çŸ©é˜µè®¡ç®—Self-Attention"></a>ä½¿ç”¨çŸ©é˜µè®¡ç®—Self-Attention</h4><p>ç¬¬ä¸€æ­¥æ˜¯è®¡ç®— Queryï¼ŒKeyï¼ŒValue çš„çŸ©é˜µã€‚é¦–å…ˆï¼Œæˆ‘ä»¬æŠŠæ‰€æœ‰è¯å‘é‡æ”¾åˆ°ä¸€ä¸ªçŸ©é˜µ X ä¸­ï¼Œç„¶ååˆ†åˆ«å’Œ3 ä¸ªæƒé‡çŸ©é˜µ$W^Q, W^K W^V$ ç›¸ä¹˜ï¼Œå¾—åˆ° Qï¼ŒKï¼ŒV çŸ©é˜µã€‚</p>
<p><img src="2-qkv-multi.png">å›¾ï¼šQKVçŸ©é˜µä¹˜æ³•</p>
<p>?????? WQ\WKçŸ©é˜µéƒ½æ˜¯æ€ä¹ˆæ¥çš„</p>
<p>çŸ©é˜µ X ä¸­çš„æ¯ä¸€è¡Œï¼Œè¡¨ç¤ºå¥å­ä¸­çš„æ¯ä¸€ä¸ªè¯çš„è¯å‘é‡ï¼Œé•¿åº¦æ˜¯ 512ã€‚Qï¼ŒKï¼ŒV çŸ©é˜µä¸­çš„æ¯ä¸€è¡Œè¡¨ç¤º Query å‘é‡ï¼ŒKey å‘é‡ï¼ŒValue å‘é‡ï¼Œå‘é‡é•¿åº¦æ˜¯ 64ã€‚</p>
<p>æ¥ç€ï¼Œç”±äºæˆ‘ä»¬ä½¿ç”¨äº†çŸ©é˜µæ¥è®¡ç®—ï¼Œæˆ‘ä»¬å¯ä»¥æŠŠä¸Šé¢çš„ç¬¬ 2 æ­¥åˆ°ç¬¬ 6 æ­¥å‹ç¼©ä¸ºä¸€æ­¥ï¼Œç›´æ¥å¾—åˆ° Self Attention çš„è¾“å‡ºã€‚</p>
<p><img src="2-attention-output.webp" alt="è¾“å‡º"><br>å›¾ï¼šè¾“å‡º</p>
<h4 id="å¤šå¤´æ³¨æ„åŠ›æœºåˆ¶ï¼ˆmulti-head-attentionï¼‰"><a href="#å¤šå¤´æ³¨æ„åŠ›æœºåˆ¶ï¼ˆmulti-head-attentionï¼‰" class="headerlink" title="å¤šå¤´æ³¨æ„åŠ›æœºåˆ¶ï¼ˆmulti-head attentionï¼‰"></a>å¤šå¤´æ³¨æ„åŠ›æœºåˆ¶ï¼ˆmulti-head attentionï¼‰</h4><p>Transformer çš„è®ºæ–‡é€šè¿‡å¢åŠ å¤šå¤´æ³¨æ„åŠ›æœºåˆ¶ï¼ˆä¸€ç»„æ³¨æ„åŠ›ç§°ä¸ºä¸€ä¸ª attention headï¼‰ï¼Œè¿›ä¸€æ­¥å®Œå–„äº† Self Attention å±‚ã€‚è¿™ç§æœºåˆ¶ä»å¦‚ä¸‹ä¸¤ä¸ªæ–¹é¢å¢å¼ºäº† attention å±‚çš„èƒ½åŠ›ï¼š</p>
<ul>
<li>å®ƒæ‰©å±•äº†æ¨¡å‹å…³æ³¨ä¸åŒä½ç½®çš„èƒ½åŠ›ã€‚</li>
<li>å¤šå¤´æ³¨æ„åŠ›æœºåˆ¶èµ‹äºˆ attention å±‚å¤šä¸ªâ€œå­è¡¨ç¤ºç©ºé—´â€ã€‚</li>
</ul>
<p>æ¥ä¸‹æ¥å°±æœ‰ç‚¹éº»çƒ¦äº†ï¼Œå› ä¸ºå‰é¦ˆç¥ç»ç½‘ç»œå±‚æ¥æ”¶çš„æ˜¯ 1 ä¸ªçŸ©é˜µï¼ˆå…¶ä¸­æ¯è¡Œçš„å‘é‡è¡¨ç¤ºä¸€ä¸ªè¯ï¼‰ï¼Œè€Œä¸æ˜¯ 8 ä¸ªçŸ©é˜µã€‚æ‰€ä»¥æˆ‘ä»¬éœ€è¦ä¸€ç§æ–¹æ³•ï¼ŒæŠŠ 8 ä¸ªçŸ©é˜µæ•´åˆä¸ºä¸€ä¸ªçŸ©é˜µã€‚</p>
<p>æ€ä¹ˆæ‰èƒ½åšåˆ°å‘¢ï¼Ÿæˆ‘ä»¬æŠŠçŸ©é˜µæ‹¼æ¥èµ·æ¥ï¼Œç„¶åå’Œå¦ä¸€ä¸ªæƒé‡çŸ©é˜µ$W^Q$ç›¸ä¹˜ã€‚</p>
<p><img src="2-to1.webp" alt="æ•´åˆçŸ©é˜µ"><br>å›¾ï¼šæ•´åˆçŸ©é˜µ</p>
<ol>
<li>æŠŠ 8 ä¸ªçŸ©é˜µ {Z0,Z1â€¦,Z7} æ‹¼æ¥èµ·æ¥</li>
<li>æŠŠæ‹¼æ¥åçš„çŸ©é˜µå’Œ WO æƒé‡çŸ©é˜µç›¸ä¹˜</li>
<li>å¾—åˆ°æœ€ç»ˆçš„çŸ©é˜µ Zï¼Œè¿™ä¸ªçŸ©é˜µåŒ…å«äº†æ‰€æœ‰ attention headsï¼ˆæ³¨æ„åŠ›å¤´ï¼‰ çš„ä¿¡æ¯ã€‚è¿™ä¸ªçŸ©é˜µä¼šè¾“å…¥åˆ° FFNN (Feed Forward Neural Network)å±‚ã€‚</li>
</ol>
<p>è¿™å°±æ˜¯å¤šå¤´æ³¨æ„åŠ›çš„å…¨éƒ¨å†…å®¹ã€‚æˆ‘çŸ¥é“ï¼Œåœ¨ä¸Šé¢çš„è®²è§£ä¸­ï¼Œå‡ºç°äº†ç›¸å½“å¤šçš„çŸ©é˜µã€‚ä¸‹é¢æˆ‘æŠŠæ‰€æœ‰çš„å†…å®¹éƒ½æ”¾åˆ°ä¸€å¼ å›¾ä¸­ï¼Œè¿™æ ·ä½ å¯ä»¥æ€»æ½å…¨å±€ï¼Œåœ¨è¿™å¼ å›¾ä¸­çœ‹åˆ°æ‰€æœ‰çš„å†…å®¹ã€‚</p>
<p><img src="2-put-together.webp" alt="æ”¾åœ¨ä¸€èµ·"><br>å›¾ï¼šæ”¾åœ¨ä¸€èµ·</p>
<p>æ—¢ç„¶æˆ‘ä»¬å·²ç»è°ˆåˆ°äº†å¤šå¤´æ³¨æ„åŠ›ï¼Œç°åœ¨è®©æˆ‘ä»¬é‡æ–°å›é¡¾ä¹‹å‰çš„ç¿»è¯‘ä¾‹å­ï¼Œçœ‹ä¸‹å½“æˆ‘ä»¬ç¼–ç å•è¯itæ—¶ï¼Œä¸åŒçš„ attention heads ï¼ˆæ³¨æ„åŠ›å¤´ï¼‰å…³æ³¨çš„æ˜¯ä»€ä¹ˆéƒ¨åˆ†ã€‚</p>
<p><img src="2-it-attention.webp" alt="`it`çš„attention"><br>å›¾ï¼š<code>it</code>çš„attention</p>
<p>å½“æˆ‘ä»¬ç¼–ç å•è¯â€itâ€æ—¶ï¼Œå…¶ä¸­ä¸€ä¸ª attention head ï¼ˆæ³¨æ„åŠ›å¤´ï¼‰æœ€å…³æ³¨çš„æ˜¯â€the animalâ€ï¼Œå¦å¤–ä¸€ä¸ª attention head å…³æ³¨çš„æ˜¯â€tiredâ€ã€‚å› æ­¤åœ¨æŸç§æ„ä¹‰ä¸Šï¼Œâ€itâ€åœ¨æ¨¡å‹ä¸­çš„è¡¨ç¤ºï¼Œèåˆäº†â€animalâ€å’Œâ€wordâ€çš„éƒ¨åˆ†è¡¨è¾¾ã€‚</p>
<p>ç„¶è€Œï¼Œå½“æˆ‘ä»¬æŠŠæ‰€æœ‰ attention headsï¼ˆæ³¨æ„åŠ›å¤´ï¼‰ éƒ½åœ¨å›¾ä¸Šç”»å‡ºæ¥æ—¶ï¼Œå¤šå¤´æ³¨æ„åŠ›åˆå˜å¾—éš¾ä»¥è§£é‡Šäº†ã€‚</p>
<p><img src="2-all-att.png" alt="æ‰€æœ‰æ³¨æ„åŠ›heads"><br>å›¾ï¼šæ‰€æœ‰æ³¨æ„åŠ›heads</p>
<h2 id="ä»£ç å®ç°çŸ©é˜µè®¡ç®—-Attention"><a href="#ä»£ç å®ç°çŸ©é˜µè®¡ç®—-Attention" class="headerlink" title="ä»£ç å®ç°çŸ©é˜µè®¡ç®— Attention"></a>ä»£ç å®ç°çŸ©é˜µè®¡ç®— Attention</h2><p>éœ€è¦æ³¨æ„çš„æ˜¯ï¼šåœ¨å‰é¢çš„è®²è§£ä¸­ï¼Œæˆ‘ä»¬çš„ Kã€Qã€V çŸ©é˜µçš„åºåˆ—é•¿åº¦éƒ½æ˜¯ä¸€æ ·çš„ã€‚ä½†æ˜¯åœ¨å®é™…ä¸­ï¼ŒKã€V çŸ©é˜µçš„åºåˆ—é•¿åº¦æ˜¯ä¸€æ ·çš„ï¼Œè€Œ Q çŸ©é˜µçš„åºåˆ—é•¿åº¦å¯ä»¥ä¸ä¸€æ ·ã€‚</p>
<p>è¿™ç§æƒ…å†µå‘ç”Ÿåœ¨ï¼šåœ¨è§£ç å™¨éƒ¨åˆ†çš„Encoder-Decoder Attentionå±‚ä¸­ï¼ŒQ çŸ©é˜µæ˜¯æ¥è‡ªè§£ç å™¨ä¸‹å±‚ï¼Œè€Œ Kã€V çŸ©é˜µåˆ™æ˜¯æ¥è‡ªç¼–ç å™¨çš„è¾“å‡ºã€‚</p>
<p><img src="2-encoder-decoder.gif" alt="encoder-decoderåŠ¨æ€å›¾"><br>åŠ¨æ€å›¾ï¼šencoder-decoderåŠ¨æ€å›¾</p>
<p>åœ¨å®Œæˆäº†ç¼–ç ï¼ˆencodingï¼‰é˜¶æ®µä¹‹åï¼Œæˆ‘ä»¬å¼€å§‹è§£ç ï¼ˆdecodingï¼‰é˜¶æ®µã€‚è§£ç ï¼ˆdecoding ï¼‰é˜¶æ®µçš„æ¯ä¸€ä¸ªæ—¶é—´æ­¥éƒ½è¾“å‡ºä¸€ä¸ªç¿»è¯‘åçš„å•è¯ï¼ˆè¿™é‡Œçš„ä¾‹å­æ˜¯è‹±è¯­ç¿»è¯‘ï¼‰ã€‚</p>
<p>è¾“å‡ºæ˜¯ï¼š</p>
<ul>
<li>attn_outputï¼šå½¢çŠ¶æ˜¯ (L,N,E)</li>
<li>attn_output_weightsï¼šå½¢çŠ¶æ˜¯ (N,L,S)<br>ä»£ç ç¤ºä¾‹å¦‚ä¸‹ï¼š</li>
</ul>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">## nn.MultiheadAttention è¾“å…¥ç¬¬0ç»´ä¸ºlength</span><br><span class="line"># batch_size ä¸º 64ï¼Œæœ‰ 12 ä¸ªè¯ï¼Œæ¯ä¸ªè¯çš„ Query å‘é‡æ˜¯ 300 ç»´</span><br><span class="line">query &#x3D; torch.rand(12,64,300)</span><br><span class="line"># batch_size ä¸º 64ï¼Œæœ‰ 10 ä¸ªè¯ï¼Œæ¯ä¸ªè¯çš„ Key å‘é‡æ˜¯ 300 ç»´</span><br><span class="line">key &#x3D; torch.rand(10,64,300)</span><br><span class="line"># batch_size ä¸º 64ï¼Œæœ‰ 10 ä¸ªè¯ï¼Œæ¯ä¸ªè¯çš„ Value å‘é‡æ˜¯ 300 ç»´</span><br><span class="line">value&#x3D; torch.rand(10,64,300)</span><br><span class="line"></span><br><span class="line">embed_dim &#x3D; 299</span><br><span class="line">num_heads &#x3D; 1</span><br><span class="line"># è¾“å‡ºæ˜¯ (attn_output, attn_output_weights)</span><br><span class="line">multihead_attn &#x3D; nn.MultiheadAttention(embed_dim, num_heads)</span><br><span class="line">attn_output &#x3D; multihead_attn(query, key, value)[0]</span><br><span class="line"># output: torch.Size([12, 64, 300])</span><br><span class="line"># batch_size ä¸º 64ï¼Œæœ‰ 12 ä¸ªè¯ï¼Œæ¯ä¸ªè¯çš„å‘é‡æ˜¯ 300 ç»´</span><br><span class="line">print(attn_output.shape)</span><br></pre></td></tr></table></figure>

<h3 id="æ‰‹åŠ¨å®ç°è®¡ç®—-Attention"><a href="#æ‰‹åŠ¨å®ç°è®¡ç®—-Attention" class="headerlink" title="æ‰‹åŠ¨å®ç°è®¡ç®— Attention"></a>æ‰‹åŠ¨å®ç°è®¡ç®— Attention</h3><p>åœ¨ PyTorch æä¾›çš„ MultiheadAttention  ä¸­ï¼Œç¬¬ 1 ç»´æ˜¯å¥å­é•¿åº¦ï¼Œç¬¬ 2 ç»´æ˜¯ batch sizeã€‚è¿™é‡Œæˆ‘ä»¬çš„ä»£ç å®ç°ä¸­ï¼Œç¬¬ 1 ç»´æ˜¯ batch sizeï¼Œç¬¬ 2 ç»´æ˜¯å¥å­é•¿åº¦ã€‚ä»£ç é‡Œä¹ŸåŒ…æ‹¬ï¼šå¦‚ä½•ç”¨çŸ©é˜µå®ç°å¤šç»„æ³¨æ„åŠ›çš„å¹¶è¡Œè®¡ç®—ã€‚ä»£ç ä¸­å·²ç»æœ‰è¯¦ç»†æ³¨é‡Šå’Œè¯´æ˜ã€‚</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br></pre></td><td class="code"><pre><span class="line">class MultiheadAttention(nn.Module):</span><br><span class="line">    # n_headsï¼šå¤šå¤´æ³¨æ„åŠ›çš„æ•°é‡</span><br><span class="line">    # hid_dimï¼šæ¯ä¸ªè¯è¾“å‡ºçš„å‘é‡ç»´åº¦</span><br><span class="line">    def __init__(self, hid_dim, n_heads, dropout):</span><br><span class="line">        super(MultiheadAttention, self).__init__()</span><br><span class="line">        self.hid_dim &#x3D; hid_dim</span><br><span class="line">        self.n_heads &#x3D; n_heads</span><br><span class="line"></span><br><span class="line">        # å¼ºåˆ¶ hid_dim å¿…é¡»æ•´é™¤ h</span><br><span class="line">        assert hid_dim % n_heads &#x3D;&#x3D; 0</span><br><span class="line">        # å®šä¹‰ W_q çŸ©é˜µ</span><br><span class="line">        self.w_q &#x3D; nn.Linear(hid_dim, hid_dim)</span><br><span class="line">        # å®šä¹‰ W_k çŸ©é˜µ</span><br><span class="line">        self.w_k &#x3D; nn.Linear(hid_dim, hid_dim)</span><br><span class="line">        # å®šä¹‰ W_v çŸ©é˜µ</span><br><span class="line">        self.w_v &#x3D; nn.Linear(hid_dim, hid_dim)</span><br><span class="line">        self.fc &#x3D; nn.Linear(hid_dim, hid_dim)</span><br><span class="line">        self.do &#x3D; nn.Dropout(dropout)</span><br><span class="line">        # ç¼©æ”¾</span><br><span class="line">        self.scale &#x3D; torch.sqrt(torch.FloatTensor([hid_dim &#x2F;&#x2F; n_heads]))</span><br><span class="line"></span><br><span class="line">    def forward(self, query, key, value, mask&#x3D;None):</span><br><span class="line">        # K: [64,10,300], batch_size ä¸º 64ï¼Œæœ‰ 12 ä¸ªè¯ï¼Œæ¯ä¸ªè¯çš„ Query å‘é‡æ˜¯ 300 ç»´</span><br><span class="line">        # V: [64,10,300], batch_size ä¸º 64ï¼Œæœ‰ 10 ä¸ªè¯ï¼Œæ¯ä¸ªè¯çš„ Query å‘é‡æ˜¯ 300 ç»´</span><br><span class="line">        # Q: [64,12,300], batch_size ä¸º 64ï¼Œæœ‰ 10 ä¸ªè¯ï¼Œæ¯ä¸ªè¯çš„ Query å‘é‡æ˜¯ 300 ç»´</span><br><span class="line">        # bszï¼š batch size</span><br><span class="line">        bsz &#x3D; query.shape[0]</span><br><span class="line">        Q &#x3D; self.w_q(query)</span><br><span class="line">        K &#x3D; self.w_k(key)</span><br><span class="line">        V &#x3D; self.w_v(value)</span><br><span class="line">        # è¿™é‡ŒæŠŠ K Q V çŸ©é˜µæ‹†åˆ†ä¸ºå¤šç»„æ³¨æ„åŠ›ï¼Œå˜æˆäº†ä¸€ä¸ª 4 ç»´çš„çŸ©é˜µ</span><br><span class="line">        # æœ€åä¸€ç»´å°±æ˜¯æ˜¯ç”¨ self.hid_dim &#x2F;&#x2F; self.n_heads æ¥å¾—åˆ°çš„ï¼Œè¡¨ç¤ºæ¯ç»„æ³¨æ„åŠ›çš„å‘é‡é•¿åº¦, æ¯ä¸ª head çš„å‘é‡é•¿åº¦æ˜¯ï¼š300&#x2F;6&#x3D;50</span><br><span class="line">        # 64 è¡¨ç¤º batch sizeï¼Œ6 è¡¨ç¤ºæœ‰ 6ç»„æ³¨æ„åŠ›ï¼Œ10 è¡¨ç¤ºæœ‰ 10 è¯ï¼Œ50 è¡¨ç¤ºæ¯ç»„æ³¨æ„åŠ›çš„è¯çš„å‘é‡é•¿åº¦</span><br><span class="line">        # K: [64,10,300] æ‹†åˆ†å¤šç»„æ³¨æ„åŠ› -&gt; [64,10,6,50] è½¬ç½®å¾—åˆ° -&gt; [64,6,10,50]</span><br><span class="line">        # V: [64,10,300] æ‹†åˆ†å¤šç»„æ³¨æ„åŠ› -&gt; [64,10,6,50] è½¬ç½®å¾—åˆ° -&gt; [64,6,10,50]</span><br><span class="line">        # Q: [64,12,300] æ‹†åˆ†å¤šç»„æ³¨æ„åŠ› -&gt; [64,12,6,50] è½¬ç½®å¾—åˆ° -&gt; [64,6,12,50]</span><br><span class="line">        # è½¬ç½®æ˜¯ä¸ºäº†æŠŠæ³¨æ„åŠ›çš„æ•°é‡ 6 æ”¾åˆ°å‰é¢ï¼ŒæŠŠ 10 å’Œ 50 æ”¾åˆ°åé¢ï¼Œæ–¹ä¾¿ä¸‹é¢è®¡ç®—</span><br><span class="line">        Q &#x3D; Q.view(bsz, -1, self.n_heads, self.hid_dim &#x2F;&#x2F;</span><br><span class="line">                   self.n_heads).permute(0, 2, 1, 3)</span><br><span class="line">        K &#x3D; K.view(bsz, -1, self.n_heads, self.hid_dim &#x2F;&#x2F;</span><br><span class="line">                   self.n_heads).permute(0, 2, 1, 3)</span><br><span class="line">        V &#x3D; V.view(bsz, -1, self.n_heads, self.hid_dim &#x2F;&#x2F;</span><br><span class="line">                   self.n_heads).permute(0, 2, 1, 3)</span><br><span class="line"></span><br><span class="line">        # ç¬¬ 1 æ­¥ï¼šQ ä¹˜ä»¥ Kçš„è½¬ç½®ï¼Œé™¤ä»¥scale</span><br><span class="line">        # [64,6,12,50] * [64,6,50,10] &#x3D; [64,6,12,10]</span><br><span class="line">        # attentionï¼š[64,6,12,10]</span><br><span class="line">        attention &#x3D; torch.matmul(Q, K.permute(0, 1, 3, 2)) &#x2F; self.scale</span><br><span class="line"></span><br><span class="line">        # æŠŠ mask ä¸ä¸ºç©ºï¼Œé‚£ä¹ˆå°±æŠŠ mask ä¸º 0 çš„ä½ç½®çš„ attention åˆ†æ•°è®¾ç½®ä¸º -1e10</span><br><span class="line">        if mask isnotNone:</span><br><span class="line">            attention &#x3D; attention.masked_fill(mask &#x3D;&#x3D; 0, -1e10)</span><br><span class="line"></span><br><span class="line">        # ç¬¬ 2 æ­¥ï¼šè®¡ç®—ä¸Šä¸€æ­¥ç»“æœçš„ softmaxï¼Œå†ç»è¿‡ dropoutï¼Œå¾—åˆ° attentionã€‚</span><br><span class="line">        # æ³¨æ„ï¼Œè¿™é‡Œæ˜¯å¯¹æœ€åä¸€ç»´åš softmaxï¼Œä¹Ÿå°±æ˜¯åœ¨è¾“å…¥åºåˆ—çš„ç»´åº¦åš softmax</span><br><span class="line">        # attention: [64,6,12,10]</span><br><span class="line">        attention &#x3D; self.do(torch.softmax(attention, dim&#x3D;-1))</span><br><span class="line"></span><br><span class="line">        # ç¬¬ä¸‰æ­¥ï¼Œattentionç»“æœä¸Vç›¸ä¹˜ï¼Œå¾—åˆ°å¤šå¤´æ³¨æ„åŠ›çš„ç»“æœ</span><br><span class="line">        # [64,6,12,10] * [64,6,10,50] &#x3D; [64,6,12,50]</span><br><span class="line">        # x: [64,6,12,50]</span><br><span class="line">        x &#x3D; torch.matmul(attention, V)</span><br><span class="line"></span><br><span class="line">        # å› ä¸º query æœ‰ 12 ä¸ªè¯ï¼Œæ‰€ä»¥æŠŠ 12 æ”¾åˆ°å‰é¢ï¼ŒæŠŠ 5 å’Œ 60 æ”¾åˆ°åé¢ï¼Œæ–¹ä¾¿ä¸‹é¢æ‹¼æ¥å¤šç»„çš„ç»“æœ</span><br><span class="line">        # x: [64,6,12,50] è½¬ç½®-&gt; [64,12,6,50]</span><br><span class="line">        x &#x3D; x.permute(0, 2, 1, 3).contiguous()</span><br><span class="line">        # è¿™é‡Œçš„çŸ©é˜µè½¬æ¢å°±æ˜¯ï¼šæŠŠå¤šç»„æ³¨æ„åŠ›çš„ç»“æœæ‹¼æ¥èµ·æ¥</span><br><span class="line">        # æœ€ç»ˆç»“æœå°±æ˜¯ [64,12,300]</span><br><span class="line">        # x: [64,12,6,50] -&gt; [64,12,300]</span><br><span class="line">        x &#x3D; x.view(bsz, -1, self.n_heads * (self.hid_dim &#x2F;&#x2F; self.n_heads))</span><br><span class="line">        x &#x3D; self.fc(x)</span><br><span class="line">        return x</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"># batch_size ä¸º 64ï¼Œæœ‰ 12 ä¸ªè¯ï¼Œæ¯ä¸ªè¯çš„ Query å‘é‡æ˜¯ 300 ç»´</span><br><span class="line">query &#x3D; torch.rand(64, 12, 300)</span><br><span class="line"># batch_size ä¸º 64ï¼Œæœ‰ 12 ä¸ªè¯ï¼Œæ¯ä¸ªè¯çš„ Key å‘é‡æ˜¯ 300 ç»´</span><br><span class="line">key &#x3D; torch.rand(64, 10, 300)</span><br><span class="line"># batch_size ä¸º 64ï¼Œæœ‰ 10 ä¸ªè¯ï¼Œæ¯ä¸ªè¯çš„ Value å‘é‡æ˜¯ 300 ç»´</span><br><span class="line">value &#x3D; torch.rand(64, 10, 300)</span><br><span class="line">attention &#x3D; MultiheadAttention(hid_dim&#x3D;300, n_heads&#x3D;6, dropout&#x3D;0.1)</span><br><span class="line">output &#x3D; attention(query, key, value)</span><br><span class="line">## output: torch.Size([64, 12, 300])</span><br><span class="line">print(output.shape)</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<h3 id="å…³é”®ä»£ç "><a href="#å…³é”®ä»£ç " class="headerlink" title="å…³é”®ä»£ç "></a>å…³é”®ä»£ç </h3><p>å…¶ä¸­ç”¨çŸ©é˜µå®ç°å¤šå¤´æ³¨æ„åŠ›çš„å…³é”®ä»£ç å¦‚ä¸‹æ‰€ç¤ºï¼Œ Kã€Qã€V çŸ©é˜µæ‹†åˆ†ä¸ºå¤šç»„æ³¨æ„åŠ›ï¼Œå˜æˆäº†ä¸€ä¸ª 4 ç»´çš„çŸ©é˜µã€‚</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"># è¿™é‡ŒæŠŠ K Q V çŸ©é˜µæ‹†åˆ†ä¸ºå¤šç»„æ³¨æ„åŠ›ï¼Œå˜æˆäº†ä¸€ä¸ª 4 ç»´çš„çŸ©é˜µ</span><br><span class="line">        # æœ€åä¸€ç»´å°±æ˜¯æ˜¯ç”¨ self.hid_dim &#x2F;&#x2F; self.n_heads æ¥å¾—åˆ°çš„ï¼Œè¡¨ç¤ºæ¯ç»„æ³¨æ„åŠ›çš„å‘é‡é•¿åº¦, æ¯ä¸ª head çš„å‘é‡é•¿åº¦æ˜¯ï¼š300&#x2F;6&#x3D;50</span><br><span class="line">        # 64 è¡¨ç¤º batch sizeï¼Œ6 è¡¨ç¤ºæœ‰ 6ç»„æ³¨æ„åŠ›ï¼Œ10 è¡¨ç¤ºæœ‰ 10 ä¸ªè¯ï¼Œ50 è¡¨ç¤ºæ¯ç»„æ³¨æ„åŠ›çš„è¯çš„å‘é‡é•¿åº¦</span><br><span class="line">        # K: [64,10,300] æ‹†åˆ†å¤šç»„æ³¨æ„åŠ› -&gt; [64,10,6,50] è½¬ç½®å¾—åˆ° -&gt; [64,6,10,50]</span><br><span class="line">        # V: [64,10,300] æ‹†åˆ†å¤šç»„æ³¨æ„åŠ› -&gt; [64,10,6,50] è½¬ç½®å¾—åˆ° -&gt; [64,6,10,50]</span><br><span class="line">        # Q: [64,12,300] æ‹†åˆ†å¤šç»„æ³¨æ„åŠ› -&gt; [64,12,6,50] è½¬ç½®å¾—åˆ° -&gt; [64,6,12,50]</span><br><span class="line">        # è½¬ç½®æ˜¯ä¸ºäº†æŠŠæ³¨æ„åŠ›çš„æ•°é‡ 6 æ”¾åˆ°å‰é¢ï¼ŒæŠŠ 10 å’Œ 50 æ”¾åˆ°åé¢ï¼Œæ–¹ä¾¿ä¸‹é¢è®¡ç®—</span><br><span class="line">        Q &#x3D; Q.view(bsz, -1, self.n_heads, self.hid_dim &#x2F;&#x2F;</span><br><span class="line">                   self.n_heads).permute(0, 2, 1, 3)</span><br><span class="line">        K &#x3D; K.view(bsz, -1, self.n_heads, self.hid_dim &#x2F;&#x2F;</span><br><span class="line">                   self.n_heads).permute(0, 2, 1, 3)</span><br><span class="line">        V &#x3D; V.view(bsz, -1, self.n_heads, self.hid_dim &#x2F;&#x2F;</span><br><span class="line">                   self.n_heads).permute(0, 2, 1, 3)</span><br><span class="line">ç»è¿‡ attention è®¡ç®—å¾—åˆ° x çš„å½¢çŠ¶æ˜¯ &#96;[64,12,6,50]&#96;ï¼Œ64 è¡¨ç¤º batch sizeï¼Œ6 è¡¨ç¤ºæœ‰ 6ç»„æ³¨æ„åŠ›ï¼Œ10 è¡¨ç¤ºæœ‰ 10 ä¸ªè¯ï¼Œ50 è¡¨ç¤ºæ¯ç»„æ³¨æ„åŠ›çš„è¯çš„å‘é‡é•¿åº¦ã€‚æŠŠè¿™ä¸ªçŸ©é˜µè½¬æ¢ä¸º &#96;[64,12,300]&#96;çš„çŸ©é˜µï¼Œå°±æ˜¯ç›¸å½“äºæŠŠå¤šç»„æ³¨æ„åŠ›çš„ç»“æœæ‹¼æ¥èµ·æ¥ã€‚</span><br><span class="line">e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e e ee</span><br><span class="line"></span><br><span class="line">è¿™é‡Œçš„çŸ©é˜µè½¬æ¢å°±æ˜¯ï¼šæŠŠå¤šç»„æ³¨æ„åŠ›çš„ç»“æœæ‹¼æ¥èµ·æ¥ï¼Œæœ€ç»ˆç»“æœå°±æ˜¯ [64,12,300]ï¼Œx: [64,12,6,50] -&gt; [64,12,300]</span><br><span class="line">x &#x3D; x.view(bsz, -1, self.n_heads * (self.hid_dim &#x2F;&#x2F; self.n_heads))</span><br></pre></td></tr></table></figure>

<h2 id="ä½¿ç”¨ä½ç½®ç¼–ç æ¥è¡¨ç¤ºåºåˆ—çš„é¡ºåº"><a href="#ä½¿ç”¨ä½ç½®ç¼–ç æ¥è¡¨ç¤ºåºåˆ—çš„é¡ºåº" class="headerlink" title="ä½¿ç”¨ä½ç½®ç¼–ç æ¥è¡¨ç¤ºåºåˆ—çš„é¡ºåº"></a>ä½¿ç”¨ä½ç½®ç¼–ç æ¥è¡¨ç¤ºåºåˆ—çš„é¡ºåº</h2><p>åˆ°ç›®å‰ä¸ºæ­¢ï¼Œæˆ‘ä»¬é˜è¿°çš„æ¨¡å‹ä¸­ç¼ºå¤±äº†ä¸€ä¸ªä¸œè¥¿ï¼Œé‚£å°±æ˜¯è¡¨ç¤ºåºåˆ—ä¸­å•è¯é¡ºåºçš„æ–¹æ³•ã€‚</p>
<p>ä¸ºäº†è§£å†³è¿™ä¸ªé—®é¢˜ï¼ŒTransformer æ¨¡å‹å¯¹æ¯ä¸ªè¾“å…¥çš„å‘é‡éƒ½æ·»åŠ äº†ä¸€ä¸ªå‘é‡ã€‚è¿™äº›å‘é‡éµå¾ªæ¨¡å‹å­¦ä¹ åˆ°çš„ç‰¹å®šæ¨¡å¼ï¼Œæœ‰åŠ©äºç¡®å®šæ¯ä¸ªå•è¯çš„ä½ç½®ï¼Œæˆ–è€…å¥å­ä¸­ä¸åŒå•è¯ä¹‹é—´çš„è·ç¦»ã€‚è¿™ç§åšæ³•èƒŒåçš„ç›´è§‰æ˜¯ï¼šå°†è¿™äº›è¡¨ç¤ºä½ç½®çš„å‘é‡æ·»åŠ åˆ°è¯å‘é‡ä¸­ï¼Œå¾—åˆ°äº†æ–°çš„å‘é‡ï¼Œè¿™äº›æ–°å‘é‡æ˜ å°„åˆ° Q/K/Vï¼Œç„¶åè®¡ç®—ç‚¹ç§¯å¾—åˆ° attention æ—¶ï¼Œå¯ä»¥æä¾›æœ‰æ„ä¹‰çš„ä¿¡æ¯ã€‚</p>
<p><img src="2-position.png" alt="ä½ç½®ç¼–ç "><br>å›¾ï¼šä½ç½®ç¼–ç </p>
<p>ä¸ºäº†è®©æ¨¡å‹äº†è§£å•è¯çš„é¡ºåºï¼Œæˆ‘ä»¬æ·»åŠ äº†å¸¦æœ‰ä½ç½®ç¼–ç çš„å‘é‡â€“è¿™äº›å‘é‡çš„å€¼éµå¾ªç‰¹å®šçš„æ¨¡å¼ã€‚ å¦‚æœæˆ‘ä»¬å‡è®¾è¯å‘é‡çš„ç»´åº¦æ˜¯ 4ï¼Œé‚£ä¹ˆå¸¦æœ‰ä½ç½®ç¼–ç çš„å‘é‡å¯èƒ½å¦‚ä¸‹æ‰€ç¤ºï¼š</p>
<p><img src="2-position2.png" alt="ä½ç½®ç¼–ç "><br>å›¾ï¼šä½ç½®ç¼–ç </p>
<p>ä½ç½®ç¼–ç çš„å¯è§†åŒ–åˆ†æï¼š</p>
<p>åœ¨ä¸‹å›¾ä¸­ï¼Œæ¯ä¸€è¡Œè¡¨ç¤ºä¸€ä¸ªå¸¦æœ‰ä½ç½®ç¼–ç çš„å‘é‡ã€‚æ‰€ä»¥ï¼Œç¬¬ä¸€è¡Œå¯¹åº”äºåºåˆ—ä¸­ç¬¬ä¸€ä¸ªå•è¯çš„ä½ç½®ç¼–ç å‘é‡ã€‚æ¯ä¸€è¡Œéƒ½åŒ…å« 512 ä¸ªå€¼ï¼Œæ¯ä¸ªå€¼çš„èŒƒå›´åœ¨ -1 å’Œ 1 ä¹‹é—´ã€‚æˆ‘å¯¹è¿™äº›å‘é‡è¿›è¡Œäº†æ¶‚è‰²å¯è§†åŒ–ï¼Œä½ å¯ä»¥ä»ä¸­çœ‹åˆ°å‘é‡éµå¾ªçš„æ¨¡å¼ã€‚</p>
<p><img src="2-position3.png" alt="ä½ç½®ç¼–ç å›¾ç¤º"><br>å›¾ï¼šä½ç½®ç¼–ç å›¾ç¤º</p>
<p>è¿™æ˜¯ä¸€ä¸ªçœŸå®çš„ä¾‹å­ï¼ŒåŒ…å«äº† 20 ä¸ªè¯ï¼Œæ¯ä¸ªè¯å‘é‡çš„ç»´åº¦æ˜¯ 512ã€‚ä½ å¯ä»¥çœ‹åˆ°ï¼Œå®ƒçœ‹èµ·æ¥åƒä»ä¸­é—´ä¸€åˆ†ä¸ºäºŒã€‚è¿™æ˜¯å› ä¸ºå·¦åŠéƒ¨åˆ†çš„å€¼æ˜¯ç”±<strong>sine</strong>å‡½æ•°äº§ç”Ÿçš„ï¼Œè€Œå³åŠéƒ¨åˆ†çš„å€¼æ˜¯ç”±<strong>cosine</strong>å‡½æ•°äº§ç”Ÿçš„ï¼Œç„¶åå°†ä»–ä»¬æ‹¼æ¥èµ·æ¥ï¼Œå¾—åˆ°æ¯ä¸ªä½ç½®ç¼–ç å‘é‡ã€‚</p>
<p>ä½ å¯ä»¥åœ¨get_timing_signal_1d()ä¸ŠæŸ¥çœ‹ç”Ÿæˆä½ç½®ç¼–ç çš„ä»£ç ã€‚è¿™ç§æ–¹æ³•æ¥è‡ªäº<code>Tranformer2Transformer</code> çš„å®ç°ã€‚</p>
<p>è€Œè®ºæ–‡ä¸­çš„æ–¹æ³•å’Œä¸Šé¢å›¾ä¸­çš„ç¨æœ‰ä¸åŒï¼Œå®ƒä¸æ˜¯ç›´æ¥æ‹¼æ¥ä¸¤ä¸ªå‘é‡ï¼Œè€Œæ˜¯å°†ä¸¤ä¸ªå‘é‡äº¤ç»‡åœ¨ä¸€èµ·ã€‚å¦‚ä¸‹å›¾æ‰€ç¤ºã€‚</p>
<p><img src="2-positin4.png" alt="ä½ç½®ç¼–ç äº¤ç»‡"><br>å›¾ï¼šä½ç½®ç¼–ç äº¤ç»‡</p>
<p>æ­¤ä¸ºç”Ÿæˆä½ç½®ç¼–ç çš„å…¬å¼ï¼Œåœ¨ Transformer è®ºæ–‡çš„ 3.5 èŠ‚ä¸­æœ‰è¯¦ç»†è¯´æ˜ã€‚</p>
<p>è¿™ä¸æ˜¯å”¯ä¸€ä¸€ç§ç”Ÿæˆä½ç½®ç¼–ç çš„æ–¹æ³•ã€‚ä½†è¿™ç§æ–¹æ³•çš„ä¼˜ç‚¹æ˜¯ï¼šå¯ä»¥æ‰©å±•åˆ°æœªçŸ¥çš„åºåˆ—é•¿åº¦ã€‚ä¾‹å¦‚ï¼šå½“æˆ‘ä»¬çš„æ¨¡å‹éœ€è¦ç¿»è¯‘ä¸€ä¸ªå¥å­ï¼Œè€Œè¿™ä¸ªå¥å­çš„é•¿åº¦å¤§äºè®­ç»ƒé›†ä¸­æ‰€æœ‰å¥å­çš„é•¿åº¦ï¼Œè¿™æ—¶ï¼Œè¿™ç§ä½ç½®ç¼–ç çš„æ–¹æ³•ä¹Ÿå¯ä»¥ç”Ÿæˆä¸€æ ·é•¿çš„ä½ç½®ç¼–ç å‘é‡ã€‚</p>
<h3 id="æ®‹å·®è¿æ¥"><a href="#æ®‹å·®è¿æ¥" class="headerlink" title="æ®‹å·®è¿æ¥"></a>æ®‹å·®è¿æ¥</h3><p>åœ¨æˆ‘ä»¬ç»§ç»­è®²è§£ä¹‹å‰ï¼Œç¼–ç å™¨ç»“æ„ä¸­æœ‰ä¸€ä¸ªéœ€è¦æ³¨æ„çš„ç»†èŠ‚æ˜¯ï¼šç¼–ç å™¨çš„æ¯ä¸ªå­å±‚ï¼ˆSelf Attention å±‚å’Œ FFNNï¼‰éƒ½æœ‰ä¸€ä¸ªæ®‹å·®è¿æ¥å’Œå±‚æ ‡å‡†åŒ–ï¼ˆlayer-normalizationï¼‰ã€‚</p>
<p><img src="2-resnet.png" alt="æ®‹å·®è¿æ¥"><br>å›¾ï¼šæ®‹å·®è¿æ¥</p>
<p>å°† Self-Attention å±‚çš„å±‚æ ‡å‡†åŒ–ï¼ˆlayer-normalizationï¼‰å’Œå‘é‡éƒ½è¿›è¡Œå¯è§†åŒ–ï¼Œå¦‚ä¸‹æ‰€ç¤ºï¼š</p>
<p><img src="2-lyn.png" alt="æ ‡å‡†åŒ–"><br>å›¾ï¼šæ ‡å‡†åŒ–</p>
<p>åœ¨è§£ç å™¨çš„å­å±‚é‡Œé¢ä¹Ÿæœ‰å±‚æ ‡å‡†åŒ–ï¼ˆlayer-normalizationï¼‰ã€‚å‡è®¾ä¸€ä¸ª Transformer æ˜¯ç”± 2 å±‚ç¼–ç å™¨å’Œä¸¤å±‚è§£ç å™¨ç»„æˆçš„ï¼Œå¦‚ä¸‹å›¾æ‰€ç¤ºã€‚</p>
<p><img src="2-2layer.png" alt="2å±‚ç¤ºæ„å›¾"><br>å›¾ï¼š2å±‚ç¤ºæ„å›¾</p>
<h3 id="Decoderï¼ˆè§£ç å™¨ï¼‰"><a href="#Decoderï¼ˆè§£ç å™¨ï¼‰" class="headerlink" title="Decoderï¼ˆè§£ç å™¨ï¼‰"></a>Decoderï¼ˆè§£ç å™¨ï¼‰</h3><p>ç°åœ¨æˆ‘ä»¬å·²ç»ä»‹ç»äº†è§£ç å™¨ä¸­çš„å¤§éƒ¨åˆ†æ¦‚å¿µï¼Œæˆ‘ä»¬ä¹ŸåŸºæœ¬çŸ¥é“äº†è§£ç å™¨çš„åŸç†ã€‚ç°åœ¨è®©æˆ‘ä»¬æ¥çœ‹ä¸‹ï¼Œ ç¼–ç å™¨å’Œè§£ç å™¨æ˜¯å¦‚ä½•ååŒå·¥ä½œçš„ã€‚</p>
<p>ä¸Šé¢è¯´äº†ï¼Œç¼–ç å™¨ä¸€èˆ¬æœ‰å¤šå±‚ï¼Œç¬¬ä¸€ä¸ªç¼–ç å™¨çš„è¾“å…¥æ˜¯ä¸€ä¸ªåºåˆ—ï¼Œæœ€åä¸€ä¸ªç¼–ç å™¨è¾“å‡ºæ˜¯ä¸€ç»„æ³¨æ„åŠ›å‘é‡ K å’Œ Vã€‚è¿™äº›æ³¨æ„åŠ›å‘é‡å°†ä¼šè¾“å…¥åˆ°æ¯ä¸ªè§£ç å™¨çš„Encoder-Decoder Attentionå±‚ï¼Œè¿™æœ‰åŠ©äºè§£ç å™¨æŠŠæ³¨æ„åŠ›é›†ä¸­ä¸­è¾“å…¥åºåˆ—çš„åˆé€‚ä½ç½®ã€‚</p>
<p>åœ¨å®Œæˆäº†ç¼–ç ï¼ˆencodingï¼‰é˜¶æ®µä¹‹åï¼Œæˆ‘ä»¬å¼€å§‹è§£ç ï¼ˆdecodingï¼‰é˜¶æ®µã€‚è§£ç ï¼ˆdecoding ï¼‰é˜¶æ®µçš„æ¯ä¸€ä¸ªæ—¶é—´æ­¥éƒ½è¾“å‡ºä¸€ä¸ªç¿»è¯‘åçš„å•è¯ï¼ˆè¿™é‡Œçš„ä¾‹å­æ˜¯è‹±è¯­ç¿»è¯‘ï¼‰ã€‚</p>
<p>æ¥ä¸‹æ¥ä¼šé‡å¤è¿™ä¸ªè¿‡ç¨‹ï¼Œç›´åˆ°è¾“å‡ºä¸€ä¸ªç»“æŸç¬¦ï¼ŒTransformer å°±å®Œæˆäº†æ‰€æœ‰çš„è¾“å‡ºã€‚æ¯ä¸€æ­¥çš„è¾“å‡ºéƒ½ä¼šåœ¨ä¸‹ä¸€ä¸ªæ—¶é—´æ­¥è¾“å…¥åˆ°ä¸‹é¢çš„ç¬¬ä¸€ä¸ªè§£ç å™¨ã€‚Decoder å°±åƒ Encoder é‚£æ ·ï¼Œä»ä¸‹å¾€ä¸Šä¸€å±‚ä¸€å±‚åœ°è¾“å‡ºç»“æœã€‚æ­£å¯¹å¦‚ç¼–ç å™¨çš„è¾“å…¥æ‰€åšçš„å¤„ç†ï¼Œæˆ‘ä»¬æŠŠè§£ç å™¨çš„è¾“å…¥å‘é‡ï¼Œä¹ŸåŠ ä¸Šä½ç½®ç¼–ç å‘é‡ï¼Œæ¥æŒ‡ç¤ºæ¯ä¸ªè¯çš„ä½ç½®ã€‚</p>
<p><img src="2-decoder.gif" alt="decoderåŠ¨æ€å›¾"><br>åŠ¨æ€å›¾ï¼šdecoderåŠ¨æ€å›¾</p>
<p>è§£ç å™¨ä¸­çš„ Self Attention å±‚ï¼Œå’Œç¼–ç å™¨ä¸­çš„ Self Attention å±‚ä¸å¤ªä¸€æ ·ï¼š<strong>åœ¨è§£ç å™¨é‡Œï¼ŒSelf Attention å±‚åªå…è®¸å…³æ³¨åˆ°è¾“å‡ºåºåˆ—ä¸­æ—©äºå½“å‰ä½ç½®ä¹‹å‰çš„å•è¯</strong>ã€‚å…·ä½“åšæ³•æ˜¯ï¼šåœ¨ Self Attention åˆ†æ•°ç»è¿‡ Softmax å±‚ä¹‹å‰ï¼Œå±è”½å½“å‰ä½ç½®ä¹‹åçš„é‚£äº›ä½ç½®ã€‚</p>
<p>Encoder-Decoder Attentionå±‚çš„åŸç†å’Œå¤šå¤´æ³¨æ„åŠ›ï¼ˆmultiheaded Self Attentionï¼‰æœºåˆ¶ç±»ä¼¼ï¼Œ<strong>ä¸åŒä¹‹å¤„</strong>æ˜¯ï¼šEncoder-Decoder Attentionå±‚æ˜¯ä½¿ç”¨å‰ä¸€å±‚çš„è¾“å‡ºæ¥æ„é€  Query çŸ©é˜µï¼Œè€Œ Key çŸ©é˜µå’Œ Value çŸ©é˜µæ¥è‡ªäºè§£ç å™¨æœ€ç»ˆçš„è¾“å‡ºã€‚</p>
<h3 id="æœ€åçš„çº¿æ€§å±‚å’Œ-Softmax-å±‚"><a href="#æœ€åçš„çº¿æ€§å±‚å’Œ-Softmax-å±‚" class="headerlink" title="æœ€åçš„çº¿æ€§å±‚å’Œ Softmax å±‚"></a>æœ€åçš„çº¿æ€§å±‚å’Œ Softmax å±‚</h3><p>Decoder æœ€ç»ˆçš„è¾“å‡ºæ˜¯ä¸€ä¸ªå‘é‡ï¼Œå…¶ä¸­æ¯ä¸ªå…ƒç´ æ˜¯æµ®ç‚¹æ•°ã€‚æˆ‘ä»¬æ€ä¹ˆæŠŠè¿™ä¸ªå‘é‡è½¬æ¢ä¸ºå•è¯å‘¢ï¼Ÿè¿™æ˜¯ç”± Softmax å±‚åé¢çš„çº¿æ€§å±‚æ¥å®Œæˆçš„ã€‚</p>
<p><strong>çº¿æ€§å±‚å°±æ˜¯ä¸€ä¸ªæ™®é€šçš„å…¨è¿æ¥ç¥ç»ç½‘ç»œï¼Œå¯ä»¥æŠŠè§£ç å™¨è¾“å‡ºçš„å‘é‡ï¼Œæ˜ å°„åˆ°ä¸€ä¸ªæ›´é•¿çš„å‘é‡ï¼Œè¿™ä¸ªå‘é‡ç§°ä¸º logits å‘é‡</strong>ã€‚</p>
<p><strong>Softmax å±‚ä¼šæŠŠè¿™äº›åˆ†æ•°è½¬æ¢ä¸ºæ¦‚ç‡ï¼ˆæŠŠæ‰€æœ‰çš„åˆ†æ•°è½¬æ¢ä¸ºæ­£æ•°ï¼Œå¹¶ä¸”åŠ èµ·æ¥ç­‰äº 1ï¼‰ã€‚ç„¶åé€‰æ‹©æœ€é«˜æ¦‚ç‡çš„é‚£ä¸ªæ•°å­—å¯¹åº”çš„è¯ï¼Œå°±æ˜¯è¿™ä¸ªæ—¶é—´æ­¥çš„è¾“å‡ºå•è¯</strong>ã€‚</p>
<p><img src="2-linear.png" alt="çº¿æ€§å±‚"><br>å›¾ï¼šçº¿æ€§å±‚</p>
<p>åœ¨ä¸Šå›¾ä¸­ï¼Œæœ€ä¸‹é¢çš„å‘é‡ï¼Œå°±æ˜¯ç¼–ç å™¨çš„è¾“å‡ºï¼Œè¿™ä¸ªå‘é‡è¾“å…¥åˆ°çº¿æ€§å±‚å’Œ Softmax å±‚ï¼Œæœ€ç»ˆå¾—åˆ°è¾“å‡ºçš„è¯ã€‚</p>
<h3 id="Transformer-çš„è®­ç»ƒè¿‡ç¨‹"><a href="#Transformer-çš„è®­ç»ƒè¿‡ç¨‹" class="headerlink" title="Transformer çš„è®­ç»ƒè¿‡ç¨‹"></a>Transformer çš„è®­ç»ƒè¿‡ç¨‹</h3><p>ç°åœ¨æˆ‘ä»¬å·²ç»äº†è§£äº† Transformer çš„å‰å‘ä¼ æ’­è¿‡ç¨‹ï¼Œä¸‹é¢è®²è®² Transformer çš„è®­ç»ƒè¿‡ç¨‹ï¼Œè¿™ä¹Ÿæ˜¯éå¸¸æœ‰ç”¨çš„çŸ¥è¯†ã€‚</p>
<p>åœ¨è®­ç»ƒè¿‡ç¨‹ä¸­ï¼Œæ¨¡å‹ä¼šç»è¿‡ä¸Šé¢è®²çš„æ‰€æœ‰å‰å‘ä¼ æ’­çš„æ­¥éª¤ã€‚ä½†æ˜¯ï¼Œå½“æˆ‘ä»¬åœ¨ä¸€ä¸ªæ ‡æ³¨å¥½çš„æ•°æ®é›†ä¸Šè®­ç»ƒè¿™ä¸ªæ¨¡å‹çš„æ—¶å€™ï¼Œæˆ‘ä»¬å¯ä»¥å¯¹æ¯”æ¨¡å‹çš„è¾“å‡ºå’ŒçœŸå®çš„æ ‡ç­¾ã€‚</p>
<p>ä¸ºäº†å¯è§†åŒ–è¿™ä¸ªå¯¹æ¯”ï¼Œè®©æˆ‘ä»¬å‡è®¾è¾“å‡ºè¯æ±‡è¡¨åªåŒ…å« 6 ä¸ªå•è¯ï¼ˆâ€œaâ€, â€œamâ€, â€œiâ€, â€œthanksâ€, â€œstudentâ€, and â€œ<eos>â€ï¼ˆâ€œ<eos>â€è¡¨ç¤ºå¥å­æœ«å°¾ï¼‰ï¼‰ã€‚</p>
<p><img src="2-6words.webp" alt="6ä¸ªè¯"><br>å›¾ï¼š6ä¸ªè¯</p>
<p>æˆ‘ä»¬æ¨¡å‹çš„è¾“å‡ºè¯æ±‡è¡¨ï¼Œæ˜¯åœ¨è®­ç»ƒä¹‹å‰çš„æ•°æ®é¢„å¤„ç†é˜¶æ®µæ„é€ çš„ã€‚å½“æˆ‘ä»¬ç¡®å®šäº†è¾“å‡ºè¯æ±‡è¡¨ï¼Œæˆ‘ä»¬å¯ä»¥ç”¨å‘é‡æ¥è¡¨ç¤ºè¯æ±‡è¡¨ä¸­çš„æ¯ä¸ªå•è¯ã€‚è¿™ä¸ªè¡¨ç¤ºæ–¹æ³•ä¹Ÿç§°ä¸º  one-hot encodingã€‚ä¾‹å¦‚ï¼Œæˆ‘ä»¬å¯ä»¥æŠŠå•è¯ â€œamâ€ ç”¨ä¸‹é¢çš„å‘é‡æ¥è¡¨ç¤ºï¼š</p>
<p><img src="2-am.webp" alt="amå‘é‡"><br>å›¾ï¼šamå‘é‡</p>
<p>ä»‹ç»äº†è®­ç»ƒè¿‡ç¨‹ï¼Œæˆ‘ä»¬æ¥ç€è®¨è®ºæ¨¡å‹çš„æŸå¤±å‡½æ•°ï¼Œè¿™æˆ‘ä»¬åœ¨è®­ç»ƒæ—¶éœ€è¦ä¼˜åŒ–çš„ç›®æ ‡ï¼Œé€šè¿‡ä¼˜åŒ–è¿™ä¸ªç›®æ ‡æ¥å¾—åˆ°ä¸€ä¸ªè®­ç»ƒå¥½çš„ã€éå¸¸ç²¾ç¡®çš„æ¨¡å‹ã€‚</p>
<h3 id="æŸå¤±å‡½æ•°"><a href="#æŸå¤±å‡½æ•°" class="headerlink" title="æŸå¤±å‡½æ•°"></a>æŸå¤±å‡½æ•°</h3><p>ç”¨ä¸€ä¸ªç®€å•çš„ä¾‹å­æ¥è¯´æ˜è®­ç»ƒè¿‡ç¨‹ï¼Œæ¯”å¦‚ï¼šæŠŠâ€œmerciâ€ç¿»è¯‘ä¸ºâ€œthanksâ€ã€‚</p>
<p>è¿™æ„å‘³ç€æˆ‘ä»¬å¸Œæœ›æ¨¡å‹æœ€ç»ˆè¾“å‡ºçš„æ¦‚ç‡åˆ†å¸ƒï¼Œä¼šæŒ‡å‘å•è¯ â€thanksâ€œï¼ˆåœ¨â€œthanksâ€è¿™ä¸ªè¯çš„æ¦‚ç‡æœ€é«˜ï¼‰ã€‚ä½†æ¨¡å‹è¿˜æ²¡è®­ç»ƒå¥½ï¼Œå®ƒè¾“å‡ºçš„æ¦‚ç‡åˆ†å¸ƒå¯èƒ½å’Œæˆ‘ä»¬å¸Œæœ›çš„æ¦‚ç‡åˆ†å¸ƒç›¸å·®ç”šè¿œã€‚</p>
<p><img src="2-loss.webp" alt="æ¦‚ç‡åˆ†å¸ƒ"><br>å›¾ï¼šæ¦‚ç‡åˆ†å¸ƒ</p>
<p>ç”±äºæ¨¡å‹çš„å‚æ•°éƒ½æ˜¯éšæœºåˆå§‹åŒ–çš„ã€‚æ¨¡å‹åœ¨æ¯ä¸ªè¯è¾“å‡ºçš„æ¦‚ç‡éƒ½æ˜¯éšæœºçš„ã€‚æˆ‘ä»¬å¯ä»¥æŠŠè¿™ä¸ªæ¦‚ç‡å’Œæ­£ç¡®çš„è¾“å‡ºæ¦‚ç‡åšå¯¹æ¯”ï¼Œç„¶åä½¿ç”¨åå‘ä¼ æ’­æ¥è°ƒæ•´æ¨¡å‹çš„æƒé‡ï¼Œä½¿å¾—è¾“å‡ºçš„æ¦‚ç‡åˆ†å¸ƒæ›´åŠ æ¥è¿‘æ­£ç¡®(pq)è¾“å‡ºã€‚</p>
<p>é‚£æˆ‘ä»¬è¦æ€ä¹ˆæ¯”è¾ƒä¸¤ä¸ªæ¦‚ç‡åˆ†å¸ƒå‘¢ï¼Ÿæˆ‘ä»¬å¯ä»¥ç®€å•åœ°ç”¨ä¸€ä¸ªæ¦‚ç‡åˆ†å¸ƒå‡å»å¦ä¸€ä¸ªæ¦‚ç‡åˆ†å¸ƒã€‚å…³äºæ›´å¤šç»†èŠ‚ï¼Œä½ å¯ä»¥æŸ¥çœ‹<strong>äº¤å‰ç†µ</strong>(cross-entropy)]å’Œ<strong>KL æ•£åº¦</strong>(Kullbackâ€“Leibler divergence)çš„ç›¸å…³æ¦‚å¿µã€‚</p>
<p>ä½†ä¸Šé¢çš„ä¾‹å­æ˜¯ç»è¿‡ç®€åŒ–çš„ï¼Œå› ä¸ºæˆ‘ä»¬çš„å¥å­åªæœ‰ä¸€ä¸ªå•è¯ã€‚åœ¨å®é™…ä¸­ï¼Œæˆ‘ä»¬ä½¿ç”¨çš„å¥å­ä¸åªæœ‰ä¸€ä¸ªå•è¯ã€‚ä¾‹å¦‚â€“è¾“å…¥æ˜¯ï¼šâ€œje suis Ã©tudiantâ€ ï¼Œè¾“å‡ºæ˜¯ï¼šâ€œi am a studentâ€ã€‚è¿™æ„å‘³ç€ï¼Œæˆ‘ä»¬çš„æ¨¡å‹éœ€è¦è¾“å‡ºå¤šä¸ªæ¦‚ç‡åˆ†å¸ƒï¼Œæ»¡è¶³å¦‚ä¸‹æ¡ä»¶ï¼š</p>
<ul>
<li>æ¯ä¸ªæ¦‚ç‡åˆ†å¸ƒéƒ½æ˜¯ä¸€ä¸ªå‘é‡ï¼Œé•¿åº¦æ˜¯ vocab_sizeï¼ˆæˆ‘ä»¬çš„ä¾‹å­ä¸­ï¼Œå‘é‡é•¿åº¦æ˜¯ 6ï¼Œä½†å®é™…ä¸­æ›´å¯èƒ½æ˜¯ 30000 æˆ–è€… 50000ï¼‰</li>
<li>ç¬¬ä¸€ä¸ªæ¦‚ç‡åˆ†å¸ƒä¸­ï¼Œæœ€é«˜æ¦‚ç‡å¯¹åº”çš„å•è¯æ˜¯ â€œiâ€</li>
<li>ç¬¬äºŒä¸ªæ¦‚ç‡åˆ†å¸ƒä¸­ï¼Œæœ€é«˜æ¦‚ç‡å¯¹åº”çš„å•è¯æ˜¯ â€œamâ€</li>
<li>ä»¥æ­¤ç±»æ¨ï¼Œç›´åˆ°ç¬¬ 5 ä¸ªæ¦‚ç‡åˆ†å¸ƒä¸­ï¼Œæœ€é«˜æ¦‚ç‡å¯¹åº”çš„å•è¯æ˜¯ â€œ&lt;eos&gt;(pq)â€ï¼Œè¡¨ç¤ºæ²¡æœ‰ä¸‹ä¸€ä¸ªå•è¯äº†</li>
</ul>
<p><img src="2-target.png" alt="æ¦‚ç‡åˆ†å¸ƒ"><br>å›¾ï¼šæ¦‚ç‡åˆ†å¸ƒ</p>
<p>æˆ‘ä»¬ç”¨ä¾‹å­ä¸­çš„å¥å­è®­ç»ƒæ¨¡å‹ï¼Œå¸Œæœ›äº§ç”Ÿå›¾ä¸­æ‰€ç¤ºçš„æ¦‚ç‡åˆ†å¸ƒ<br>æˆ‘ä»¬çš„æ¨¡å‹åœ¨ä¸€ä¸ªè¶³å¤Ÿå¤§çš„æ•°æ®é›†ä¸Šï¼Œç»è¿‡è¶³å¤Ÿé•¿æ—¶é—´çš„è®­ç»ƒåï¼Œå¸Œæœ›è¾“å‡ºçš„æ¦‚ç‡åˆ†å¸ƒå¦‚ä¸‹å›¾æ‰€ç¤ºï¼š</p>
<p><img src="2-trained.webp" alt="è®­ç»ƒåæ¦‚ç‡åˆ†å¸ƒ"><br>å›¾ï¼šè®­ç»ƒåæ¦‚ç‡åˆ†å¸ƒ</p>
<p>å¸Œæœ›ç»è¿‡è®­ç»ƒï¼Œæ¨¡å‹ä¼šè¾“å‡ºæˆ‘ä»¬å¸Œæœ›çš„æ­£ç¡®ç¿»è¯‘ã€‚å½“ç„¶ï¼Œå¦‚æœä½ è¦ç¿»è¯‘çš„å¥å­æ˜¯è®­ç»ƒé›†ä¸­çš„ä¸€éƒ¨åˆ†ï¼Œé‚£è¾“å‡ºçš„ç»“æœå¹¶ä¸èƒ½è¯´æ˜ä»€ä¹ˆã€‚æˆ‘ä»¬å¸Œæœ›çš„æ˜¯æ¨¡å‹åœ¨æ²¡è§è¿‡çš„å¥å­ä¸Šä¹Ÿèƒ½å¤Ÿå‡†ç¡®ç¿»è¯‘ã€‚éœ€è¦æ³¨æ„çš„æ˜¯ï¼šæ¦‚ç‡åˆ†å¸ƒå‘é‡ä¸­ï¼Œæ¯ä¸ªä½ç½®éƒ½ä¼šæœ‰ä¸€ç‚¹æ¦‚ç‡ï¼Œå³ä½¿è¿™ä¸ªä½ç½®ä¸æ˜¯è¾“å‡ºå¯¹åº”çš„å•è¯â€“è¿™æ˜¯ Softmax ä¸­ä¸€ä¸ªå¾ˆæœ‰ç”¨çš„ç‰¹æ€§ï¼Œæœ‰åŠ©äºå¸®åŠ©è®­ç»ƒè¿‡ç¨‹ã€‚</p>
<p>ç°åœ¨ï¼Œç”±äºæ¨¡å‹æ¯ä¸ªæ—¶é—´æ­¥åªäº§ç”Ÿä¸€ä¸ªè¾“å‡ºï¼Œæˆ‘ä»¬å¯ä»¥è®¤ä¸ºï¼šæ¨¡å‹æ˜¯ä»æ¦‚ç‡åˆ†å¸ƒä¸­é€‰æ‹©æ¦‚ç‡æœ€å¤§çš„è¯ï¼Œå¹¶ä¸”ä¸¢å¼ƒå…¶ä»–è¯ã€‚è¿™ç§æ–¹æ³•å«åš<strong>è´ªå©ªè§£ç </strong>ï¼ˆgreedy decodingï¼‰ã€‚</p>
<p>å¦ä¸€ç§æ–¹æ³•æ˜¯æ¯ä¸ªæ—¶é—´æ­¥ä¿ç•™ä¸¤ä¸ªæœ€é«˜æ¦‚ç‡çš„è¾“å‡ºè¯ï¼Œç„¶ååœ¨ä¸‹ä¸€ä¸ªæ—¶é—´æ­¥ï¼Œé‡å¤æ‰§è¡Œè¿™ä¸ªè¿‡ç¨‹ï¼šå‡è®¾ç¬¬ä¸€ä¸ªä½ç½®æ¦‚ç‡æœ€é«˜çš„ä¸¤ä¸ªè¾“å‡ºçš„è¯æ˜¯â€Iâ€œå’Œâ€aâ€œï¼Œè¿™ä¸¤ä¸ªè¯éƒ½ä¿ç•™ï¼Œç„¶åæ ¹æ®ç¬¬ä¸€ä¸ªè¯è®¡ç®—ç¬¬äºŒä¸ªä½ç½®çš„è¯çš„æ¦‚ç‡åˆ†å¸ƒï¼Œå†å–å‡º 2 ä¸ªæ¦‚ç‡æœ€é«˜çš„è¯ï¼Œå¯¹äºç¬¬äºŒä¸ªä½ç½®å’Œç¬¬ä¸‰ä¸ªä½ç½®ï¼Œæˆ‘ä»¬ä¹Ÿé‡å¤è¿™ä¸ªè¿‡ç¨‹ã€‚è¿™ç§æ–¹æ³•ç§°ä¸º<strong>é›†æŸæœç´¢</strong>(beam search)ï¼Œåœ¨æˆ‘ä»¬çš„ä¾‹å­ä¸­ï¼Œbeam_size çš„å€¼æ˜¯ 2ï¼ˆå«ä¹‰æ˜¯ï¼šåœ¨æ‰€æœ‰æ—¶é—´æ­¥ï¼Œæˆ‘ä»¬ä¿ç•™ä¸¤ä¸ªæœ€é«˜æ¦‚ç‡ï¼‰ï¼Œtop_beams çš„å€¼ä¹Ÿæ˜¯ 2ï¼ˆè¡¨ç¤ºæˆ‘ä»¬æœ€ç»ˆä¼šè¿”å›ä¸¤ä¸ªç¿»è¯‘çš„ç»“æœï¼‰ã€‚beam_size å’Œ top_beams éƒ½æ˜¯ä½ å¯ä»¥åœ¨å®éªŒä¸­å°è¯•çš„è¶…å‚æ•°ã€‚</p>
<h3 id="æ›´è¿›ä¸€æ­¥ç†è§£"><a href="#æ›´è¿›ä¸€æ­¥ç†è§£" class="headerlink" title="æ›´è¿›ä¸€æ­¥ç†è§£"></a>æ›´è¿›ä¸€æ­¥ç†è§£</h3><p>æˆ‘å¸Œæœ›ä¸Šé¢è®²çš„å†…å®¹ï¼Œå¯ä»¥å¸®åŠ©ä½ ç†è§£ Transformer ä¸­çš„ä¸»è¦æ¦‚å¿µã€‚å¦‚æœä½ æƒ³æ›´æ·±ä¸€æ­¥åœ°ç†è§£ï¼Œæˆ‘å»ºè®®ä½ å¯ä»¥å‚è€ƒä¸‹é¢è¿™äº›ï¼š</p>
<ul>
<li>é˜…è¯» Transformer çš„è®ºæ–‡ï¼š<br>ã€ŠAttention Is All You Needã€‹<br>é“¾æ¥åœ°å€ï¼š<a href="https://arxiv.org/abs/1706.03762">https://arxiv.org/abs/1706.03762</a></li>
<li>é˜…è¯»Transformer çš„åšå®¢æ–‡ç« ï¼š<br>ã€ŠTransformer: A Novel Neural Network Architecture for Language Understandingã€‹<br>é“¾æ¥åœ°å€ï¼š<a href="https://ai.googleblog.com/2017/08/transformer-novel-neural-network.html">https://ai.googleblog.com/2017/08/transformer-novel-neural-network.html</a><br>é˜…è¯»ã€ŠTensor2Tensor announcementã€‹</li>
<li>é“¾æ¥åœ°å€ï¼š<a href="https://ai.googleblog.com/2017/06/accelerating-deep-learning-research.html">https://ai.googleblog.com/2017/06/accelerating-deep-learning-research.html</a></li>
<li>è§‚çœ‹è§†é¢‘ ã€Åukasz Kaiserâ€™s talkã€‘æ¥ç†è§£æ¨¡å‹å’Œå…¶ä¸­çš„ç»†èŠ‚<br>é“¾æ¥åœ°å€ï¼š<a href="https://www.youtube.com/watch?v=rBCqOTEfxvg">https://www.youtube.com/watch?v=rBCqOTEfxvg</a><br>è¿è¡Œè¿™ä»½ä»£ç ï¼šã€Jupyter Notebook provided as part of the Tensor2Tensor repoã€‘</li>
<li>é“¾æ¥åœ°å€ï¼š<a href="https://colab.research.google.com/github/tensorflow/tensor2tensor/blob/master/tensor2tensor/notebooks/hello_t2t.ipynb%E3%80%82">https://colab.research.google.com/github/tensorflow/tensor2tensor/blob/master/tensor2tensor/notebooks/hello_t2t.ipynbã€‚</a></li>
<li>æŸ¥çœ‹è¿™ä¸ªé¡¹ç›®ï¼šã€Tensor2Tensor repoã€‘<br>é“¾æ¥åœ°å€ï¼š<a href="https://github.com/tensorflow/tensor2tensor">https://github.com/tensorflow/tensor2tensor</a></li>
</ul>
<h3 id="è‡´è°¢"><a href="#è‡´è°¢" class="headerlink" title="è‡´è°¢"></a>è‡´è°¢</h3><p>ä¸»è¦ç”±å“ˆå°”æ»¨å·¥ä¸šå¤§å­¦å¼ è´¤åŒå­¦ç¿»è¯‘æ’°å†™ï¼Œç”±æœ¬é¡¹ç›®åŒå­¦ç»„ç»‡å’Œæ•´ç†ã€‚æœ€åï¼ŒæœŸå¾…æ‚¨çš„é˜…è¯»åé¦ˆå’Œstarå“¦ï¼Œè°¢è°¢ã€‚</p>
<h3 id="è½¬è½½å¹¶ç¼–è¾‘"><a href="#è½¬è½½å¹¶ç¼–è¾‘" class="headerlink" title="è½¬è½½å¹¶ç¼–è¾‘"></a>è½¬è½½å¹¶ç¼–è¾‘</h3><p>ç«¥èŒ— æ•´ç†ç¬”è®°</p>
<p>ç¼–ç å™¨æ˜¯å¹¶è¡Œçš„ï¼Œä½†æ˜¯è§£ç å™¨å’ŒRNNä¸€æ ·ä¸èƒ½å¹¶è¡Œã€‚</p>
]]></content>
      
        
        <tags>
            
            <tag> DataWhale-NLP-Transformer </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title></title>
      <url>/2021/08/18/Task02%20%E6%B6%88%E6%81%AF%E4%BC%A0%E9%80%92%E5%9B%BE%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/</url>
      <content type="html"><![CDATA[<h1 id="Task02-æ¶ˆæ¯ä¼ é€’å›¾ç¥ç»ç½‘ç»œ"><a href="#Task02-æ¶ˆæ¯ä¼ é€’å›¾ç¥ç»ç½‘ç»œ" class="headerlink" title="Task02 æ¶ˆæ¯ä¼ é€’å›¾ç¥ç»ç½‘ç»œ"></a>Task02 æ¶ˆæ¯ä¼ é€’å›¾ç¥ç»ç½‘ç»œ</h1><h2 id="ç¬”è®°éƒ¨åˆ†"><a href="#ç¬”è®°éƒ¨åˆ†" class="headerlink" title="ç¬”è®°éƒ¨åˆ†"></a>ç¬”è®°éƒ¨åˆ†</h2><ul>
<li><p>æ¶ˆæ¯ä¼ é€’èŒƒå¼</p>
<ul>
<li><p>ç”¨$\mathbf{x}^{(k-1)}<em>i\in\mathbb{R}^F$è¡¨ç¤º$(k-1)$å±‚ä¸­èŠ‚ç‚¹$i$çš„èŠ‚ç‚¹ç‰¹å¾ï¼Œ$\mathbf{e}</em>{j,i} \in \mathbb{R}^D$ è¡¨ç¤ºä»èŠ‚ç‚¹$j$åˆ°èŠ‚ç‚¹$i$çš„è¾¹çš„ç‰¹å¾ï¼Œæ¶ˆæ¯ä¼ é€’å›¾ç¥ç»ç½‘ç»œå¯ä»¥æè¿°ä¸º</p>
</li>
<li><p>$$<br>\mathbf{x}_i^{(k)} = \gamma^{(k)} \left( \mathbf{x}<em>i^{(k-1)}, \square</em>{j \in \mathcal{N}(i)} , \phi^{(k)}\left(\mathbf{x}_i^{(k-1)}, \mathbf{x}<em>j^{(k-1)},\mathbf{e}</em>{j,i}\right) \right),<br>$$</p>
<p><img src="file://C:\Users\qinan\Desktop\team-study\team-learning-nlp\GNN\Markdown%E7%89%88%E6%9C%AC\images\image-20210516110407207.png?lastModify=1624111214" alt="èŠ‚ç‚¹åµŒå…¥ï¼ˆNode Embeddingï¼‰"></p>
<p>å›¾ç‰‡å±•ç¤ºäº†<strong>åŸºäºæ¶ˆæ¯ä¼ é€’èŒƒå¼çš„ç”ŸæˆèŠ‚ç‚¹è¡¨å¾çš„è¿‡ç¨‹</strong>ï¼š</p>
<ol>
<li>åœ¨å›¾çš„æœ€å³ä¾§ï¼ŒBèŠ‚ç‚¹çš„é‚»æ¥èŠ‚ç‚¹ï¼ˆA,Cï¼‰çš„ä¿¡æ¯ä¼ é€’ç»™äº†Bï¼Œç»è¿‡ä¿¡æ¯å˜æ¢å¾—åˆ°äº†Bçš„åµŒå…¥ï¼ŒCã€DèŠ‚ç‚¹åŒã€‚</li>
<li>åœ¨å›¾çš„ä¸­å³ä¾§ï¼ŒAèŠ‚ç‚¹çš„é‚»æ¥èŠ‚ç‚¹ï¼ˆB,C,Dï¼‰çš„ä¹‹å‰å¾—åˆ°çš„èŠ‚ç‚¹åµŒå…¥ä¼ é€’ç»™äº†èŠ‚ç‚¹Aï¼›åœ¨å›¾çš„ä¸­å·¦ä¾§ï¼Œèšåˆå¾—åˆ°çš„ä¿¡æ¯ç»è¿‡ä¿¡æ¯å˜æ¢å¾—åˆ°äº†AèŠ‚ç‚¹æ–°çš„åµŒå…¥ã€‚</li>
<li>é‡å¤å¤šæ¬¡ï¼Œæˆ‘ä»¬å¯ä»¥å¾—åˆ°æ¯ä¸€ä¸ªèŠ‚ç‚¹çš„ç»è¿‡å¤šæ¬¡ä¿¡æ¯å˜æ¢çš„åµŒå…¥ã€‚è¿™æ ·çš„ç»è¿‡å¤šæ¬¡ä¿¡æ¯èšåˆä¸å˜æ¢çš„èŠ‚ç‚¹åµŒå…¥å°±å¯ä»¥ä½œä¸ºèŠ‚ç‚¹çš„è¡¨å¾ï¼Œå¯ä»¥ç”¨äºèŠ‚ç‚¹çš„åˆ†ç±»ã€‚</li>
</ol>
</li>
</ul>
</li>
</ul>
<ul>
<li><p>ç»§æ‰¿<code>MessagePassing</code>ç±»çš„<code>GCNConv</code></p>
<ul>
<li>GCNConvçš„æ•°å­¦å®šä¹‰ä¸º</li>
</ul>
<p>$$<br>\mathbf{x}<em>i^{(k)} = \sum</em>{j \in \mathcal{N}(i) \cup { i }} \frac{1}{\sqrt{\deg(i)} \cdot \sqrt{\deg(j)}} \cdot \left( \mathbf{\Theta} \cdot \mathbf{x}_j^{(k-1)} \right),<br>$$</p>
<ul>
<li><p>å…¶ä¸­ï¼Œç›¸é‚»èŠ‚ç‚¹çš„ç‰¹å¾é¦–å…ˆé€šè¿‡æƒé‡çŸ©é˜µ$\mathbf{\Theta}$è¿›è¡Œè½¬æ¢ï¼Œç„¶åæŒ‰ç«¯ç‚¹çš„åº¦è¿›è¡Œå½’ä¸€åŒ–å¤„ç†ï¼Œæœ€åè¿›è¡ŒåŠ æ€»ã€‚</p>
</li>
<li><p>æ­¥éª¤ç»†åˆ†ï¼š</p>
</li>
</ul>
<ol>
<li>å‘é‚»æ¥çŸ©é˜µæ·»åŠ è‡ªç¯è¾¹ã€‚</li>
<li>çº¿æ€§è½¬æ¢èŠ‚ç‚¹ç‰¹å¾çŸ©é˜µã€‚</li>
<li>è®¡ç®—å½’ä¸€åŒ–ç³»æ•°ã€‚</li>
<li>å½’ä¸€åŒ–$j$ä¸­çš„èŠ‚ç‚¹ç‰¹å¾ã€‚</li>
<li>å°†ç›¸é‚»èŠ‚ç‚¹ç‰¹å¾ç›¸åŠ ï¼ˆâ€æ±‚å’Œ â€œèšåˆï¼‰ã€‚</li>
</ol>
</li>
</ul>
<ul>
<li><p>ä½œä¸š</p>
<ul>
<li><p>MessagePassingçš„è¿è¡Œæµç¨‹ï¼š</p>
<ul>
<li>é€šè¿‡çº¿æ€§å˜æ¢ä»¥åŠåˆ©ç”¨å½’ä¸€åŒ–ç³»æ•°å°†æºèŠ‚ç‚¹å¾€ç›®æ ‡èŠ‚ç‚¹ä¼ é€’ç‰¹å¾</li>
<li>é€šè¿‡å¤šç§æ–¹å¼ï¼ˆmaxã€averageã€sumï¼‰å¯¹ç‰¹å¾è¿›è¡Œèšåˆ</li>
<li>å°†èšåˆåçš„ä¿¡æ¯å†æ¬¡è¿›è¡Œè½¬æ¢</li>
</ul>
</li>
<li><p>ç»§æ‰¿<code>MessagePassing</code>ç±»çš„è§„èŒƒ,å¹¶è¯·ç»§æ‰¿<code>MessagePassing</code>ç±»æ¥è‡ªå®šä¹‰å‡ ä¸ªçš„å›¾ç¥ç»ç½‘ç»œç±»</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">from</span> torch.nn <span class="keyword">import</span> functional <span class="keyword">as</span> F</span><br><span class="line"><span class="keyword">from</span> torch_geometric.nn <span class="keyword">import</span> MessagePassing</span><br><span class="line"><span class="keyword">from</span> torch_geometric.datasets <span class="keyword">import</span> Planetoid</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">MyGNN</span>(<span class="params">MessagePassing</span>):</span></span><br><span class="line">    <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">    .. math::</span></span><br><span class="line"><span class="string">        \mathbf&#123;x&#125;^&#123;\prime&#125;_i = \mathbf&#123;x&#125;_i \cdot \mathbf&#123;\Theta&#125;_1 +</span></span><br><span class="line"><span class="string">        \sum_&#123;j \in \mathcal&#123;N&#125;(i)&#125; e_&#123;j,i&#125; \cdot</span></span><br><span class="line"><span class="string">        (\mathbf&#123;\Theta&#125;_2 \mathbf&#123;x&#125;_i - \mathbf&#123;\Theta&#125;_3 \mathbf&#123;x&#125;_j)</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self, in_channels, out_channels, device</span>):</span></span><br><span class="line">        <span class="built_in">super</span>(MyGNN, self).__init__(aggr=<span class="string">&#x27;add&#x27;</span>)</span><br><span class="line">        self.in_channels = in_channels</span><br><span class="line">        self.out_channels = out_channels</span><br><span class="line"></span><br><span class="line">        self.lin1 = torch.nn.Linear(in_channels, out_channels).to(device)</span><br><span class="line">        self.lin2 = torch.nn.Linear(in_channels, out_channels).to(device)</span><br><span class="line">        self.lin3 = torch.nn.Linear(in_channels, out_channels).to(device)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span>(<span class="params">self, x, edge_index</span>):</span></span><br><span class="line">        a = self.lin1(x)</span><br><span class="line">        b = self.lin2(x)</span><br><span class="line">        out = self.propagate(edge_index, a=a, b=b)</span><br><span class="line">        <span class="keyword">return</span> self.lin3(x) + out</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">message</span>(<span class="params">self, a_i, b_j</span>):</span></span><br><span class="line">        out = a_i - b_j</span><br><span class="line">        <span class="keyword">return</span> out</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__repr__</span>(<span class="params">self</span>):</span></span><br><span class="line">        <span class="keyword">return</span> <span class="string">&#x27;&#123;&#125;(&#123;&#125;, &#123;&#125;)&#x27;</span>.<span class="built_in">format</span>(self.__class__.__name__, self.in_channels,</span><br><span class="line">                                   self.out_channels)</span><br></pre></td></tr></table></figure></li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line">device = torch.device(<span class="string">&#x27;cuda:0&#x27;</span>)</span><br><span class="line"></span><br><span class="line">dataset = Planetoid(root=<span class="string">&#x27;dataset/Cora&#x27;</span>, name=<span class="string">&#x27;Cora&#x27;</span>)</span><br><span class="line">model = MyGNN(in_channels=dataset.num_features, out_channels=dataset.num_classes, device=device)</span><br><span class="line"><span class="built_in">print</span>(model)</span><br><span class="line"></span><br><span class="line">data = dataset[<span class="number">0</span>].to(device)</span><br><span class="line">optimizer = torch.optim.Adam(model.parameters(), lr=<span class="number">0.01</span>, weight_decay=<span class="number">5e-4</span>)</span><br><span class="line"></span><br><span class="line">model.train()</span><br><span class="line"><span class="keyword">for</span> epoch <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">200</span>):</span><br><span class="line">    optimizer.zero_grad()</span><br><span class="line">    out = model(data.x, data.edge_index).to(device)</span><br><span class="line">    pred = out.argmax(dim=<span class="number">1</span>)</span><br><span class="line">    accuracy = <span class="built_in">int</span>((pred[data.test_mask] == data.y[data.test_mask]).<span class="built_in">sum</span>()) / data.test_mask.<span class="built_in">sum</span>()</span><br><span class="line">    loss = F.nll_loss(out[data.train_mask], data.y[data.train_mask])</span><br><span class="line">    loss.backward()</span><br><span class="line">    optimizer.step()</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">if</span> epoch % <span class="number">10</span> == <span class="number">0</span>:</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&quot;Train Epoch: &#123;:3&#125; Accuracy: &#123;:.2f&#125;%&quot;</span>.<span class="built_in">format</span>(epoch, accuracy.item() * <span class="number">100.0</span>))</span><br><span class="line">        </span><br><span class="line">å‚è€ƒè‡ª@å¤©å›½ä¹‹å½± http://relph.gitee.io/my-team-learning/<span class="comment">#/gnn_learning26/task02</span></span><br></pre></td></tr></table></figure></li>
</ul>
]]></content>
      
        
    </entry>
    
    <entry>
      <title><![CDATA[Hello World]]></title>
      <url>/2021/08/18/hello-world/</url>
      <content type="html"><![CDATA[<p>Welcome to <a href="https://hexo.io/">Hexo</a>! This is your very first post. Check <a href="https://hexo.io/docs/">documentation</a> for more info. If you get any problems when using Hexo, you can find the answer in <a href="https://hexo.io/docs/troubleshooting.html">troubleshooting</a> or you can ask me on <a href="https://github.com/hexojs/hexo/issues">GitHub</a>.</p>
<h2 id="Quick-Start"><a href="#Quick-Start" class="headerlink" title="Quick Start"></a>Quick Start</h2><h3 id="Create-a-new-post"><a href="#Create-a-new-post" class="headerlink" title="Create a new post"></a>Create a new post</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo new <span class="string">&quot;My New Post&quot;</span></span><br></pre></td></tr></table></figure>

<p>More info: <a href="https://hexo.io/docs/writing.html">Writing</a></p>
<h3 id="Run-server"><a href="#Run-server" class="headerlink" title="Run server"></a>Run server</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo server</span><br></pre></td></tr></table></figure>

<p>More info: <a href="https://hexo.io/docs/server.html">Server</a></p>
<h3 id="Generate-static-files"><a href="#Generate-static-files" class="headerlink" title="Generate static files"></a>Generate static files</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo generate</span><br></pre></td></tr></table></figure>

<p>More info: <a href="https://hexo.io/docs/generating.html">Generating</a></p>
<h3 id="Deploy-to-remote-sites"><a href="#Deploy-to-remote-sites" class="headerlink" title="Deploy to remote sites"></a>Deploy to remote sites</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo deploy</span><br></pre></td></tr></table></figure>

<p>More info: <a href="https://hexo.io/docs/one-command-deployment.html">Deployment</a></p>
]]></content>
      
        
    </entry>
    
    <entry>
      <title></title>
      <url>/2021/08/18/AI%E4%BA%A4%E5%8F%89/</url>
      <content type="html"></content>
      
        
    </entry>
    
    <entry>
      <title><![CDATA[çŸ¥è¯†å›¾è°±ç¬”è®°]]></title>
      <url>/2021/04/16/%E7%9F%A5%E8%AF%86%E5%9B%BE%E8%B0%B1%E7%AC%94%E8%AE%B0/</url>
      <content type="html"><![CDATA[<h1 id="çŸ¥è¯†å›¾è°±"><a href="#çŸ¥è¯†å›¾è°±" class="headerlink" title="çŸ¥è¯†å›¾è°±"></a>çŸ¥è¯†å›¾è°±</h1><ul>
<li><a href="https://github.com/km1994/NLP-Interview-Notes/tree/main/NLPinterview/KG">https://github.com/km1994/NLP-Interview-Notes/tree/main/NLPinterview/KG</a></li>
</ul>
<ol>
<li>ä»€ä¹ˆæ˜¯schemaï¼Ÿ<br> å³æ˜¯ç»™å‡ºç‰¹å®šçš„æ•°æ®æ ¼å¼ï¼Œå¦‚å®ä½“çš„å±æ€§åªæœ‰å¹´é¾„ å§“åï¼Œé‚£ä¹ˆåŠ å…¥æ­¤çŸ¥è¯†å›¾è°±çš„å®ä½“å°±å¿…é¡»ç¬¦åˆè¿™ä¸ªè¦æ±‚ï¼ŒåŠ å…¥å¦‚â€œæ€§åˆ«â€å°±ä¸è¡Œã€‚</li>
<li>ä¿¡æ¯æŠ½å–çš„éš¾ç‚¹åœ¨å“ªé‡Œï¼Ÿ<br> å¤„ç†éç»“æ„åŒ–æ•°æ®ï¼ŒæŠ½å–å‡ºç»“æ„åŒ–æ•°æ®ï¼ˆå®ä½“å’Œå…³ç³»ï¼‰</li>
<li>æ„å»ºKGæ‰€æ¶‰åŠåˆ°çš„æŠ€æœ¯<ul>
<li>NERï¼ˆå®ä½“å‘½åè¯†åˆ«ï¼‰<ul>
<li>ç›®æ ‡ï¼šä»æ–‡æœ¬ä¸­æå–å‡ºå®ä½“å¹¶å¯¹æ¯ä¸ªå®ä½“åšâ€œåˆ†ç±»/æ‰“æ ‡ç­¾â€<br>å¦‚â€œVirgilâ€™s BBQâ€æå–å‡ºå¹¶æ ‡è®°ä¸Šâ€œRestaurantâ€</li>
<li>ç›®å‰æŠ€æœ¯å·²ç»æ¯”è¾ƒæˆç†Ÿ</li>
</ul>
</li>
<li>å…³ç³»æŠ½å–ï¼ˆRelation Extactionï¼‰</li>
<li>å®ä½“å¯¹é½ï¼ˆEntity Resolution **ï¼‰<ul>
<li>å¦‚NYCå’Œnew york cityæŒ‡å¾—åŒä¸€ä¸ªä¸œè¥¿éœ€è¦å¯¹é½</li>
</ul>
</li>
<li>æŒ‡ä»£æ¶ˆè§£ï¼ˆCoreference Resolutionï¼‰<br>â€œitâ€æŒ‡ä»£çš„å“ªä¸ªåè¯</li>
</ul>
</li>
<li>KGçš„å­˜å‚¨å’ŒæŸ¥è¯¢<ul>
<li>çŸ¥è¯†å›¾è°±å¹¶ä¸ä¸€å®šç”¨å›¾æ•°æ®åº“ï¼ˆPDBï¼‰ï¼Œæ•°æ®åº“åªæ˜¯ä¸€ç§å­˜å‚¨å½¢å¼ï¼Œç‰¹å®šåœºæ™¯å¯ä»¥ç”¨ä¸åŒæ•°æ®åº“ï¼ˆå¦‚ä¸ç”¨æ‰©å±•çš„å¯ä»¥ç”¨å…³ç³»å‹æ•°æ®åº“ï¼‰</li>
<li>egï¼š æŸ¥ Bobâ€™s friendâ€™s friendâ€™s friend<ul>
<li>è‹¥ä½¿ç”¨å…³ç³»å‹æ•°æ®åº“ï¼Œå°±è¦ä¸€ç›´åšjointï¼ŒæŸ¥è¯¢æ—¶é—´æŒ‡æ•°çº§å¢é•¿</li>
<li>ä½†æ˜¯è‹¥ä½¿ç”¨å›¾æ•°æ®åº“ï¼ŒæŸ¥è¯¢æ—¶é—´åªä¼šçº¿æ€§å¢é•¿</li>
</ul>
</li>
<li>PDBå›¾æ•°æ®åº“çš„å¥½å¤„ï¼š<ul>
<li>è¡¨è¾¾æ›´æ¥è¿‘äºè‡ªç„¶è¯­è¨€</li>
<li>æ˜“æ‰©å±•</li>
<li>æ€§èƒ½å¥½</li>
</ul>
</li>
</ul>
</li>
</ol>
]]></content>
      
        
        <tags>
            
            <tag> NLP </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[hexoè°ƒè¯•æ—¥å¿—]]></title>
      <url>/2021/03/24/hexo%E8%B0%83%E8%AF%95%E6%97%A5%E5%BF%97/</url>
      <content type="html"><![CDATA[<ol>
<li>hexo då‡ºé”™ <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">Error: Spawn failed at ChildProcess.&lt;anonymous&gt; (E:\blog\node_modules\hexo-</span><br><span class="line">util\lib\spawn.js:51:21) at ChildProcess.emit (events.js:210:5) at ChildProcess.cp.emit (E:\blog\node_modules\cross-</span><br><span class="line">spawn\lib\enoent.js:34:29) at Process.ChildProcess._handle.onexit (internal&#x2F;child_process.js:272:12)</span><br></pre></td></tr></table></figure>
<ul>
<li>è§£å†³åŠæ³•ï¼š</li>
</ul>
<ol>
<li>åˆ é™¤.deploy_gitæ–‡ä»¶</li>
<li>ä¾æ¬¡æ‰§è¡Œ<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">dexo clean</span><br><span class="line">dexo g</span><br><span class="line">dexo d</span><br></pre></td></tr></table></figure></li>
</ol>
</li>
</ol>
]]></content>
      
        
        <tags>
            
            <tag> hexo </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[è°ƒè¯•æ—¥å¿—]]></title>
      <url>/2021/03/24/python%E8%B0%83%E8%AF%95%E6%97%A5%E5%BF%97/</url>
      <content type="html"><![CDATA[<hr>
<ol>
<li><p>å¦‚æœå‡½æ•°defä¸­æ²¡æœ‰returnï¼Œåªæœ‰printï¼Œå¦‚æœå†åœ¨å¼•ç”¨æ—¶ä½¿ç”¨printï¼Œé‚£ä¹ˆæœ€åä¼šæœ‰noneè¾“å‡ºã€‚</p>
</li>
<li><p>printä¸æ¢è¡ŒåŠ   end=â€œâ€</p>
 <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">print(&quot;....&quot;, end&#x3D;&quot;&quot;)</span><br></pre></td></tr></table></figure></li>
<li><p>è®¡ç®—å­—ç¬¦ä¸²ä¸­å„å­—æ¯å‡ºç°çš„æ¬¡æ•°ï¼š</p>
 <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">def get_frequency_dict(sequence):</span><br><span class="line">    &quot;&quot;&quot;</span><br><span class="line">    Returns a dictionary where the keys are elements of the sequence</span><br><span class="line">    and the values are integer counts, for the number of times that</span><br><span class="line">    an element is repeated in the sequence.</span><br><span class="line"></span><br><span class="line">    sequence: string or list</span><br><span class="line">    return: dictionary</span><br><span class="line">    &quot;&quot;&quot;</span><br><span class="line">    </span><br><span class="line">    # freqs: dictionary (element_type -&gt; int)</span><br><span class="line">    freq &#x3D; &#123;&#125;</span><br><span class="line">    for x in sequence:</span><br><span class="line">        freq[x] &#x3D; freq.get(x,0) + 1</span><br><span class="line">    return freq</span><br></pre></td></tr></table></figure></li>
<li><p><strong>dict.get(â€˜aâ€™,0) and dict[â€˜aâ€™]</strong>:usual way to access a value is hand[â€˜aâ€™], where â€˜aâ€™<br>â€‹is the key we want to find. However,this only works if the key is in the dictionary; otherwise, we get a KeyError â€‹. To avoid this, we can instead use the function call hand.get(â€˜aâ€™,0)</p>
 <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">get(key, [default])</span><br><span class="line">Return the value for key if key is in the dictionary, else default. If default is not given, it defaults to None, so that this method never raises a KeyError.</span><br></pre></td></tr></table></figure></li>
<li><p>å¤§å°å†™è½¬æ¢</p>
 <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">str &#x3D; &quot;www.runoob.com&quot;</span><br><span class="line">print(str.upper())          # æŠŠæ‰€æœ‰å­—ç¬¦ä¸­çš„å°å†™å­—æ¯è½¬æ¢æˆå¤§å†™å­—æ¯</span><br><span class="line">print(str.lower())          # æŠŠæ‰€æœ‰å­—ç¬¦ä¸­çš„å¤§å†™å­—æ¯è½¬æ¢æˆå°å†™å­—æ¯</span><br></pre></td></tr></table></figure></li>
<li><p>åœ¨å­—å…¸éå†è¿‡ç¨‹ä¸­ä¿®æ”¹å­—å…¸å…ƒç´ ï¼ŒæŠ¥é”™Â  <strong>å¾—çŸ¥éå†æ—¶ä¸èƒ½ä¿®æ”¹å­—å…¸å…ƒç´ </strong></p>
 <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">for k in func_dict.keys():</span><br><span class="line">    if func_dict[k] is np.nan:</span><br><span class="line">        del func_dict[k]</span><br><span class="line">        continue</span><br><span class="line">RuntimeError: dictionary changed size during iteration</span><br></pre></td></tr></table></figure>
<p> <strong>è§£å†³åŠæ³•ï¼šå°†éå†æ¡ä»¶æ”¹ä¸ºåˆ—è¡¨</strong></p>
 <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">for k in list(func_dict.keys()):</span><br><span class="line">if func_dict[k] is np.nan:</span><br><span class="line">    del func_dict[k]</span><br><span class="line">    continue</span><br></pre></td></tr></table></figure></li>
<li><p>dict.copy()æ‰æ˜¯å¤åˆ¶ï¼Œè€Œç­‰äºåªæ˜¯å¼•ç”¨è€Œå·²,å­—ç¬¦ä¸²å¤åˆ¶ç›´æ¥å¯ä»¥ç”¨ç­‰å·</p>
</li>
<li><p>How can I add new keys to a dictionary?</p>
 <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">d &#x3D; &#123;&#39;key&#39;: &#39;value&#39;&#125;</span><br><span class="line">print(d)  # &#123;&#39;key&#39;: &#39;value&#39;&#125;</span><br><span class="line"></span><br><span class="line">d[&#39;mynewkey&#39;] &#x3D; &#39;mynewvalue&#39;</span><br><span class="line"></span><br><span class="line">print(d)  # &#123;&#39;key&#39;: &#39;value&#39;, &#39;mynewkey&#39;: &#39;mynewvalue&#39;&#125;</span><br></pre></td></tr></table></figure></li>
<li><p>input() can only has one parameter</p>
 <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">nilai_tinggi &#x3D; int(input(&quot;Enter the height of children number &quot;, str(A)))</span><br><span class="line">TypeError: raw_input() takes from 1 to 2 positional arguments but 3 were given</span><br></pre></td></tr></table></figure>
<p> è§£å†³æ–¹æ³•ï¼š</p>
 <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">nilai_tinggi &#x3D; int(input(&quot;Enter the height of children number %d&quot; %A))</span><br></pre></td></tr></table></figure></li>
</ol>
]]></content>
      
        
        <tags>
            
            <tag> python </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[Hello, World Article!]]></title>
      <url>/2021/03/24/Hello-World-Article/</url>
      <content type="html"><![CDATA[<h1 id="hello-word"><a href="#hello-word" class="headerlink" title="hello word!"></a>hello word!</h1>]]></content>
      
        
    </entry>
    
  
  
</search>
